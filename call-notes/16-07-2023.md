Another insight: constructing/introducing things with linear resources keeps them available
until the result of the construction is consumed, while eliminating linear
resources eliminates them when

Two phases: consuming and using?
* Consuming entails the resource is no longer available (elimination)
* Using entails using resources to construct other resources (introduction) all
    resources are still available until one of them is *consumed*

    Consuming linear resources:
        function elimination,
        case expression,
    Using linear resources without consuming them:
        function introduction,
        let and letrec,
        constructor application

The calculus of delegated consumption (LOL)

## Examples

```haskell
f :: A -o B -o C
f x y = case (x,y) of z { (a,b) -> ... }
```
We use either (x,y), (a,b), or z in the body, since the scrutinee uses x,y but
does not consume them

```haskell
f :: A -o B -o C
f x y = case something x y of z { (a,b) -> ... }
```
In the body of the let we have available (a,b) and z, because x and y were
consumed.

```haskell
f :: A -o B -o C
f x y = case let w = something x y in () of z { (a,b) -> ... }
```
Available (x,y), (a,b), z?

So it would work by assuming the idea that, in the case alternatives, (a,b) have
fragmented usage environments equal to the *USED* in the scrutinee, although the
consumed variables are no longer available. What about $z$ then?

For most rules we would talk uniformly about used and consumed; but in the case
expression we would do different things to them.

However, what if no variables are *USED* in the scrutinee, only consumed? That
would make (a,b) and z unrestricted -- wrong.
```haskell
f :: A -o B -o C
f x y = case something x y of z { (a,b) -> a a a b b b z z z }
```

There seem to be two cases:
* All linear variables in the scrutinee are *consumed*, in which case we *must*
    consume the result: (a,b) are linear, and z has usage environment (a,b)
* All linear variables in the scrutinee are *used*, in which case they're still
    available in the alternatives, z maps to those linear variables used in the
    scrutinee, and the linear variables in the pattern have a fragmented usage environment
    (And in patterns with no linear variables we keep the rule -- it's a value
    and already consumed -- we drop the resources)

I'm not even sure there would be a way to consume some and use some variables in
the same expression -- so there wouldn't be used and consumed variables, but
rather two distinct consuming and using stages?

~~This could turn out to model a good thing in the rules: that a linear function
only *consumes* its argument when the application itself is *consumed* (since
the function elimination rule will say something like *consumes* this if *consumed*).~~


I think what we need is exactly in the definition of consuming, functions have a
distinct definition:
Definition 2.1 (Consume exactly once).
• To consume a value of atomic base type (like Int or Ptr) exactly once, just evaluate it.
• To consume a function value exactly once, apply it to one argument, and consume its result
exactly once.
• To consume a pair exactly once, pattern-match on it, and consume each component exactly
once.
• In general, to consume a value of an algebraic datatype exactly once, pattern-match on it,
and consume all its linear components exactly once (Sec. 2.5).

Can we duplicate values, once they've been evaluated e.g. could we use a
pointer multiple times after evaluating some linear resources to it? No, I don't
think so.
> ~~term should not be duplicated unless and until it has been reduced to a value~~

But if we evaluate a pointer with case, we'd be able to use it again through the
match variable -- using that match variable exactly once is the same as re-using
the pointer exactly once

More counter examples -- of the ideas so far:
```haskell
f x y = case K x y of z { K a b -> ...use x y, z, or a b...;
                          K2 w -> ... saying x y are available is weird... }
```
Actually, I think that is fine. `x` and `y` are available because ?


What does Case do?

Let binds names to expressions that consume resources, but
only consumes those resources once the binder is evaluated.


Case evaluates the scrutinee to WHNF and chooses a branch based on the Core
pattern, which can be one of:

    data AltCon
      = DataAlt DataCon   --  ^ A plain data constructor: @case e of { Foo x -> ... }@.
                          -- Invariant: the 'DataCon' is always from a @data@ type, and never from a @newtype@

      | LitAlt  Literal   -- ^ A literal: @case e of { 1 -> ... }@
                          -- Invariant: always an *unlifted* literal
                          -- See Note [Literal alternatives]

      | DEFAULT           -- ^ Trivial alternative: @case e of { _ -> ... }@


Why is this linear?
```haskell
f x = case x of z { K a b -> expensive x; K2 w -> w }
```
Here, `x` can be an unlifted value like `3#`, or a pointer to a thunk which will
be overwritten when evaluated, or a pointer to a heap allocated value.

What about this?
```haskell
f y = let x = use y
       in case x of z { K a b -> expensive x; K2 w -> w }
```
Here, `x` is decidedly an unevaluated thunk.


And why is this linear?
```haskell
f y = let x = use y
      let t = expensive x
       in case x of z { K a b -> t; K2 w -> w }
```

When `x` appears in the case scrut., `y` is consumed, resulting in `x` being a
pointer to an evaluated closure with the result of `use y` -- which, now that
has been evaluated, must be consumed exactly once.

Perhaps we could have that for `case var of ...`, in the branch alternatives,
`var` is available as a linear variable. For the last example to typecheck, we
would also need to record the usage environment of `t` to be `x`, rather than
`y`. It feels like that's the right thing to do, even now, and then to see what
was consumed we'd need to traverse the usage environments recursively inward?

---------

## Thunks as Suspended Computations

Computation consumes the linear resources used to define that computation (all
of them, or can some be suspended inside of the computation too?)

Thunks are suspended computations. We can bind a name to a thunk, but we only
perform the computation which consumes the linear resources when we force the
thunk to be evaluated.

Consider
* `x` is a suspended computation that uses some resources `Δ`.
    * If `x` is linearly bound, we don't know exactly what resources were used
        to construct this computation (in this case it could also already be
        evaluated, but it all lines up correctly).
    * If `x` is `Δ`-bound, we know exactly what resources were used -- `Δ`.
* The expression
    ```haskell
    case x of z {...}
    ```
    forces the `x` suspended computation, consuming the linear resources, and
    returns the result of the computation, under the name `x` still.

Insight: We can introduce a rule for forcing suspended computations separately,
which is well defined for linear and delta-vars, and then we can reduce
`case var of ...` to this rule of forcing `var`.

Maybe...
```
    Δ,xΔσ ⊦ x:σ   Γ,x1!σ ⊦ e : τ
    ----------------------------- (unsuspend)
        Γ,Δ,xΔσ ⊦ !x; e : τ
```
where `!σ` means an evaluated σ, and perhaps `case` can only pattern match on
evaluated scrutinees? Or shouldn't the `case` rule be merged with the above? We
just need to figure out how it handles evaluation to WHNF of things more
complicated than variables (see below).

Examples:
```haskell
close :: Handle ⊸ RW# ⊸ (# [Char], RW# #)

f :: Handle ⊸ RW# ⊸ (# Int, RW# #)
f x rw = let y = close x rw in !y; case y of [] -> 0; (a:as) -> expensive y
```
The `case` here doesn't work yet ^. What if `close` only closes the handle when
all elements in the string are consumed? Then `x` is only *fully* consumed after
that, but it can not be used when it is *partly* consumed either (we don't know
how close works)


---

A `case` only guarantees to consume the scrutinee fully if all the
linear resources in each pattern are fully consumed, or otherwise we might only
consume part of the resources to get the expression to WHNF, and the rest remain
unevaluated (and thus the resources are not computed).

When thunks (suspended computations) are forced, computations occurs and
consumes the linear resources needed for that computation, producing new linear
resources that must be further consumed.

How do we concile the fact that forcing some expressions will consume them fully
while some will only consume them partly and require further computation for the
resources to be all consumed?

Rather, that forcing an expression only consumes it to WHNF, and only when we
know we reached NF do we know that all resources were consumed.

In branches where no more linear variables are bound, we know all linear
resources were consumed. In branches where there are linear variables bound, all
of them must still be consumed to finish consuming the scrutinee fully.

What would be the difference between the case rule ((unsuspend) above) for vars
and the case for expressions evaluated to WHNF?

In the case body, we have available a fragment of the usage environment of the
scrutinee, and each linear variable has a fragment of that fragment. In the case
of a variable, the fragment is actually the whole.

Something something the continuation passing style representation/sequent linear
calculus might make it easier to reason about linearity? Then we could translate
it back?

```
        Δ,xΔσ ⊦ x:σ             {{ Γ,x1!σ ⊦ e : τ }}
    ------------------------------------------------------------ (case_var)
        Γ,Δ,xΔσ ⊦ case x of z { K a b -> e1 ; K2 -> e2 } : τ

     Γ,Δ ⊦ e:σ     Γ',Δ_f,aΔ_f_f, bΔ_f_f, zΔ_fσ ⊦ e : τ     Γ',zωσ ⊦ e : τ
    ------------------------------------------------------------------------ (case)
        Γ,Γ',Δ ⊦ case e of z { K a b -> e1 ; K2 -> e2 } : τ
```

The substitution in the `case` rule for when there are no linearly bound vars
evidences that evaluation to NF (not really NF if there are unrestricted
variables left are there? what is it then?) consumes all the resources used by
the scrutinee.



