@misc{jones1999haskell,
  title={Haskell 98},
  author={Jones, Simon Peyton and Hughes, John and Augustsson, Lennart and Barton, Dave and Boutel, Brian and Burton, Warren and Fasel, Joseph and Hammond, Kevin and Hinze, Ralf and Hudak, Paul and others},
  year={1999},
  publisher={Citeseer}
}

@article{marlow2010haskell,
  title={Haskell 2010 language report},
  author={Marlow, Simon and others},
  year={2010}
}

@article{cite:linearhaskell,
  author    = {Jean{-}Philippe Bernardy and
               Mathieu Boespflug and
               Ryan R. Newton and
               Simon Peyton Jones and
               Arnaud Spiwack},
  title     = {Linear Haskell: practical linearity in a higher-order polymorphic
               language},
  journal   = {CoRR},
  volume    = {abs/1710.09756},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.09756},
  eprinttype = {arXiv},
  eprint    = {1710.09756},
  timestamp = {Mon, 13 Aug 2018 16:47:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-09756.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{linearbase,
  title = {{linear-base}},
  author = {{Tweag}},
  howpublished = {\url{https://github.com/tweag/linear-base}},
  note = {Accessed: 2022-11-25}
}

@article{10.1145/1160074.1159811,
author = {Peyton Jones, Simon and Vytiniotis, Dimitrios and Weirich, Stephanie and Washburn, Geoffrey},
title = {Simple Unification-Based Type Inference for GADTs},
year = {2006},
issue_date = {September 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/1160074.1159811},
doi = {10.1145/1160074.1159811},
abstract = {Generalized algebraic data types (GADTs), sometimes known as "guarded recursive data types" or "first-class phantom types", are a simple but powerful generalization of the data types of Haskell and ML. Recent works have given compelling examples of the utility of GADTs, although type inference is known to be difficult. Our contribution is to show how to exploit programmer-supplied type annotations to make the type inference task almost embarrassingly easy. Our main technical innovation is wobbly types, which express in a declarative way the uncertainty caused by the incremental nature of typical type-inference algorithms.},
journal = {SIGPLAN Not.},
month = {sep},
pages = {50–61},
numpages = {12},
keywords = {type inference, generalized algebraic data types}
}

@inproceedings{10.1145/1159803.1159811,
author = {Peyton Jones, Simon and Vytiniotis, Dimitrios and Weirich, Stephanie and Washburn, Geoffrey},
title = {Simple Unification-Based Type Inference for GADTs},
year = {2006},
isbn = {1595933093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1159803.1159811},
doi = {10.1145/1159803.1159811},
abstract = {Generalized algebraic data types (GADTs), sometimes known as "guarded recursive data types" or "first-class phantom types", are a simple but powerful generalization of the data types of Haskell and ML. Recent works have given compelling examples of the utility of GADTs, although type inference is known to be difficult. Our contribution is to show how to exploit programmer-supplied type annotations to make the type inference task almost embarrassingly easy. Our main technical innovation is wobbly types, which express in a declarative way the uncertainty caused by the incremental nature of typical type-inference algorithms.},
booktitle = {Proceedings of the Eleventh ACM SIGPLAN International Conference on Functional Programming},
pages = {50–61},
numpages = {12},
keywords = {type inference, generalized algebraic data types},
location = {Portland, Oregon, USA},
series = {ICFP '06}
}

@article{10.1145/3408971,
author = {Serrano, Alejandro and Hage, Jurriaan and Peyton Jones, Simon and Vytiniotis, Dimitrios},
title = {A Quick Look at Impredicativity},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {ICFP},
url = {https://doi.org/10.1145/3408971},
doi = {10.1145/3408971},
abstract = {Type inference for parametric polymorphism is wildly successful, but has always suffered from an embarrassing flaw: polymorphic types are themselves not first class. We present Quick Look, a practical, implemented, and deployable design for impredicative type inference. To demonstrate our claims, we have modified GHC, a production-quality Haskell compiler, to support impredicativity. The changes required are modest, localised, and are fully compatible with GHC's myriad other type system extensions.},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {89},
numpages = {29},
keywords = {Type systems, constraint-based inference, impredicative polymorphism}
}

@inproceedings{10.1145/3062341.3062357,
author = {Eisenberg, Richard A. and Peyton Jones, Simon},
title = {Levity Polymorphism},
year = {2017},
isbn = {9781450349888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3062341.3062357},
doi = {10.1145/3062341.3062357},
abstract = {Parametric polymorphism is one of the linchpins of modern typed programming, but it comes with a real performance penalty. We describe this penalty; offer a principled way to reason about it (kinds as calling conventions); and propose levity polymorphism. This new form of polymorphism allows abstractions over calling conventions; we detail and verify restrictions that are necessary in order to compile levity-polymorphic functions. Levity polymorphism has created new opportunities in Haskell, including the ability to generalize nearly half of the type classes in GHC's standard library.},
booktitle = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {525–539},
numpages = {15},
keywords = {compilation, polymorphism, unboxed types},
location = {Barcelona, Spain},
series = {PLDI 2017}
}

@article{10.1017/S0956796806006034,
author = {Peyton Jones, Simon and Vytiniotis, Dimitrios and Weirich, Stephanie and Shields, Mark},
title = {Practical Type Inference for Arbitrary-Rank Types},
year = {2007},
issue_date = {January 2007},
publisher = {Cambridge University Press},
address = {USA},
volume = {17},
number = {1},
issn = {0956-7968},
url = {https://doi.org/10.1017/S0956796806006034},
doi = {10.1017/S0956796806006034},
abstract = {Haskell's popularity has driven the need for ever more expressive type system features, most of which threaten the decidability and practicality of Damas-Milner type inference. One such feature is the ability to write functions with higher-rank types – that is, functions that take polymorphic functions as their arguments. Complete type inference is known to be undecidable for higher-rank (impredicative) type systems, but in practice programmers are more than willing to add type annotations to guide the type inference engine, and to document their code. However, the choice of just what annotations are required, and what changes are required in the type system and its inference algorithm, has been an ongoing topic of research. We take as our starting point a $lambda$-calculus proposed by Odersky and L\"{a}ufer. Their system supports arbitrary-rank polymorphism through the exploitation of type annotations on $lambda$-bound arguments and arbitrary sub-terms. Though elegant, and more convenient than some other proposals, Odersky and L\"{a}ufer's system requires many annotations. We show how to use local type inference (invented by Pierce and Turner) to greatly reduce the annotation burden, to the point where higher-rank types become eminently usable. Higher-rank types have a very modest impact on type inference. We substantiate this claim in a very concrete way, by presenting a complete type-inference engine, written in Haskell, for a traditional Damas-Milner type system, and then showing how to extend it for higher-rank types. We write the type-inference engine using a monadic framework: it turns out to be a particularly compelling example of monads in action. The paper is long, but is strongly tutorial in style. Although we use Haskell as our example source language, and our implementation language, much of our work is directly applicable to any ML-like functional language.},
journal = {J. Funct. Program.},
month = {jan},
pages = {1–82},
numpages = {82}
}

@article{10.1145/227699.227700,
author = {Hall, Cordelia V. and Hammond, Kevin and Peyton Jones, Simon L. and Wadler, Philip L.},
title = {Type Classes in Haskell},
year = {1996},
issue_date = {March 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/227699.227700},
doi = {10.1145/227699.227700},
abstract = {This article defines a set of type inference rules for resolving overloading introduced by type classes, as used in the functional programming language Haskell. Programs including type classes are transformed into ones which may be typed by standard Hindley-Milner inference rules. In contrast to other work on type classes, the rules presented here relate directly to Haskell programs. An innovative aspect of this work is the use of second-order lambda calculus to record type information in the transformed program.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {mar},
pages = {109–138},
numpages = {30},
keywords = {Haskell, type classes, functional programming, types}
}


@article{10.1145/3473569,
author = {Eisenberg, Richard A. and Duboc, Guillaume and Weirich, Stephanie and Lee, Daniel},
title = {An Existential Crisis Resolved: Type Inference for First-Class Existential Types},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {ICFP},
url = {https://doi.org/10.1145/3473569},
doi = {10.1145/3473569},
abstract = {Despite the great success of inferring and programming with universal types, their dual—existential types—are much harder to work with. Existential types are useful in building abstract types, working with indexed types, and providing first-class support for refinement types. This paper, set in the context of Haskell, presents a bidirectional type-inference algorithm that infers where to introduce and eliminate existentials without any annotations in terms, along with an explicitly typed, type-safe core language usable as a compilation target. This approach is backward compatible. The key ingredient is to use strong existentials, which support (lazily) projecting out the encapsulated data, not weak existentials accessible only by pattern-matching.},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {64},
numpages = {29},
keywords = {type inference, Haskell, existential types}
}

@inproceedings{DBLP:conf/popl/DamasM82,
  author    = {Lu{\'{\i}}s Damas and
               Robin Milner},
  editor    = {Richard A. DeMillo},
  title     = {Principal Type-Schemes for Functional Programs},
  booktitle = {Conference Record of the Ninth Annual {ACM} Symposium on Principles
               of Programming Languages, Albuquerque, New Mexico, USA, January 1982},
  pages     = {207--212},
  publisher = {{ACM} Press},
  year      = {1982},
  url       = {https://doi.org/10.1145/582153.582176},
  doi       = {10.1145/582153.582176},
  timestamp = {Tue, 06 Nov 2018 11:07:43 +0100},
  biburl    = {https://dblp.org/rec/conf/popl/DamasM82.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{cite:linear-logic,
title = {Linear logic},
journal = {Theoretical Computer Science},
volume = {50},
number = {1},
pages = {1-101},
year = {1987},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(87)90045-4},
url = {https://www.sciencedirect.com/science/article/pii/0304397587900454},
author = {Jean-Yves Girard},
abstract = {The familiar connective of negation is broken into two operations: linear negation which is the purely negative part of negation and the modality “of course” which has the meaning of a reaffirmation. Following this basic discovery, a completely new approach to the whole area between constructive logics and programmation is initiated.}
}

@techreport{cite:barberdill,
    author={Andrew Barber},
    title={Dual Intuitionistic Linear Logic},
    institution={The University of Edinburgh},
    year={1996},
    number={ECS-LFCS-96-347}
}

@InProceedings{brady:LIPIcs.ECOOP.2021.9,
  author =	{Brady, Edwin},
  title =	{{Idris 2: Quantitative Type Theory in Practice}},
  booktitle =	{35th European Conference on Object-Oriented Programming (ECOOP 2021)},
  pages =	{9:1--9:26},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-190-0},
  ISSN =	{1868-8969},
  year =	{2021},
  volume =	{194},
  editor =	{M{\o}ller, Anders and Sridharan, Manu},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/opus/volltexte/2021/14052},
  URN =		{urn:nbn:de:0030-drops-140527},
  doi =		{10.4230/LIPIcs.ECOOP.2021.9},
  annote =	{Keywords: Dependent types, linear types, concurrency}
}


@article{10.1145/2692956.2663188,
author = {Matsakis, Nicholas D. and Klock, Felix S.},
title = {The Rust Language},
year = {2014},
issue_date = {December 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {3},
issn = {1094-3641},
url = {https://doi.org/10.1145/2692956.2663188},
doi = {10.1145/2692956.2663188},
abstract = {Rust is a new programming language for developing reliable and efficient systems. It is designed to support concurrency and parallelism in building applications and libraries that take full advantage of modern hardware. Rust's static type system is safe1 and expressive and provides strong guarantees about isolation, concurrency, and memory safety.Rust also offers a clear performance model, making it easier to predict and reason about program efficiency. One important way it accomplishes this is by allowing fine-grained control over memory representations, with direct support for stack allocation and contiguous record storage. The language balances such controls with the absolute requirement for safety: Rust's type system and runtime guarantee the absence of data races, buffer overflows, stack overflows, and accesses to uninitialized or deallocated memory.},
journal = {Ada Lett.},
month = {oct},
pages = {103–104},
numpages = {2},
keywords = {affine type systems, rust, systems programming, memory management}
}

@incollection {curry:34,
    author    = {H.B. Curry},
    journal = {Proceedings of the National Academy of Sciences},
    title     = {Functionality in Combinatory Logic},
    year      = {1934},
    volume = {20},
    number = {11},
   pages = {584-590},
   doi = {​10.1073/pnas.20.11.584​},
   address   = {Department of Mathematics, The Pennsylvania State College},
 }

@incollection{howard:80,
  author =       {William A. Howard},
  journal = {To H.B. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism},
  title =  {The Formulae-as-types notion of construction},
  year =         {1980 (originally circulated 1969)},
  pages =        "479-490",
  ISBN = {​978-0-12-349050-6​}
}

@inbook{marlow2012the,
author = {Marlow, Simon and Peyton Jones, Simon},
title = {The Glasgow Haskell Compiler},
booktitle = {The Architecture of Open Source Applications, Volume 2},
year = {2012},
month = {January},
abstract = {The Glasgow Haskell Compiler (GHC) started as part of an academic research project funded by the UK government at the beginning of the 1990’s, with several goals in mind:

 	To make freely available a robust and portable compiler for Haskell that generates high performance code;
 	To provide a modular foundation that other researchers can extend and develop;
 	To learn how real programs behave, so that we can design and build better compilers.

GHC is now over 20 years old, and has been under continuous active development since its inception. Today, GHC releases are downloaded by hundreds of thousands of people, the online repository of Haskell libraries has over 3,000 packages, GHC is used to teach Haskell in many undergraduate courses, and there are a growing number of instances of Haskell being depended upon commercially.},
publisher = {Lulu},
url = {https://www.microsoft.com/en-us/research/publication/the-glasgow-haskell-compiler/},
edition = {The Architecture of Open Source Applications, Volume 2},
}

@inproceedings{cite:systemfc,
author = {Sulzmann, Martin and Chakravarty, Manuel and Peyton Jones, Simon and Donnelly, Kevin},
title = {System F with type equality coercions},
booktitle = {ACM SIGPLAN International Workshop on Types in Language Design and Implementation (TLDI'07)},
year = {2007},
month = {January},
abstract = {We introduce a variant of System F that uses a single mechanism to enable the type preserving translation of generalised abstract data types (GADTs), type classes with associated types and functional dependencies, as well as closed type functions. The core idea is to pass around explicit evidence for type equalities, just like System F passes types explicitly. We use this evidence to justify type casts encoding non-syntactic type equalities induced by the mentioned source language features. In particular, we don't need special typing rules for pattern matching on GADTs, we can easily combine GADTs with type classes, and we can relax restrictions on programs involving associated types or functional dependencies.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/system-f-with-type-equality-coercions/},
pages = {53-66},
isbn = {1-59593-393-X},
edition = {ACM SIGPLAN International Workshop on Types in Language Design and Implementation (TLDI'07)},
}

@article{cite:outsideinx,
    title={OutsideIn(X) Modular type inference with local assumptions},
    volume={21},
    DOI={10.1017/S0956796811000098},
    number={4-5},
    journal={Journal of Functional Programming},
    publisher={Cambridge University Press},
    author={VYTINIOTIS, DIMITRIOS and PEYTON JONES, SIMON and SCHRIJVERS, TOM and SULZMANN, MARTIN},
    year={2011},
    pages={333–412}
}

@inproceedings{maurer2017compiling,
author = {Maurer, Luke and Ariola, Zena and Downen, Paul and Peyton Jones, Simon},
title = {Compiling without continuations},
booktitle = {ACM Conference on Programming Languages Design and Implementation (PLDI'17)},
year = {2017},
month = {June},
abstract = {Many fields of study in compilers give rise to the concept of  a join point --- a place where different execution paths come together.   While they have often been treated by representing them as functions or  continuations, we believe it is time to study them in their own right. We show  that adding them to a direct-style functional intermediate language allows new optimizations to be performed, including a functional version of  loop-invariant code motion. Finally, we report on recent work on the Glasgow  Haskell Compiler which added join points to the Core language.},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/compiling-without-continuations/},
pages = {482-494},
}

@article{peytonjones1997a,
author = {Peyton Jones, Simon and Santos, Andre},
title = {A transformation-based optimiser for Haskell},
year = {1997},
month = {October},
abstract = {Many compilers do some of their work by means of correctness-preserving, and hopefully performance-improving, program transformations. The Glasgow Haskell Compiler (GHC) takes this idea of "compilation by transformation" as its war-cry, trying to express as much as possible of the compilation process in the form of program transformations.

This paper reports on our practical experience of the transformational approach to compilation, in the context of a substantial compiler.


This is a journal version of "Compilation by program transformation: a report from the trenches" (ESOP'96)},
url = {https://www.microsoft.com/en-us/research/publication/a-transformation-based-optimiser-for-haskell/},
journal = {Science of Computer Programming},
volume = {32},
number = {1},
}

@phdthesis{santos1995compilation,
author = {Santos, Andre and Peyton Jones, Simon},
title = {Compilation by transformation for non-strict functional languages},
organization = {University of Glasgow},
year = {1995},
month = {July},
abstract = {In this thesis we present and analyse a set of automatic source-to-source program transformations that are suitable for incorporation in optimising compilers for lazy functional languages.  These transformations improve the quality of code in many different respects, such as execution time and memory usage.

The transformations presented are divided into two sets: global transformations, which are performed once (or perhaps twice) during compilation; and a set of local transformations with are performed before and after each of the global transformations, so that they can simplify the code before applying the global transformations, and take advantage of them afterwards.

Many of the local transformations are simple, well known, and do not have major effects on their own.  They become important as they interact with each other and with global transformations, sometimes in non-obvious ways.  We present how and why they improve the code, and perform extensive experiments with real application programs.

We describe four global transformations, two of which have not been used in any lazy functional compiler we know of: the static argument transformations and let-floating transformations.  The other two are well known for lazy functional languages, but no major studies of their effects have been performed: full laziness and lambda lifting.  We also study and measure the effects of different inlining strategies.

We also present a Cost Semantics as a way to reason about the effects of program transformations in lazy functional languages.

[I have listed myself as an author only so that this thesis appears on my home page; it is Andre's thesis!]},
url = {https://www.microsoft.com/en-us/research/publication/compilation-transformation-non-strict-functional-languages/},
}

@phdthesis{Breitner2016_1000054251,
    author       = {Breitner, Joachim},
    year         = {2016},
    title        = {Lazy Evaluation: From natural semantics to a machine-checked compiler transformation},
    doi          = {10.5445/IR/1000054251},
    publisher    = {{Karlsruher Institut für Technologie (KIT)}},
    keywords     = {Haskell, Lazy Evaluation, Call Arity, Interactive Theorem Proving},
    pagetotal    = {226},
    school       = {Karlsruher Institut für Technologie (KIT)},
    language     = {english}
}

@article{baker-finch2004constructed,
author = {Baker-Finch, Clem and Glynn, Kevin and Peyton Jones, Simon},
title = {Constructed Product Result Analysis for Haskell},
year = {2004},
month = {March},
abstract = {Compilers for ML and Haskell typically go to a good deal of trouble to arrange that multiple arguments can be passed efficiently to a procedure. For some reason, less effort seems to be invested in ensuring that multiple results can also be returned efficiently.

In the context of the lazy functional language Haskell, we describe an analysis, Constructed Product Result (CPR) analysis, that determines when a function can profitably return multiple results in registers. The analysis is based only on a function's definition, and not on its uses (so separate compilation is easily supported) and the results of the analysis can be expressed by a transformation of the function definition alone. We discuss a variety of design issues that were addressed in our implementation, and give measurements of the effectiveness of our approach across a substantial benchmark set.

Overall, the price/performance ratio is good: the benefits are modest in general (though occasionally dramatic), but the costs in both complexity and compile time, are low.

 },
url = {https://www.microsoft.com/en-us/research/publication/constructed-product-result-analysis-haskell/},
pages = {211-245},
journal = {Journal of Functional Programming},
volume = {14},
number = {2},
}


@article{sergey_vytiniotis_jones_breitner_2017, title={Modular, higher order cardinality analysis in theory and practice}, volume={27}, DOI={10.1017/S0956796817000016}, journal={Journal of Functional Programming}, publisher={Cambridge University Press}, author={SERGEY, ILYA and VYTINIOTIS, DIMITRIOS and JONES, SIMON L. PEYTON and BREITNER, JOACHIM}, year={2017}, pages={e11}}

@article{peytonjones2002secrets,
author = {Peyton Jones, Simon and Marlow, Simon},
title = {Secrets of the Glasgow Haskell Compiler inliner},
year = {2002},
month = {July},
abstract = {Higher-order languages, such as Haskell, encourage the programmer to build abstractions by composing functions. A good compiler must inline many of these calls to recover an efficiently executable program.

In principle, inlining is dead simple: just replace the call of a function by an instance of its body. But any compiler-writer will tell you that inlining is a black art, full of delicate compromises that work together to give good performance without unnecessary code bloat.

The purpose of this paper is, therefore, to articulate the key lessons we learned from a full-scale ``production'' inliner, the one used in the Glasgow Haskell compiler. We focus mainly on the algorithmic aspects, but we also provide some indicative measurements to substantiate the importance of various aspects of the inliner.

The "Related File" link above is an earlier tech-report version of the paper, but the JFP version is the one to read (the "View publication" button).},
url = {https://www.microsoft.com/en-us/research/publication/secrets-of-the-glasgow-haskell-compiler-inliner/},
pages = {393-434},
journal = {Journal of Functional Programming},
volume = {12},
}

@article{cite:let-floating,
author = {Peyton Jones, Simon and Partain, Will},
year = {1996},
month = {10},
pages = {},
title = {Let-Floating: Moving Bindings to Give Faster Programs},
volume = {31},
journal = {Proc. of ICFP'96},
doi = {10.1145/232629.232630}
}

@InProceedings{10.1007/3-540-06859-7_148,
author="Reynolds, John C.",
editor="Robinet, B.",
title="Towards a theory of type structure",
booktitle="Programming Symposium",
year="1974",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="408--425",
isbn="978-3-540-37819-8"
}

@inproceedings{Girard1972InterpretationFE,
  title={Interpretation fonctionelle et elimination des coupures dans l'aritmetique d'ordre superieur},
  author={Jean-Yves Girard},
  year={1972}
}

@book{augustsson1987compiling,
  title={Compiling Lazy Functional Languages, Part II},
  author={Augustsson, L.},
  isbn={9789170323263},
  series={Compiling lazy functional languages},
  url={https://books.google.pt/books?id=zUZMSgAACAAJ},
  year={1987},
  publisher={Chalmers University of Technology}
}


@article{jones_1992, title={Implementing lazy functional languages on stock hardware: the Spineless Tagless G-machine}, volume={2}, DOI={10.1017/S0956796800000319}, number={2}, journal={Journal of Functional Programming}, publisher={Cambridge University Press}, author={Jones, Simon L. Peyton}, year={1992}, pages={127–202}}

@InProceedings{10.1007/3-540-15975-4_37,
author="Johnsson, Thomas",
editor="Jouannaud, Jean-Pierre",
title="Lambda lifting: Transforming programs to recursive equations",
booktitle="Functional Programming Languages and Computer Architecture",
year="1985",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="190--203",
abstract="Lambda lifting is a technique for transforming a functional program with local function definitions, possibly with free variables in the function definitions, into a program consisting only of global function (combinator) definitions which will be used as rewrite rules. Different ways of doing lambda lifting are presented, as well as reasons for rejecting or selecting the method used in our Lazy ML compiler. A functional program implementing the chosen algorithm is given.",
isbn="978-3-540-39677-2"
}

@InProceedings{10.1007/3540543961_30,
author="Jones, Simon L. Peyton
and Launchbury, John",
editor="Hughes, John",
title="Unboxed values as first class citizens in a non-strict functional language",
booktitle="Functional Programming Languages and Computer Architecture",
year="1991",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="636--666",
abstract="The code compiled from a non-strict functional program usually manipulates heap-allocated boxed numbers. Compilers for such languages often go to considerable trouble to optimise operations on boxed numbers into simpler operations on their unboxed forms. These optimisations are usually handled in an ad hoc manner in the code generator, because earlier phases of the compiler have no way to talk about unboxed values.",
isbn="978-3-540-47599-6"
}

@misc{peytonjones1993measuring,
author = {Peyton Jones, Simon and Partain, Will},
title = {Measuring the effectiveness of a simple strictness analyser},
series = {Workshops in Computing},
year = {1993},
month = {January},
abstract = {We describe a simple strictness analyser for purely-functional programs, who how its results are used to improve programs, and provide measurements of the effects of these improvements. These measurements are given both in terms of overall run-time, and in terms of internal operations such as allocations, updates, etc. Despite its simplicity, the analyser handles higher-order functions, and non-flat domains provided they are non-recursive.},
publisher = {Springer},
url = {https://www.microsoft.com/en-us/research/publication/measuring-the-effectiveness-of-a-simple-strictness-analyser/},
pages = {201-220},
edition = {Functional Programming, Glasgow 1993},
note = {Functional Programming, Glasgow 1993},
}

% TODO: cite:ghc-source-code

