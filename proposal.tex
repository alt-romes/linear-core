\documentclass[a4paper, draft]{article}

\usepackage{fancyvrb}
\DefineVerbatimEnvironment{code}{Verbatim}{fontsize=\small}
\DefineVerbatimEnvironment{example}{Verbatim}{fontsize=\small}

\title{Linting Linearity in Core/System FC}
\author{Rodrigo Mesquita}


\begin{document}
\maketitle

\section{Introduction}

\section{Background}

\section{Technical Details}

Since Linear Haskell's\ref{}
publication and implementation release in GHC 9.2, Haskell's type system
supports linearity annotations in functions -- bringing linear types into a
mainstream pure and lazy functional language.

System FC is the formal system in which the implementation of GHC's intermediate
representation language \emph{Core} is based on.

There are at least two distinct typecheckers in core. The first is run on the frontend
language, i.e. the Haskell we write, and is a big and complex typechecker. The
second is run on the intermediate language \emph{Core} that we obtain from
desugaring Haskell.

\emph{Core} is a much smaller and more principled language than the whole of
Haskell (even though we can compile the whole of Haskell to it), and the
typechecker for it is small and fast due to \emph{Core} being explicitly typed
and having a very small abstract syntax tree. This typechecker is called
\emph{Lint} and gives us guarantees of correctness (i.e. sanity) in face of
the complexity of all the transformations a Haskell program undergoes, such as
type inference, desugaring and optimising transformations (and other Core
related passes?).

\begin{itemize}
    \item In GHC, the type Type is shared between the surface language and Core.
        So modifying the types implies that Core is modified as well. 

    \item More importantly, because Core is a good check that our implementation
        works as intended. That is, a linearly typed Core will ensure that
        linearly-typed programs are indeed desugared to linearly-typed programs
        in Core. And that optimisations do not destroy linearity.
\end{itemize}

The addition of linear types comes at two levels: frontend and Core.
In the frontend, we can now annotate with linearity type declarations and
typecheck programs that use them accordingly (a linear fuction will consume its
argument exactly once if it is consumed exactly once, for some definition of
\emph{consume} that I should revise here). In Core, we still have linearity
annotations and ideally \emph{Lint} would check that all the GHC transformations
to our linear program preserved its linearity. However, \textbf{it can't}!

Despite the strong formal foundations of linear types driving the
implementation, their interaction with the whole of GHC is still far from
trivial. Diverse problems with linearity spring up when we get past the
desugarer. In particular, optimizing transformations, coercions from GADTs and
type families, recursive lets, and empty case expressions don't currently fit in
with linearity.

We believe that GHC's transformations are correct, and it is the linear type
system that can't accommodate the resulting programs. We aim to formalise a type
system that is able to type check \emph{Core}/\emph{System FC} at all points in
the core pipeline and implement it into GHC to be able to preserve linearity
accross the stages and to enable \emph{Lint} to preserve our sanity regarding
linearity.

\section{Motivation}

\begin{itemize}
    \item Are we really preserving linearity?
    \item Inform/unlock other optimisations that take into account linearity
\end{itemize}

% Our key innovation is that, by recognising join points as a language construct,
% we both preserve join points through subsequent transformations and exploit them
% to make those transformations more effective. Next, we formalize this ap-
% proach; subsequent sections develop the consequences.

\section{Typing Usage Environments}

The first set of problems appears in the core-to-core optimisation passes. GHC
applies many optimising transformations to \emph{Core} and we believe those
transformations preserve linearity. However, our linear type system cannot check
that they indeed preserve linearity.

The simpler examples come from straightforward and common optimising
transformations. Then we have recursive let definitions that don't accommodate
linearity even though it might converge to only use the value once. Finally, we
have the empty case expression introduced with the \emph{EmptyCase} language
extension that we currently can't typecheck either.


A usage environment is a mapping from variables to multiplicities.

The key idea is to annotate every variable with either its multiplicity, if it's
lambda bound, or with its usage environment, if it's let bound.

For example, if y and z are linear, in the following code it might not look as
if y and z were both being consumed linearly, but indeed they are since in the
first branch we use x which means using y and z linearly, and we use y and z
directly on the second branch. Note that let binding x doesn't consume y and z,
only using x itself does, because of laziness.
\begin{code}
let x = (y, z) in
case e of
  Pat1 -> … x …
  Pat2 -> … y … z …
\end{code}

If we annotate the x bound by let with a usage environment $\delta$ mapping all (free?)
variables in its binder to a multiplicity ($\delta = [y := 1, z := 1]$), we
could, upon finding x, simply emit that y and z are consumed once. When typing
the second branch we'd also see that y and z are used exactly once, hence the
linearity in the two branches match.

Currently, in GHC, we don't annotate let-bound variables with a usage
environment, but we already calculate a usage environment and use it to check
some things (which things?)

\begin{itemize}
    \item Transformations, occurrences?
    \item Recursive lets
    \item Empty case expression
\end{itemize}

What do we currently do?

When we lint a core expression, we get both its type and its usage environment.
That means that to lint linearity in an expression, whenever we come across a
free variable we compute its usage environment and take it into account

\subsection{Join Points}

When duplicating a case (in the case-of-case transformation), to avoid code
explosion, the branches of the case are first made into join points

\begin{code}
case e of
  Pat1 -> u
  Pat2 -> v
~~>
let j1 = u in
let j2 = v in
case e of
  Pat1 -> j1
  Pat2 -> j2
\end{code}

If there is any linear variable in u and v, then the standard
let rule above will fail (since j1 occurs only in one branch, and
so does j2).

However, if j1 and j2 were annotated with their usage environment,

\subsection{Recursive Lets}

Optimisations can create a letrec which uses a variable linearly. The following
example uses 'x' linearly, but this is not seen by the linter.
\begin{code}
letrec f = \case
        True -> f False
        False -> x
in f True
\end{code}

Following the idea of making let-bound variables remember the usage environment
here's an informal description that that example is well typed. We want to
anotate the let-bound variable $f$ with a usage environment delta $\delta$, and
use the binding body to compute it.

Now, how to compute the usage environment of a case expression? It's described
here if I'm not mistaken
https://gitlab.haskell.org/ghc/ghc/-/wikis/uploads/355cd9a03291a852a518b0cb42f960b4/minicore.pdf.

However, not understanding it, my take would be that we can compute the usage
environment of every branch of the case expression and make sure that they all
unify (wrt to submultiplicities). The special case is when the branch happens to
call $f$ itself while computing the usage environment of $f$. If it were another
let bound variable we'd add its own usage environment to the one we're
computing; if it were a lambda bound variable we'd add [itself $:=$ its
multiplicity].

My idea is that we can emit a special usage [$rec := p$], which, when unified
against the other case branches $\delta$ will always succeed with a unification
mapping from $rec \rightarrow p\delta$ scaled by the multiplicity of $rec$

So taking the example, to compute the usage environment of $f$, we'd compute for
the second branch $[x := 1]$ and for the first branch $[rec := 1]$. Then, we'd
unify them with $rec \rightarrow [x := 1*1]$, and somehow result in $[x := 1]$

An example which should break linearity because $x$ is not linear in the first
branch:
\begin{code}
letrec f = \case
         True -> f False + f False
         False -> x
    in f True
\end{code}

To compute the usage environment of $f$ we take the second branch usage
environment $[x := 1]$ and the first branch usage $[rec := 1+1]$ and unify them,
somehow resulting in $[x := 2]$. Now, to lint the linearity in the whole let
expression we must ensure that the body of the let uses $x$ linearly. The body
is $f True$, which is a let-bound variable (how to distinguish functions that
must be applied vs variables) so we take its usage environment $[x := 2]$ which
does not use $x$ linearly and thus breaks linearity.

\textbf{Re-explained:} to compute the usage environment of the recursive
let-bound function $f$ when applied, we compute $Z$ such that for all branch
alternatives $U,V,...$, $U \subset Z$, $V \subset Z$ and so on by tracking the
multiplicities and usage environments of variables that show up in the body and
by emitting a special keyword $rec$ everytime we find a saturated call of $f$
(how to handle unsaturated calls?) (how to have a more general solution that
doesn't require a keyword, perhaps something to do with fixed points); Then we
scale $Z \setminus \{(rec,_)\}$ by $Z[rec]$ and get $T$ which is the usage
environment of $f$ when saturated.

\textbf{Example 1 revisited:}
\begin{enumerate}
    \item Take $U = \{rec := 1\}$
    \item Take $V = \{x := 1\}$
    \item Take $Z = \{x := 1, rec := 1\}$
    \item Take $\pi = Z[rec] = 1$
    \item Take $W = Z \setminus \{rec\} = \{x := 1\}$
    \item Take $T = \pi W = \{x := \pi * 1\} = \{x := 1\}$
    \item Linearity OK
\end{enumerate}

\textbf{Example 2 revisited:}
\begin{enumerate}
    \item Take $U = \{rec := 2\}$
    \item Take $V = \{x := 1\}$
    \item Take $Z = \{x := 1, rec := 1\}$
    \item Take $\pi = Z[rec] = 2$
    \item Take $W = Z \setminus \{rec\} = \{x := 1\}$
    \item Take $T = \pi W = \{x := \pi * 1\} = \{x := 2\}$
    \item Linearity not OK
\end{enumerate}

\subsection{Empty Case}

For case expressions, the usage environment is computed by checking all branches
and taking sup. However, this trick doesn't work when there are no branches.

\begin{itemize}
\item https://gitlab.haskell.org/ghc/ghc/-/issues/20058
\item https://gitlab.haskell.org/ghc/ghc/-/issues/18768

\item (1) Just like a case expression remembers its type (Note [Why does Case have a
'Type' field?] in Core.hs), it should remember its usage environment. This data
should be verified by Lint.

\item (2) Once this is done, we can remove the Bottom usage and the second field of
UsageEnv. In this step, we have to infer the correct usage environment for empty
case in the typechecker.
\end{itemize}

\begin{code}
{-# LANGUAGE LinearTypes, EmptyCase #-}
module M where

{-# NOINLINE f #-}
f :: a %1-> ()
f x = case () of {}
\end{code}

This example is well typed: a function is linear if it consumes its argument
exactly once when it's consumed exactly once. It seems like the function isn't
linear since it won't consume x because of the empty case, however, that also
means f won't be consumed due to the same empty case, thus linearity is
preserved.

\begin{code}
* In the case of empty types (see Note [Bottoming expressions]), say
  data T
we do NOT want to replace
  case (x::T) of Bool {}   -->   error Bool "Inaccessible case"
because x might raise an exception, and *that*'s what we want to see!
(#6067 is an example.) To preserve semantics we'd have to say
   x `seq` error Bool "Inaccessible case"
but the 'seq' is just such a case, so we are back to square 1.
\end{code}

There are three different problems:

\begin{itemize}
\item castBottomExpr converts (case x :: T of {}) :: T to x.
\item Worker/wrapper moves the empty case to a separate binding
\item CorePrep eliminates empty case, just like point 1 (See -- Eliminate empty
    case in GHC.CoreToStg.Prep
\end{itemize}

With castBottomExpr, we get the example above to
\begin{code}
    f = \ @a (x (%1) :: a) -> ()
\end{code}
And if we don't, 
\begin{code}
    f = \ @a (x (%1) :: a) -> case () of {}
\end{code}
And that supposedly if we had a usage environment in the case expression we
could avoid the error. How is it typed without the transformation in face
of the bottom? (Even knowing that theoretically it's because of divergence?)



\section{Multiplicity Coercions}

The second set of problems arises from our inability to coerce a multiplicity
into another (or say that one is submultiple of another?).

When we pattern match on a GADT we ...

Taking this example (copy example over) we can see that we don't know how to say
that x is indeed linear in one case and unrestricted in the other, even though
it is according to its type. We'd need some sort of coercion to coerce through
the multiplicity to the new one we uncover when we pattern match on the GADT
evidence (...)

\begin{code}
data SBool :: Bool -> Type where
  STrue :: SBool True
  SFalse :: SBool False

type family If b t f where
  If True t _ = t
  If False _ f = f

dep :: SBool b -> Int %(If b One Many) -> Int
dep STrue x = x
dep SFalse _ = 0
\end{code}

\end{document}


