\documentclass[acmsmall,review,anonymous,screen]{acmart}
\PassOptionsToPackage{dvipsnames}{xcolor}
\usepackage{boldline}
\usepackage{xcolor}
\usepackage{xargs}
\usepackage{framed}
\usepackage[framemethod=default]{mdframed}
\usepackage{mathpartir}
\usepackage{mathtools}
\usepackage{soul}
\usepackage{cmll} % ROMES:TODO: not allowed?
\usepackage{amsthm}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{cleveref}
\usepackage{makecell}
\usepackage{fancyvrb}
\usepackage{thmtools, thm-restate}
\usepackage{listings}
\usepackage{todonotes}
\usepackage[justification=centering]{subfig}

%\newtheorem{theorem}{Theorem}
%\newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}%[theorem]
%\newtheorem{lemma}{Lemma}%[theorem]
%\newtheorem{sublemma}{Lemma}[lemma]
%\newtheorem{assumption}{Assumption}

%%%%%%%%%%%%%%  Color-related things   %%%%%%%%%%%%%%

% Work around lhs2tex#82
\let\Bbbk\undefined

%include polycode.fmt
%format ⊸ = "\lolli"

% don't, for now
%%%%subst keyword a = "\textcolor{BlueViolet}{\textbf{" a "}}"

\newcommand{\myFor}[2]{\For{$#1$}{$#2$}}
\newcommand{\id}[1]{\textsf{\textsl{#1}}}

\newcommand{\incode}[1]{\lstinline{#1}}

% \renewcommand{\Varid}[1]{\textcolor{Sepia}{\id{#1}}}
% \renewcommand{\Conid}[1]{\textcolor{OliveGreen}{\id{#1}}}

%%%%%%%%%%%%  End of Color-related things   %%%%%%%%%%%%

% It might make sense to add pretty formating of individual things
% like "forall", cf.
% https://github.com/goldfirere/thesis/blob/master/tex/rae.fmt

% colorboxes, from rae's thesis as well
\definecolor{working}{rgb}{0.9,1,0.9}
\newmdenv[hidealllines=true,backgroundcolor=working,innerleftmargin=0pt,innerrightmargin=0pt,innertopmargin=-3pt,innerbottommargin=-3pt,skipabove=3pt,skipbelow=3pt]{working}
\newcommand{\workingcolorname}{light green}

\definecolor{notyet}{rgb}{1,1,0.85}
\newmdenv[hidealllines=true,backgroundcolor=notyet,innerleftmargin=0pt,innerrightmargin=0pt,innertopmargin=-3pt,innerbottommargin=-3pt,skipabove=3pt,skipbelow=3pt]{notyet}
\newcommand{\notyetcolorname}{light yellow}

\definecolor{noway}{rgb}{1,0.9,0.9}
\newmdenv[hidealllines=true,backgroundcolor=noway,innerleftmargin=0pt,innerrightmargin=0pt,innertopmargin=-3pt,innerbottommargin=-3pt,skipabove=3pt,skipbelow=3pt]{noway}
\newcommand{\nowaycolorname}{light red}

\definecolor{limitation}{rgb}{1.0, 0.875, 0.75}
\newmdenv[hidealllines=true,backgroundcolor=limitation,innerleftmargin=0pt,innerrightmargin=0pt,innertopmargin=-3pt,innerbottommargin=-3pt,skipabove=3pt,skipbelow=3pt]{limitation}
\newcommand{\limitationcolorname}{light orange}

\DefineVerbatimEnvironment{code}{Verbatim}{fontsize=\small}
\DefineVerbatimEnvironment{example}{Verbatim}{fontsize=\small}

\newcommand{\parawith}[1]{\paragraph{\emph{#1}}}
\newcommand{\lolli}{\multimap}
\newcommand{\tensor}{\otimes}
\newcommand{\one}{\mathbf{1}}
\newcommand{\bang}{{!}}

\newcommand{\llet}[2]{\mathsf{let}~#1~\mathsf{in}~#2}
\newcommand{\lletrec}[2]{\mathsf{letrec}~#1~\mathsf{in}~#2}
\newcommand{\ccase}[2]{\mathsf{case}~#1~\mathsf{of}~#2}

\definecolor{darkblue}{rgb}{0,0,0.5}
\definecolor{darkgreen}{rgb}{0,0.3,0}
\definecolor{darkpink}{rgb}{0.4,0,0.3}
\definecolor{graygreen}{rgb}{0.3,0.5,0.3}
\definecolor{grayblue}{rgb}{0.2,0.2,0.6}
\definecolor{grayred}{rgb}{0.5,0.2,0.2}

\lstset{
  frame=none,
  xleftmargin=2pt,
  stepnumber=1,
  %numbers=left,
  %numbersep=5pt,
  numberstyle=\ttfamily\tiny\color[gray]{0.3},
  belowcaptionskip=\bigskipamount,
  captionpos=b,
  escapeinside={*'}{'*},
  language=haskell,
  tabsize=2,
  emphstyle={\bf},
  commentstyle=\it,
  stringstyle=\mdseries\rmfamily,
  showspaces=false,
  keywordstyle=\bfseries\rmfamily\color{darkblue}, 
  columns=flexible,
  basicstyle=\small\sffamily,
  showstringspaces=false,
  morecomment=[l]\%,
}

\input{proof}
\input{language-v2/proof}
\input{language-v3/proof}
\input{language-v4/proof}
\input{language-v4/Syntax}
\input{language-v4/TypingRules}
\input{language-v4/TheoremsAndLemmas}

\title{Semantic Linearity in a Lazy Optimising Compiler}
\subtitle{Type-checking Linearity in GHC Core}

\author{Rodrigo Mesquita}
\affiliation{
  \department{Departamento de Inform\'{a}tica}
  \institution{FCT-NOVA, Universidade Nova de Lisboa}
  %\city{City}
  \country{Portugal}}
\affiliation{
   \institution{Well-Typed LLP}
  %\city{City}
  %\country{Something}
 }
 \email{xxx@yyy.com}
\author{Bernardo Toninho}
\orcid{0000-0002-0746-7514}
\affiliation{
  \department{Departamento de Inform\'{a}tica}
  \institution{NOVA-LINCS, FCT-NOVA, Universidade Nova de Lisboa}
  %\city{City}
  \country{Portugal}}
\email{btoninho@fct.unl.pt}
%% TODO: AFFILIATION, EMAIL
%% TODO: CCS CONCEPTS and KEYWORDS
%% TODO: ACM RIGHTS notice...
% CHECK: https://www.acm.org/binaries/content/assets/publications/taps/latex-best_practices-06-may-2020.pdf

% \date{ }

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10003790.10003801</concept_id>
       <concept_desc>Theory of computation~Linear logic</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003790.10011740</concept_id>
       <concept_desc>Theory of computation~Type theory</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006.10011008.10011009.10011012</concept_id>
       <concept_desc>Software and its engineering~Functional languages</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006.10011041</concept_id>
       <concept_desc>Software and its engineering~Compilers</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Linear logic}
\ccsdesc[500]{Theory of computation~Type theory}
\ccsdesc[500]{Software and its engineering~Functional languages}
\ccsdesc[500]{Software and its engineering~Compilers}


\keywords{Linear Types, Lazy Evaluation, Haskell, GHC Core}

\begin{document}

\begin{abstract}
Linear type systems guarantee linear resources are used exactly once.
Traditionally, using a resource is synonymous with its \emph{syntactic}
occurrence in the program, however, under the lens of non-strict evaluation,
linearity can be further understood \emph{semantically}, where a
syntactic occurrence of a resource does not necessarily entail
using that resource when the program is executed.
Semantic linearity becomes especially vital when considering the
internal language of an optimising compiler, where optimisations
heavily rewrite the source program in ways that can often break
syntactic linearity but that aim to preserve the program's semantics.
% %
% Semantic linearity is especially necessary in optimising compilers for
% languages combining linearity and laziness: optimisations leverage laziness to
% heavily rewrite the source program, pushing the interaction of linearity and
% laziness to its limit, regardless of the original program typing linearity
% conservatively.
%

We present Linear Core, the first type system that understands semantic
linearity in the presence of non-strict evaluation, suitable for the Core
intermediate language of the Glasgow Haskell Compiler. We prove Linear Core
is sound and guarantees linear resource usage and prove multiple optimising
transformations preserve linearity in Linear Core while failing to do so in
Core. We have implemented Linear Core as a compiler plugin to validate the
system against linearity-heavy libraries, including
\texttt{linear-base}.%^, in the heart of the compiler.
\end{abstract}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}

% Statically safe programming languages provide compile time correctness
% guarantees by having the compiler rule out certain classes of errors
% or invalid programs. Moreover, static typing
% allows programmers to state and enforce (compile-time) invariants
% relevant to their problem domain.
% In this sense, type safety entails that all
% possible executions of a type-correct program cannot exhibit behaviors
% deemed ``wrong'' by the type system design. This idea is captured in
% the motto ``well-typed programs do not go wrong''.%~\cite{}.

Linear types~\cite{cite:linear-logic,cite:barberdill} increase the expressiveness
of type systems by allowing them to enforce that certain resources (e.g.~a
file handle) are used \emph{exactly once}.
%
In programming languages with a linear type system, not using certain resources
or using them twice is flagged as a type error. For instance, linear types can
statically enforce correct usage of file or socket descriptors, or
that heap-allocated memory is freed exactly once (i.e.,~leaks and double-frees become
type errors), or even guarantee deadlock freedom in channel-based communication
protocols~\cite{10.1007/978-3-642-15375-4_16},
% implement safe
% high-performance language interoperability~\cite{}, 
%guarantee that quantum entangled states are not duplicated~\cite{}
among other correctness properties~\cite{10.1145/3373718.3394765,10.1145/3527313,cite:linearhaskell}.
% handle mutable state safely~\cite{}
%
The following program with a runtime error (allocated memory is freed twice) is
accepted by a C-like type system. Conversely, under the lens of a linear type
system where $p$ is deemed a linear resource created by the call to
\texttt{malloc}, the program is rejected:
% We know this to be the dreaded double-free error which will crash the program at runtime.
% \centering
\begin{code}
let p = malloc(4); in free(p); free(p);
\end{code}

Despite their promise and extensive presence in research
literature~\cite{Wadler1990LinearTC,CERVESATO2000133,10.1093/logcom/2.3.297},
an effective design combining linear and non-linear typing is both
challenging and necessary to bring the advantages of linear typing to
mainstream languages.
%
Consequently, few general purpose programming languages have linear
type systems. Among them are Idris~2~\cite{brady:LIPIcs.ECOOP.2021.9},
% a linearly and dependently typed language based on Quantitative Type Theory,
Rust~\cite{10.1145/2692956.2663188}, a language whose
ownership types build on linear types to guarantee memory safety
without garbage collection, and, more recently,
Haskell~\cite{cite:linearhaskell}, a pure, functional, and
\emph{lazy} general purpose programming language.
%
% Besides Haskell's supporting linear
% types according to the said paper, Idris 2\cite{} supports linear types in a
% dependently typed setting, Clean\cite{} has uniqueness types which are closely
% related to linear types, and Rust\cite{} has ownership types which build from
% linear types. 
%

However, linearity in Haskell stands out from linearity in other
languages because linear types permeate Haskell down to (its) Core, the
intermediate language into which Haskell is translated by the Glasgow Haskell Compiler (GHC).
%
Core is a minimal, explicitly typed, functional language to which multiple
Core-to-Core optimising transformations are applied during compilation.
%
Typechecking Core serves as a sanity check to the correction of such
transformations, since unsound ones are likely to introduce ill-typed
expressions. %, making them easy to spot.
%
% If a Core program fails to typecheck, the
% optimising transformations are very likely to have introduced an error in the
% resulting program.
%

Both Haskell and its intermediate language Core are lazily
        evaluated.
        % -- expressions in Haskell are only evaluated when needed.
        As we make clear in this paper, \emph{non-strict evaluation interacts non-trivially with linearity}.
        Intuitively, a syntactic occurrence of a linear resource does not
        necessarily entail consuming that resource since expressions are not
        necessarily evaluated (i.e., if the expression is not evaluated, the
        resource is not used).
        %
        Under eager evaluation, a syntactic occurrence of a resource
        along a given control-flow path always implies its use at runtime.
        %
        % Under eager/call-by-value evaluation, the distinction between syntactic uses of a
        % resource and the actual use of linear resources at runtime does not exist --
        % an occurrence of a variable in the program always entails consuming it.
        %

        % Include?
        % This interaction is unique to Haskell since, to the best of
        % our knowledge, it is the
        % only language featuring both laziness and linearity.

Just as Core's type system provides a degree of validation to the
translation from Haskell (dubbed \emph{desugaring}) and the subsequent
optimising transformations, a linearly typed Core would guarantee that
linear resource usage in the source language is not violated by desugaring
and the compiler optimisation passes. Moreover, linearity information in
Core can inform Core-to-Core optimising 
transformations~\cite{cite:let-floating,peytonjones1997a,cite:linearhaskell},
such as inlining and $\beta$-reduction, to produce more efficient programs.
%
% It is crucial that a program's behaviour enforced by linear types is \emph{not}
% changed by the compiler in the desugaring or optimisation stages (optimisations
% should not destroy linearity!) and a linearity aware Core type-checker is key in
% providing such guarantees -- it would be disastrous if the compiler, e.g.,
% duplicated a pointer to heap-allocated memory that was previously just used
% once and then freed in the original program.
%TODO: linearidade pode informar otimizacoes
%
% Even more, linearity in Core can inform Core-to-Core optimising
% transformations~\cite{cite:let-floating,peytonjones1997a,cite:linearhaskell},
% including inlining and $\beta$-reduction, to produce more performant programs.

% Linear core actually not so good
% Additionally, while not yet a reality, linearity in Core could be used to inform
% certain program optimisations, i.e. having linear types in Core could be used to
% further optimise certain programs and, therefore, benefit the runtime
% performance characteristics of our programs. For example, Linear Haskell\cite{}
% describes as future work an improvement to the inlining optimisation: Inlining
% is a centerpiece program optimisation primarily because of the subsequent
% optimising opportunities unlocked by inlining. However, it relies on a heuristic
% process known as \emph{cardinality analysis} to discover safe inlining
% opportunities. Unfortunately, heuristics can be volatile and fail in identifying
% crucial inlining opportunities resulting in programs that fall short of their
% performance potential. On the contrary, the linearity information could be
% integrated in the analysis and used as a (non-heuristic) cardinality
% \emph{declaration}.

% While the current version of Core is linearity-aware (i.e.,~Core has so-called
% multiplicity annotations in variable binders), its type system does not (fully)
% validate the linearity constraints in the desugared program and essentially
% fails to type-check programs resulting from several optimising transformations
% that are necessary to produce efficient object code. The reason for this latter
% point is not evidently clear:
% %
% if we can typecheck linearity in the surface level Haskell why do we fail to do
% so in Core?
%

Despite the advantages of a linearly typed Core, the status quo is
that linearity is effectively ignored in Core, being only checked
in the source Haskell code. The reason is that the desugaring
and subsequent Core-to-Core optimising transformations
eliminate and rearrange most of the syntactic constructs through
which linearity checking is performed -- often resulting in programs
that are syntactically very different from the original, especially
due to the flexibility provided by laziness wrt the
optimisations a compiler may perform.

While compiler optimisations aim to preserve the semantics of
programs and therefore a program's linear resource consumption,
a \emph{naive} syntactic analysis of the optimised programs (as
performed by the current Core type checker) often fails to recognize
the program as linear.
%
As a trivial example, let $x$ be a linear resource in the next two expressions,
where the latter results from inlining $y$ without eliminating the binder. Even
though the second expression no longer appears linear (as there are now two occurrences
of $x$), it is indeed linear because the let-bound expression is never
evaluated and $x$ is still consumed exactly once (when it is freed in the let body):
% executed, $x$ will be freed exactly once:
%
% , \emph{is} linear, as the let bound expression freeing $x$
% is never evaluated (because is not needed) -- thus $x$ is only consumed once
% when freed in the let body:
\[
\begin{array}{ccc}
\llet{y = \textsf{free}~x}{y} & \Longrightarrow_{Inlining} & \llet{y = \textsf{free}~x}{\textsf{free}~x}
\end{array}
\]

% \begin{boxedminipage}
% \begin{code}
% let y = free x
% in free x
% \end{code}
% \end{boxedminipage}

The Core optimising transformations expose a fundamental limitation of Core's
linear type system: it does not account for the non-strict evaluation model
of Core and, thus, a whole class of programs that are linear under the lens of
non-strict evaluation are rejected by Core's current linear type system.
%
In this work, we address this limitation by exploring how syntactic linearity
breaks down in the presence of non-strictness and designing a type system which,
derived from our observations, accepts the vast majority of valid non-strict
programs and optimising transformations previously rejected by traditional
linear typing disciplines. Additionally, we show our system
%
% and its implications on validating and influencing optimising transformations
% by designing a type system which analyses how syntactic linearity breaks down
% in the presence of laziness
is suitable for the intermediate language of an
optimising compiler by implementing it as a Glasgow Haskell Compiler plugin.
%
Our contributions are as follows:
%
\begin{itemize}

\item We introduce the concept of \emph{semantic} linearity, in
contrast to \emph{syntactic} linearity in Haskell, by example
(Section~\ref{sec:linearity-semantically}).

\item We introduce Linear Core, a non-strict linear language with
the key features of Core (except for type equality coercions), whose type system
accounts for semantic linearity in the presence of laziness. To the
best of our knowledge, this is the first type system to capture linearity
semantically in this context
(Section~\ref{sec:main:linear-core}).

\item We prove our type system is sound, guarantees linear resource usage, and
    prove that multiple optimising transformations, which are rejected in Core,
        are validated by Linear Core (Section~\ref{sec:main:metatheory}).

\item We discuss our implementation of Linear Core as a GHC
  plugin\footnote{We plan to submit our implementation as a companion
    artifact to this paper.} which checks linearity in
all intermediate Core programs produced during the compilation process, showing
it accepts the programs resulting from transformations in libraries such as
\texttt{linear-base} (Section~\ref{sec:discuss:implementation}).

\end{itemize}

\noindent Additional proofs and definitions are given in
Appendices~\ref{app:proofs},~\ref{app:optimisations} and~\ref{app:opsem}.

%
% We review background concepts fundamental to our work in
% Section~\ref{sec:background}, including linear type systems, linear types in
% Haskell, evaluation strategies, Core's type system, and multiple optimising
% transformations applied by GHC in its compilation process.
%
% We compare our contributions to related work and discuss possible
% avenues for further research
% (highlighting so-called
% \emph{multiplicity coercions})
% in Section~\ref{sec:discussion}, which concludes the document.

% In fact, we are not aware of any linear type system which
% understands linearity in the presence of laziness.

% \todo[inline]{In reality, the Core optimising transformations only expose a
% more fundamental issue in the existing linear types in Haskell -- its mismatch
% with the evaluation model. In call-by-need languages a mention of a variable
% might not entail using that variable - it depends on it being required or not.
% We're the first to do so as far as we know}

% Concluding, by extending Core / System $F_C$ with linearity and multiplicity
% annotations such that we can desugar all of Linear Haskell and validate it
% accross transformations taking into consideration Core's call-by-need
% semantics, we can validate the surface level linear type's implementation, we
% can guarantee optimising transformations do not destroy linearity, and we might
% be able to inform optimising transformations with linearity.

% Consider the following recursive let
% definition, where $x$ is a linear variable that must be used exactly once, would
% not typecheck in a source Haskell program since the typechecker cannot tell that
% $x$ is used linearly, but this program might occur naturally in Core from
% transformations on a program that did succesfully typecheck:
% \begin{code}
% letrec f = \case
%         True -> f False
%         False -> x
% in f True
% \end{code}

% Alternatively, one might imagine Haskell being desugared into an intermediate
% representation to which multiple different optimising transformations are
% applied but on which no integrity checks are done

% Despite \emph{want} a linearly-typed core
% because a linearly-typed Core ensures that desugaring
% Haskell and optimising transformations don't destroy linearity.

% In theory, because the Core language must also know about linearity, we should

% A remedy is to use the multiplicity annotations of λq → as cardinality declarations. Formalising
% and implementing the integration of multiplicities in the cardinality analysis is left as future work.

% In theory, we should typecheck \emph{linearity} in \textbf{Core} just the same
% as the typechecking verification we had with the existing type annotations prior
% to the addition of linear types, that is, our Core program with linearity
% annotations should be typechecked after the optimising transformations...

% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Linearity, Semantically
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Linearity, Semantically\label{sec:linearity-semantically}}

A linear type system statically guarantees that linear resources are
consumed exactly once. Consequently, whether a program is
well-typed under a linear type system intrinsically depends on the
definition of consuming a resource.
In general, consuming a resource is equated with its 
\emph{syntactic occurrence} along a control-flow path in the program. However, as this section
makes clear, in linear type systems for non-strict
languages, a distinction between using
resources \emph{syntactically} and \emph{semantically} is needed.
%
For instance, in the following Haskell-like program, there are two syntactic
occurrences of \lstinline{handle}: one is in a let-bound computation that
closes this handle, the other is returned. If the program is evaluated lazily,
the handle will not be closed because the computation that closes the handle is
never evaluated (\lstinline{x} goes unused).
%
\begin{lstlisting}
f : Handle *' $\lolli$ '* Handle
f handle = let x = close handle in handle
\end{lstlisting}
%
% Intuitively, a computation that depends on a linear resource to produce a
% result consumes that resource iff the result is effectively computed; in
% contrast, a computation that depends on a linear resource, but is never run,
% will not consume that resource.
%
% Even though there are two occurrences of \lstinline{handle} in the program, and
% it looks as though the \lstinline{handle} may be closed before returned, this function may
% actually only \emph{consume} used once -- it depends on the evaluation strategy of the
% language -- the \lstinline{handle} is closed iff the let bound computation is
% evaluated.
%
%
% Intuitively, \emph{consuming} a resource is not necessarily synonymous with its
% syntactic occurrence. In the example, \emph{non-strict} evaluation means the
% handle is never closed by the function.
%
%
% Depending on the evaluation strategy of the language, a computation that closes
% a handle might not be evaluated, and thus is not consumed.
% With \emph{eager} evaluation semantics,
% the let
%   bound expression \lstinline{close handle} is eagerly evaluated, and the \lstinline{handle} will be closed before being
% returned. It is clear that a linear type system should not accept such a
% program since the linear resource \lstinline{handle} is duplicated -- it is used in a
% computation that closes it, while still being made available to the caller of
% the function;
% %
% on the other hand, with \emph{call-by-need},
%
% Reconsider the \lstinline{handle} example program under
% \emph{call-by-need} evaluation semantics:
% The let bound expression is only evaluated if the binding \lstinline{x} is
% needed. The function returns the \lstinline{handle} right away, and forgets the
% let bound \lstinline{x} as its scope is exited, such that \lstinline{x} will
% never be needed -- consequently, the \lstinline{handle} is never closed by the
% function...
%
%
%

%Under the lens of non-strict evaluation, a syntactic
%occurrence of a resource in an expression only entails consuming that resource
%iff the expression itself is fully consumed.
%
Intuitively, a computation that depends on a linear resource to produce a
result consumes that resource iff the result is fully consumed; in
contrast, a computation that depends on a linear resource, but is never run,
will not consume that resource.
%
We argue that a linear type system for a language with non-strict evaluation
semantics should accept the above program, unlike a linear type system for the
same program if it were to be evaluated eagerly.
%
Given this observation, %and exploring the connection between computation and evaluation,
% it becomes clear that \emph{linearity} and \emph{consuming resources}, in the
% above example and for programs in general, should be defined in function of the
% language's evaluation strategy.
%
we turn our focus to linearity under lazy evaluation since the distinction between semantically and syntactically
consuming a resource is only exposed under non-strict semantics (and since GHC Core is
lazy).
%. 


% Indeed, under \emph{call-by-value}, syntactic occurrences of a linear resource
% directly correspond to semantically using that resource\footnote{With the minor exception
% of trivial aliases, which don't entail any computation even in
% \emph{call-by-value}. In theory, we could use in mutual exclusion any of the
% aliases to refer to a resource without loss of linearity} because \emph{all}
% expressions are eagerly evaluated -- if all computations are eagerly run, all
% linear resources required by computations are \emph{eagerly consumed}.

% ROMES:IMPORTANT:TODO:
% \subsection{Reductions / Function applications}
% 
% \todo[inline]{unrestricted call-by-name with resources can duplicate the resources, as if it were unsound?}
% We reduce function applications in two distinct ways, call by name (for linear
% functions) and call by need (we've now introduced linear lets, so we can look
% at this now)
% 
% Foreshadow to issues with opt (reverse binder swap)?
% 
% Or maybe just drop this section altogether

\subsection{Semantic Linearity by Example\label{sec:semantic-linearity-examples}}

This section aims to develop an intuition for semantic linearity through simple
Core programs that can be understood as linear but are rejected by Core's
linear type system (or, in fact, by all linear type systems we are
aware of prior to this work).
%
% Needed?
%Aligned with our motivation of typing linearity in GHC Core such
%that optimising transformations preserve linearity, and with the goal
%of understanding linearity in a non-strict context,
%
% BETTER?:
%Aligned with our motivation of typechecking linearity in GHC Core such
%that optimising transformations preserve linearity, and in order to explain
%linearity in a non-strict context, we illustrate semantic linearity
%through examples of Core programs that are semantically linear but rejected by
%Core's linear type system -- building intuition towards semantic linearity in a
%lazy language.
%
In the examples, a \colorbox{working}{\workingcolorname} background highlights
programs that are syntactically linear and accepted by Core's linear type
system.
%
A \colorbox{notyet}{\notyetcolorname} or
\colorbox{limitation}{\limitationcolorname} background mark programs that are
semantically linear, but not seen as linear by Core's type system.
%
Notably, the linear type system we develop in this work accepts all
\colorbox{notyet}{\notyetcolorname} programs.
%
% (while the few \colorbox{limitation}{\limitationcolorname} programs are not accepted).
A \colorbox{noway}{\nowaycolorname} background indicates that the program
violates linearity semantically, i.e.~the program effectively
discards or duplicates linear resources.

% We discuss recursive and recursive let bindings, and case expressions.

%\todo{Should we have a subsection starting with simple function application?}

\paragraph{Let bindings}
% We start our discussion with non-strict (non-recursive) let bindings, i.e. let bindings whose
% body is evaluated only when the binding is needed, rather than when declared.
%
% In Core, let bindings entail creating \emph{thunks} that suspends the
% evaluation of the let body.
% % (for background, see
% % Section~\ref{sec:background:evaluation-strategies})
% When the binding itself is evaluated, the \emph{thunk} is
% \emph{forced} and the evaluation is carried out. The result overwrites the
% \emph{thunk} -- the let binding now points to the result of the evaluation.
%
% A \emph{thunk} is \emph{forced} (and the suspended computation is evaluated) when
% the binding itself is evaluated.
%
%\begin{notyet}
% \begin{lstlisting}
% f1 :: (a *' $\lolli$ '* b) -> a *' $\lolli$ '* b
% f1 use x = let y = use x in y
% \end{lstlisting}
% \end{notyet}
% In a linear type system, a non-strict let binding that depends on a linear
% resource \lstinline{x} doesn't consume the resource as long as the binding isn't
% evaluated -- the suspended computation only uses the resource if it is run. For
% this reason, we can't naively tell whether \lstinline{x} is consumed just by looking at
% the let binding body. In the following example, we assign a computation that
% depends on the resource \lstinline{x} to a binder, which is then
% returned.
%
% \begin{figure}
%   \begin{minipage}{.33\textwidth}
%     \begin{notyet}
% \begin{lstlisting}
% f1 :: (a *' $\lolli$ '* b) -> a *' $\lolli$ '* b
% f1 use x = let y = use x in y
% \end{lstlisting}
% \end{notyet}
% \caption{one}
% \end{minipage}%
% \begin{minipage}{.33\textwidth}
%       \begin{notyet}
% \begin{lstlisting}
% f2 :: (a *' $\lolli$ '* a) -> a *' $\lolli$ '* a
% f2 use x = let y = use x in use x
% \end{lstlisting}
% \end{notyet}
% \caption{two}
% \end{minipage}%
% \begin{minipage}{.33\textwidth}
% \begin{notyet}
% \begin{lstlisting}
% f3 :: (a *' $\lolli$ '* a) -> Bool -> a *' $\lolli$ '* a
% f3 use bool x =   let y = use x in
%    case bool of
%       True -> x
%       False -> y
% \end{lstlisting}
% \end{notyet}
% \caption{Three}
% \end{minipage}%
% \end{figure}
%
%
%
%
% %
% The linear resource \lstinline{x} is used exactly once, since it is used exactly once in
% the body of the binding and the binding is used exactly once in the let body.
% %
% According to Linear Haskell's core calculus~$\lambda_{\to}^{q}$~\cite{cite:linearhaskell}, let
% bound variables are annotated with a multiplicity which is multiplied (as per
% the multiplicity semiring) by the multiplicity of all variables that are free
% in the binder's body.
% %
% In short, if a let binder is linear (has
% multiplicity $1$) then the linear variables free in its body are only used
% once; if the let binder is unrestricted (has multiplicity $\omega$) then the
% resources in its body are consumed many times, meaning no linear variables can
% occur in that let binder's body.
% %
% Unfortunately, GHC's implementation of Linear
% Haskell doesn't seem to infer multiplicities for lets yet, so while the above
% program should typecheck in Linear Haskell, it is rejected by GHC.

% The next example exposes the case in which the let binder is ignored in the let
% body. Here, the linear resource \incode{x} is used in \incode{y}'s body and in the let
% body, however, the resource is still used semantically linearly
% because \incode{y} isn't used at all, thus \incode{x} is consumed just
% once in the let body: 
% %
% \begin{notyet}
% \begin{lstlisting}
% f2 :: (a *' $\lolli$ '* a) -> a *' $\lolli$ '* a
% f2 use x = let y = use x in use x
% \end{lstlisting}
% \end{notyet}
% %
% Programmers don't often write bindings that are completely unused, yet, an
% optimising compiler will produce intermediate programs with unused bindings\footnote{Unused bindings are then
% also dropped by the optimising compiler} 
% from transformations such as inlining, which can substitute out occurrences
% of the binder (e.g. \incode{y} is inlined in the let body).

The example at the start of Section~\ref{sec:linearity-semantically}
% (similar to towards the end of Section~\ref{sec:intro}),
highlighted the subtlety of linearity in a non-strict language with
a single unused let binding.
%
%Less trivially,
In general, a let-bound expression that captures a linear variable
can be conditionally needed at runtime, depending on the branch taken.
Both optimising transformations (float-out) and programmers used to
non-strict evaluation are keen to write programs with bindings that are selectively
used in case alternatives, such as:
%
\begin{notyet}
\begin{lstlisting}
f :: (a *' $\lolli$ '* a) -> Bool -> a *' $\lolli$ '* a
f use bool x = let y = use x in
  case bool of
    True -> x 
    False -> y
\end{lstlisting}
\end{notyet}
%
This example returns \lstinline{x} in one branch and the let-bound
\lstinline{y} in the other. Semantically, as opposed to syntactically, this
program is linear % (i.e. linear resources are used exactly once)
because the linear resource \lstinline{x} is used exactly once regardless of which branch is
taken: either directly in the \lstinline{True} branch, or \emph{via} the
let-bound \lstinline{y} in the \lstinline{False} branch.

That said, a let-bound \lstinline{y} that captures a linear resource
\lstinline{x} must still be used exactly once, regardless of whether evaluation
inlines the let (\emph{à la} call-by-name) or creates a thunk (\emph{à
  la} call-by-need):
%
% \lstinline{y} must still be used exactly once.  When \lstinline{y} is inlined
% in the body, this is trivial to see since multiple occurrences of will be 
%
\begin{noway}
\begin{lstlisting}
f1 :: (a *' $\lolli$ '* b) -> a *' $\lolli$ '* (b, b)
f1 use x = let y = use x in (y, y)
\end{lstlisting}
\end{noway}
%
If \lstinline{y} is inlined, linearity is trivially violated.
%
On the other hand, if \lstinline{y} becomes a thunk, \lstinline{use x} will
only be evaluated once regardless of how many times \lstinline{y} is used.
Even so, this program must be rejected under call-by-need.
%
Intuitively, linearity is violated if the computation leaks the resource or
parts of it. For instance, if \lstinline{use = id}, the program must clearly be
rejected.
%
% TODO:NEW: Include?
% If the computation fully consumed the linear resource to produce an
% unrestricted result which was forced, the binding could be shared...
% OLD Indeed, if the result of the computation involving the linear resource
% was instead, e.g., an unrestricted integer, then sharing the result would not
% involve consuming the resource more than once.
%
%
% Redundant?
% In short, the result of evaluating a let-binder's body which depends on linear resources,
% if computed, must be consumed exactly once, or, otherwise, we risk discarding
% or duplicating (the parts of) the resources that were captured in the result.

Lastly, consider a (ill-typed) program which defines two let bindings \incode{z} and \incode{y}, where
\incode{z} uses \incode{y} which in turn uses the linear resource \incode{x}:
%
\begin{noway}
\begin{lstlisting}
f2 :: (a *' $\lolli$ '* a) -> a *' $\lolli$ '* ()
f2 use x = let y = use x in let z = use y in ()
\end{lstlisting}
\end{noway}
%
Even though the binding \incode{y} is used in \incode{z}, \incode{x} is never
consumed because \incode{z} isn't evaluated in the let body, and, thus,
\incode{y} isn't evaluated either. We use this example to highlight that even
for let-bound variables, the syntactic occurrence of a variable isn't enough to
determine whether it is used. Instead, we ought to think of uses of \incode{y}
as implying using \incode{x}, and therefore uses of \incode{z} imply using
\incode{x}, however, if neither are used, then \incode{x} isn't used. Since
\incode{x} is effectively discarded, this example also violates linearity.

% \parawith{Summary}
% The examples so far build an intuition for semantic linearity in the presence
% of lazy let bindings. 
In essence, an unused let binding doesn't consume any resources, and a let
binding used exactly once consumes the resources it captures exactly once. Let
binders that depend on linear resources must be used \emph{at most once} in
mutual exclusion with the linear resources themselves (in a sense,
let-bound variables are affine in the let body).
%
%Moreover, if the let binding \incode{y} isn't used in the let body, then the
%resources it depends on ($\ov{x}$) must still be used -- the binding $y$ is
%mutually exclusive with the resources $\ov{x}$ (for the resources to be used
%linearly, either the binder occurs exactly once $y$, or the resources $\ov{x}$
%do).
%
We discuss how to encode this principle between let bindings and their dependencies using so called \emph{usage
environments}, in Section~\ref{sec:usage-environments}.

%\vspace{-.5cm}
\paragraph{Recursive let bindings\label{sec:semantic-linearity-examples:recursive-lets}}

%Recursive lets behave similarly to non-recursive let bindings in the sense we
%must use them \emph{at most once} because, when evaluated, the linear resources
%used in the binders bodies are consumed.
%

Recursive let-bindings
%, i.e. bindings with definitions that recursively depend on the bindings they define,
behave similarly to non-recursive lets as far as their usage in the let
continuation is concerned.
%recursive lets must still be used at most once, in mutual exclusion with the
%linear resources they capture.
%
The challenge lies in understanding linearity in the definitions of the
recursive binders and determining which resources are consumed when one of the
binders in the recursive group is used.
%
% The same way that, in a let body, evaluating
% a binding that uses some resource exactly once consumes that resource once,
% using the binding in its own definition also entails using that resource once.
Consider the following program, which calls a recursive let-bound function
defined in terms of the linear resource \incode{x} and itself:
%
\begin{notyet}
\begin{lstlisting}
f3 :: Bool -> a *' $\lolli$ '* a
f3 bool x = let go b = case b of
                     True -> x
                     False -> go (not b)
                   in go bool
\end{lstlisting}
\end{notyet}
%
Function \incode{f3} is semantically linear because, iff it is consumed exactly once,
then \incode{x} is consumed exactly once. We can see this by case analysis on \incode{go}'s argument:
%\begin{itemize}%
%\item
when \incode{bool} is \incode{True}, we'll use the resource \incode{x};
%\item
 when \incode{bool} is \incode{False}, we recurse by calling \incode{go} on \incode{True}, which in turn will use the resource \incode{x}.
%\end{itemize}
In \incode{go}'s body, \incode{x} is used directly in one branch and indirectly in the
other (by recursing, which we know will result in using \incode{x} linearly).
% ROMES:TODO:!!
%\todo{this bit is quite hard to explain. It is some sort of cyclic
%argument -- we kind of assume go uses x linearly s.t. when go itself is used
%then we're using x linearly. recursion...}
%

It so happens that \incode{go} will terminate on any input, and will always consume
\incode{x}. However, termination is not a requirement for a binding to use a resource linearly,
and we could have a similar example in which \incode{go} might never terminate but still
uses \incode{x} linearly if evaluated:

\begin{notyet}
\begin{lstlisting}
f4 :: Bool -> a *' $\lolli$ '*  a
f4 bool x = let go b = case b of
                     True -> x
                     False -> go b
                   in go bool
          \end{lstlisting}
        \end{notyet}

The key to linearity in the presence of non-termination is Linear Haskell's
definition of a linear function: \emph{if a linear function application (\incode{f u}) is
consumed exactly once, then the argument (\incode{u}) is consumed exactly once}.
If \incode{f u} doesn't terminate, it is never consumed, thus the claim holds
vacuously.
% that's why \incode{f8} typechecks:
% \begin{working}
% \begin{lstlisting}
% f8 :: a *' $\lolli$ '* b
% f8 x = f8 x
% \end{lstlisting}
% \end{working}
%
If \incode{go} doesn't terminate, we aren't able to compute (or consume) the result
of \incode{f4}, so we do not promise anything about \incode{x} being consumed (\incode{f4}'s
linearity holds trivially). If it did terminate, it would consume \incode{x} exactly
once (e.g. if \incode{go} was applied to \incode{True}).

Naturally, a linear type system must statically reject any recursive group that could
lead to non-linear resource usage.
%
% Determining the linear resources used in a recursive binding might feel
% peculiar since we need to know the linear resources used by the binder to
% determine the linear resources it uses.
% %
% The paradoxical definition is difficult to grasp, just how learning that a
% function can be defined in terms of itself is perplexing when one is first
% introduced to general recursion.
% %
% Informally, we \emph{assume} the recursive binding will consume some linear resources
% exactly once, and use that assumption when reasoning about recursive calls such
% that those linear resources are used exactly once.
% Generalizing, we need to find a set of linear resources ($\Delta$) that satisfies the recursive equation
% \footnote{This set of resources will basically be the least upper bound of the sets of resources used in each
% mutually recursive binding scaled by the times each binding was used}
% arising from given binding $x$, such that:
% %\begin{enumerate}
% (1) Occurrences of $x$ in its own body are synonymous with using all resources in $\Delta$ exactly once;
% (2) and if the binding $x$ is fully evaluated, then all resources in $\Delta$ are consumed exactly once.
% %\end{enumerate}
% Finding a solution to this equation is akin to finding a (principle) type for a
% recursive binding: the binding needs to be given a type such that occurrences of
% that binding in its own body typecheck using that type.
% %
% Foreshadowing, the core system we developed assumes recursive let bindings to
% be annotated with a set of resources satisfying the equations; but we also
% present an algorithm to determine this solution, and distinguish between an
% \emph{inference} and a \emph{checking} phase, where we first determine the
% linear resources used by a group of recursive bindings and only then check
% whether the binding is linear, in our implementation of checking of recursive
% lets.
% ROMES:TODO:!!!
%\todo{We might not need the inferrence phase, somehow. Anyhow it seems like
%our inferrence is not really about determining a solution but more about
%determining how many times each thing gets used}
%
% There might not be a solution to the set of equations. In this case, the
% binding undoubtedly entails using a linear resource more than once.
%
For instance, if the linear resource \incode{x} is used in one case alternative and
recursion is used more than once in another, \incode{x} may end up being consumed
more than once:
% (thus, \incode{f5} below is ill-typed):
%
\begin{noway}
\begin{lstlisting}
f5 :: Bool -> Bool *' $\lolli$ '* Bool
f5 bool x =
  let go b
        = case b of
           True -> x
           False -> go (not b) && go True
  in go bool
\end{lstlisting}
\end{noway}
%However, if we returned \incode{x} instead of \incode{go bool} in the let body, then, despite
%the binding using \incode{x} more than once, we would consume \incode{x} exactly once,
%since recursive bindings are still lazy.
%

%Intuitively, to statically determine whether a group of recursive 
%
%Informally, we \emph{assume} the recursive binding will consume some linear resources
%exactly once, and use that assumption when reasoning about recursive calls such
%that those linear resources are used exactly once.

To determine whether the usage of a binding from a recursive group is
linear,
we must infer the superset of resources that may end up being consumed
in a single use of any of the bindings. For a strongly connected recursive
group, this superset is the same for all bindings by definition.
%
Intuitively, this inference amounts to finding a set of linear resources
($\Delta$) that satisfies the set of equations derived from the bindings
$\ov{x_i}$ in the group such that
%\begin{enumerate}
occurrences of $x_i$ in its own body are synonymous with using all resources in $\Delta$ exactly once.
%(2) and if the binding $x$ is fully evaluated, then all resources in $\Delta$ are consumed exactly once.
%\end{enumerate}
%Finding a solution to this equation is akin to finding a (principle) type for a
%recursive binding such that occurrences of itself in its definition are also well-typed.
%
It follows from the solution being the same for all bindings that
at most a single variable from the recursive group can be used in the continuation.
%
The treatment of recursive let bindings in our system is discussed in Section~\ref{sec:recursivelets}.

% Lastly, we extend our single-binding running example to use two mutually recursive bindings that
% depend a linear resource:
% \begin{notyet}
% \begin{lstlisting}
% f10 :: Bool -> a *' $\lolli$ '* a
% f10 bool x =
%   let go1 b = case b of
%            True -> go2 b
%            False -> go1 (not b)
%        go2 b = case b of
%            True -> x
%            False -> go1 b
%   in go1 bool
% \end{lstlisting}
% \end{notyet}
% As before, we must find a solution to the set of equations defined by the
% mutually recursive bindings to determine which resources will be consumed.
% In this case, \incode{go1} and \incode{go2} both consume \incode{x} exactly once if evaluated.
% We additionally note that a strongly connected group of recursive bindings
% (i.e. all bindings are transitively reachable from any of them) will always
% consume the same set of resources -- if all bindings are potentially reachable,
% then all linear resources are too.

% \parawith{Summary}
% Summarising, recursive let bindings behave like non-recursive let bindings in
% that if they aren't consumed, the resources they depend on aren't consumed
% either.  However, recursive let bindings are defined in terms of themselves, so
% the set of linear resources that will be consumed when the binder is evaluated
% is also defined in terms of itself (we need it to determine what resources are
% used when we recurse). We can intuitively think of this set of linear resources
% that will be consumed as a solution to a set of equations defined by a group of
% mutually recursive bindings, which we are able to reason about without an
% algorithm for simpler programs. In our work, the core type system isn't
% concerned with deriving said solution, but we present a simple algorithm for
% inferring it with our implementation.

\paragraph{Case expressions}
We have observed that more programs can be accepted as linear by delaying
resource consumption in (recursive) let bindings until they are evaluated.
On the other hand, \emph{case expressions drive evaluation} -- and, therefore,
do consume resources.

%and semantic linearity can only be understood in terms of how expressions are
%evaluated.

%Up until now, there have been no examples in which linear resources are
%\emph{fully consumed} in the bodies of linear functions.

%%%%%%%%%%%%%%% KEEEP ????? %%%%%%%
%%%%%%%%%All example functions so far returned a value that has to be itself consumed
%%%%%%%%%exactly once to ensure the linear argument is, in turn, consumed exactly once
%%%%%%%%%-- as opposed to functions whose application simply needs to be evaluated to
%%%%%%%%%guarantee its linear argument is consumed (e.g.,~functions that return an
%%%%%%%%%unrestricted value).

%
%The latter are of particular relevance because linearly-typed abstractions
%usually require such a function to provide newly-created linear resources to.
%
% For example, the entry point to the linear array API presented in Linear
% Haskell takes such a function as its second argument:
% \begin{working}
% \begin{lstlisting}
% newMArray :: Int -> (MArray a *' $\lolli$ '* Unrestricted b) *' $\lolli$ '* b
% \end{lstlisting}
% \end{working}
%(The second argument is a function that consumes |MArray a| linearly
%and returns an unrestricted result -- we don't need to consume said result
%exactly once to guarantee that |MArray a| is used linearly in the function
%body.)
%
% ROMES:TODO: Há qualquer coisa que não gosto nada! na coerência deste paragrafo
%
%Case expressions enable us to consume resources and so write
%functions that fully consume their linear arguments.
% CORTEI
To understand exactly how,
we turn to the definition of \emph{consuming} a resource from Linear
Haskell~\cite{cite:linearhaskell}:
%begin{itemize}
% \item
to consume a value of atomic base type (such as~\texttt{Int} or
        \texttt{Ptr}) exactly once, just evaluate it;
        % \item
        to consume a function value exactly once, apply it to one argument,
        and consume its result exactly once;
        % \item
        to consume a value of an algebraic datatype exactly once,
        pattern-match on it, and consume all its linear components exactly once.
        % For example, a linear pair (equivalent to $\tensor$) is consumed exactly
        % once if pattern-matched on \emph{and} both the first and second element are
        % consumed once.
%\end{itemize}
Thus, we can consume a linear resource by fully evaluating it -- and evaluation
happens in case expressions.

%%% In Section~\ref{sec:generalizing-evaluation-consuming} we generalize the idea
%%% that consuming a resource is deeply tied to evaluation.  Here, we continue
%%% building intuition for semantic linearity, first reviewing how case expressions
%%% evaluate expressions, and then exploring how they consume resources, by way of example.

In Core, cases are of the form $\ccase{e_s}{z~\{\ov{\rho_i \to e_i}\}}$,
where $e_s$ is the case \emph{scrutinee}, $z$ is the case \emph{binder}, and
$\ov{\rho_i \to e_i}$ are the case \emph{alternatives}, composed of a pattern
$\rho_i$ and of the corresponding expression $e_i$. 
%\begin{enumerate}
%\item
The case scrutinee is always evaluated to Weak Head Normal Form (WHNF) and
%
% \item
% evaluating an expression that is already in WHNF is a no-op, that is,
% no computation occurs; 
%
the case binder is an alias to the result of evaluating the scrutinee
to WHNF. Moreover, in Core, the alternative patterns are always exhaustive.
% i.e. there always exists
% a pattern that matches the WHNF of a value resulting from evaluating the
% scrutinee, where a pattern is either a wildcard that matches all expressions
% ($\_$), or a constructor and its linear and non-linear component binders
% ($K~\ov{x}\ov{y}$, with $\ov{x}$ as linearly-bound variables and $\ov{y}$ as
% unrestricted ones).

%\end{enumerate}

% ROMES:TODO: We should talk about WHNF in the background, not here.
% \parawith{WHNF} An expression is in Weak Head Normal Form when 

We start with an
example of a program that constructs a tuple from linear resources then pattern
matches on it, then uses both linearly-bound variables from the tuple pattern
match. This is well-typed in Linear Haskell:
\begin{working}
\begin{lstlisting}
f6 :: a *' $\lolli$ '* b *' $\lolli$ '* (a *' $\lolli$ '* b *' $\lolli$ '* c) -> c
f6 x y use = case (x,y) of z { (a,b) -> use a b }
\end{lstlisting}
\end{working}
What might be more surprising is that a similar program which discards the
pattern variables and instead uses the resources in the scrutinee is 
\emph{semantically} linear, despite not being accepted by Linear Haskell:
\begin{notyet}
\begin{lstlisting}
f7 :: a *' $\lolli$ '* b *' $\lolli$ '* (a *' $\lolli$ '* b *' $\lolli$ '* c) -> c
f7 x y use = case (x,y) of z { (a,b) -> use x y }
\end{lstlisting}
\end{notyet}
We justify that \incode{f7} is linear by appealing to the fact that 
the tuple being scrutinized is already in WHNF and so evaluating it will
not consume either $x$ or $y$. Even if the tuple was constructed with
two expressions using $x$ and $y$ respectively, no computation would happen
since we are not using $a$ or $b$ (thereby never forcing the arguments
of the tuple). However, if we did use $a$ in the case body, then $x$
would be unavailable (as opposed to \incode{y}) and \incode{f8} below must be rejected:
\begin{noway}
\begin{lstlisting}
f8 :: a *' $\lolli$ '* b *' $\lolli$ '* (a *' $\lolli$ '* a *' $\lolli$ '* c) -> c
f8 x y use = case (x,y) of z { (a,b) -> use a x }
\end{lstlisting}
\end{noway}
This idea that $x$ and $a$ are mutually exclusive is the same behind let
bindings being mutually exclusive to the resources that define them.
By forcing the pattern variable we run the computations
defined in terms of the linear variables used for that constructor
argument. Otherwise, if we do not use the pattern variables, then we
do not run the computation and thus no resources are consumed.

A third (semantically well-typed, but rejected by Linear Haskell) option is to use the case binder $z$ instead of $a,b$ or $x,y$:
\begin{notyet}
\begin{lstlisting}
f9 :: a *' $\lolli$ '* b *' $\lolli$ '* (a *' $\lolli$ '* b *' $\lolli$ '* c) -> c
f9 x y use = case (x,y) of z { (a,b) -> uncurry use z }
\end{lstlisting}
\end{notyet}
Again, $z$ is mutually exclusive with $(a,b)$ and with $(x,y)$, but at least one of
the three must occur to ensure the linear resources are consumed. In this
example, we can think that using $a$ entails using the resource $x$, $b$ the
resource $y$, and the case binder $z$ entails using both $a$ and $b$.

Dually, consider the scrutinee to be an expression that's not in WHNF, s.t.
evaluating it to WHNF will require performing computation and thus consume linear
resources (\incode{f10} below is well-typed in our system but rejected
by Linear Haskell):
\begin{notyet}
\begin{lstlisting}
f10 :: a *' $\lolli$ '* b *' $\lolli$ '* (a *' $\lolli$ '* b *' $\lolli$ '* (c,d)) -> (c,d)
f10 x y use = case use x y of z { (a,b) -> z }
\end{lstlisting}
\end{notyet}
Unlike when the scrutinee was in WHNF, we can no longer use $x,y$ in the case
alternatives, but we must still use either the case binder $z$ or the linear
pattern variables $a,b$. %  e.g. it would be quite disastrous if any of the following typechecked:
% \begin{noway}
% \begin{lstlisting}
% doubleFree :: Ptr *' $\lolli$ '* (Ptr *' $\lolli$ '* Result) -> Result
% doubleFree x free = case free x of z { Result v -> free x }
% \end{lstlisting}
% \end{noway}
% % Remover
% \begin{noway}
% \begin{lstlisting}
% leakPointer :: Ptr -> ()
% leakPointer x = case id x of z { _ -> () }
% \end{lstlisting}
% \end{noway}
%
%whereas this is fine:
%\begin{notyet}
%\begin{code}
%f16 :: Ptr -o (Ptr -o (Value,Int)) -> (Value,Int)
%f16 x free = case K (free x) of z { K y -> free x }
%\end{code}
%\end{notyet}
%
The result of evaluating the scrutinee must be consumed exactly once to guarantee
that the resources used in the scrutinee are fully consumed. %, or
                                %risk them being only ``almost''
                                %consumed.
For instance, take
\incode{use} in \incode{f10} to be the pairing function \incode{(,)}: it is not sufficient for \incode{use x y} to be
evaluated to WHNF to consume \incode{x} and \incode{y}. Otherwise, if all the resources were
considered to be fully consumed after the scrutinee were evaluated in a case
expression, we could simply ignore the pattern variables, potentially
discarding linear resources. In
short, if the scrutinee is not in WHNF we must either consume the case binder
or the linear components of the pattern.


On the other hand, if we match on a constructor without any linear components,
all linear resources used in the scrutinee must have been fully consumed in
that branch since the result of evaluating it can be consumed unrestrictedly
(by definition, a constructor application to unrestricted arguments is also
unrestricted).
%
Hence, in the branch for a constructor without linear fields, the case
binder can also be used unrestrictedly. For example, the program in
Figure~\ref{fig:nolin} is semantically linear.
%
\begin{figure}[h]
 \begin{minipage}{0.5\textwidth}
\begin{notyet}
\begin{lstlisting}
f11 :: () *' $\lolli$ '* ()
f11 x = case x of z { () -> z <> z }
\end{lstlisting}
\end{notyet}
\vspace{-0.5cm}
\caption{No Linear Fields\label{fig:nolin}}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{limitation}
\begin{lstlisting}
f12 :: a *' $\lolli$ '* a
f12 x = case K1 x of z { K2 -> x; K1 a -> x }
\end{lstlisting}
\end{limitation}
\vspace{-0.5cm}
\caption{Absurd Branches\label{fig:absurd}}
\end{minipage}
\end{figure}
%
A second example of an unrestricted pattern, where \incode{K2} has no fields
and \incode{K1} has one linear field, is shown in Figure~\ref{fig:absurd}.
The use of \incode{x} in the \incode{K2} branch is valid despite \incode{x}
also occurring in the scrutinee because this branch is never taken. In fact,
any arbitrary resource could be used in absurd branches and be understood as
linear (despite not being seen as such by our system).

While many of these examples may seem artificial due to the pattern match on a
known constructor, we note that in between the transformations programs
undergo in an optimising compiler, many such programs naturally occur (e.g.,~if
the definition of a function is inlined in the scrutinee).
%
% However, the scrutinee before evaluation likely isn't in WHNF, thus scrutinee
% resources cannot directly occur in the case alternatives, since they might be
% potentially consumed when evaluating the scrutinee, the program leading up to
% this one wouldn't have been linear (even semantically).

% Further exploring that each linear field must be consumed exactly once, and
% that resources in WHNF scrutinees aren't consumed, we are able to construct
% more contrived examples (Figures~\ref{fig:badcase}
% and~\ref{fig:goodcase}). the example in Figure~\ref{fig:badcase} does not typecheck
% because the same linear field is used twice, but the example in
% Figure~\ref{fig:goodcase} does since it
% uses each linear field exactly once, despite pattern matching on the same
% components twice.

% %Remover estes
% \begin{figure}[t]
%   \begin{minipage}{0.5\textwidth}
% \begin{noway}
% \begin{lstlisting}
% f w = case w of z
%         (a,b) -> case (a,b) of z'
%                         (c,d) -> (a,c)
% \end{lstlisting}
% \end{noway}
% \vspace{-0.5cm}
% \caption{Bad Case\label{fig:badcase}}
% \end{minipage}%
% \begin{minipage}{0.5\textwidth}
% \begin{notyet}
% \begin{lstlisting}
% f w = case w of z
%         (a,b) -> case (a,b) of z'
%                         (c,d) -> (a,d)
% \end{lstlisting}
% \end{notyet}
% \vspace{-0.5cm}
% \caption{Good Case\label{fig:goodcase}}
% \end{minipage}
% \end{figure}

As for \emph{default} case alternatives, also known as \emph{wildcards}
(written $\_$): matching a wildcard doesn't provide any linearity information,
% unlike a pattern with linear or unrestricted components,
%
but the
scrutinee is still evaluated to WHNF.
%
% so linearity is seen as before but without
% fully consuming the scrutinee linear resources (in non-linear patterns) nor
% binding new linear resources (in linear patterns).
%
When matching a wildcard, if the scrutinee is already in WHNF,
programs that either use the resources from the scrutinee directly, or the case
binder in that alternative, can be seen as linear. If the scrutinee is not in
WHNF, we \emph{must} use the case binder, as it's the only way to linearly
consume the result of evaluating the scrutinee.

% \parawith{Summary}
% In summary, case expressions evaluate their scrutinees to WHNF,
% introduce a case binder, and bind pattern variables. If the scrutinee is
% already in WHNF, all resources occurring in it are still available in the case
% alternative, alongside the case binder and the pattern-bound variables. In the
% case alternative, either the resources of the scrutinee, the case binder, or
% the linearly bound pattern variables must be used exactly once, but mutually
% exclusively. For scrutinees not in WHNF, in the case alternative, either the
% case binder or the linear pattern variables need to be used, in mutual exclusion.
% If the pattern doesn't bind any linear resources, then it may be consumed
% unrestrictedly, and therefore the case binder may also be used unrestrictedly.

% This is fine, because |x| in the case alternative is known to be K...
% Variables really are weird case...
% ROMES:TODO: Do something about this?
% \begin{noway}
% \begin{code}
% f :: a -o (a -o K) -o a
% f x use = case x of z { K -> x }
% \end{code}
% \end{noway}

%We used to call NOT IN WHNF "negative" hah
%\begin{code}
%-- This is NOT OK since (g x y) is negative (eliminates g)
%f x y = case g x y of z
%          K1 a b -> (x,y)
%          K2 w   -> (x,y)
%\end{code}


%% The harder harder things

%\todo[inline]{Should we discuss this? It would be fine, but we're not able to see this because of call-by-name substitution}
%\begin{code}
%f x = case x of z { _ -> x }
%\end{code}

%\todo[inline]{the harder ones regarding reverse binder swap. these give some
%intuition, but this is an unsound optimisation in some contexts}
%\begin{code}
%f y = let x = use y
%       in case x of z { K a b -> expensive x; K2 w -> w }
%\end{code}
%
%\begin{code}
%f y = let x = use y
%      let t = expensive x
%       in case x of z { K a b -> t; K2 w -> w }
%\end{code}
%
%\begin{code}
%f x = case x of z { K a b -> expensive x; K2 w -> w }
%
%
%f y = let x = use y
%       in case x of z { K a b -> expensive x; K2 w -> w }
%
%
%f y = let x = use y
%      let t = expensive x
%       in case x of z { K a b -> t; K2 w -> w }
%\end{code}

% ROMES: We don't have time to do this I think
%%%\subsection{Generalizing linearity in function of evaluation\label{sec:generalizing-evaluation-consuming}}
%%%
%%%\todo[inline]{Deixar isto para último, dificil generalizar, se necessario cortar}
%%%
%%%Indeed, as hinted towards in the previous section, there's a deep connection
%%%between \emph{evaluation} and \emph{consuming resources}.
%%%
%%%Definition X.Y: A linear resource is consumed when it is either fully evaluated
%%%(NF) to a value, or when it is returned s.t. an application of that function
%%%being fully evaluated would fully evaluate the resource to a value. Or something like that.
%%%%
%%%Note how this generalizes Linear Haskell's definition of consuming a resource: $\dots$
%%%
%%%\begin{itemize}
%%%\item We could almost say that eventually everything all linear
%%%resources must be evaluated to NF to be consumed, or returned by a function
%%%s.t. a continuation of that function has to evaluate the result to NF., or something.
%%%
%%%\item Discuss our own generalized (call-by-value, call-by-name, etc)
%%%definition of consuming resources by evaluation. Something like, if an
%%%expression is fully evaluated, all linear resources that expression depends on
%%%to compute a result are consumed, or something...
%%%
%%%\item How does this relate to strictness? Reference the section of Linear
%%%Haskell about linearity and strictness, and basically revisit what they say.
%%%
%%%\end{itemize}
  

% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Linear Core
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A Type System for Semantic Linearity in Core\label{sec:main:linear-core}}

In this section, we develop a linear calculus $\lambda_\Delta^\pi$,
dubbed \emph{Linear Core}, that combines the linearity-in-the-arrow
and multiplicity polymorphism introduced by Linear
Haskell~\cite{cite:linearhaskell} with all the key features of GHC's Core
language (algebraic datatypes, case expressions, and recursive lazy let bindings),
except for equality coercions, which we discuss as future work in
Section~\ref{sec:future-work}.
%

Linear Core makes precise the various insights discussed in the
previous section in a linear type system that we prove is sound and guarantees
linear resource usage at runtime.
This result is obtained (see Section~\ref{sec:main:metatheory}) via a soundness argument on a
call-by-need big-step operational semantics that becomes stuck when linear
variables in the runtime heap are used more than once. We show this
semantics to be bisimilar to a
Launchbury-style~\cite{10.1145/158511.158618} natural semantics. 
%\todo{O que digo aqui sobre a semantica launchbury style?}
Crucially,
Linear Core typing accepts all the semantically linear examples
(highlighted with \colorbox{notyet}{\notyetcolorname})
from Section~\ref{sec:semantic-linearity-examples}, which Core currently
rejects.
%
Additionally, we prove that multiple optimising Core-to-Core transformations
preserve linearity in Linear Core, while violating it under Core's
current type system.
%
%To the best of our knowledge, we are the first to prove optimisations preserve
%types in a non-strict linear language.
% 
Despite the focus on GHC Core, the fundamental ideas for
understanding linearity in our call-by-need calculus can be readily applied to
other non-strict languages.

Linear Core's first key idea is to delay consuming
resources until a computation that depends on those resources is effectively
evaluated or returned. Delayed consumption is tracked by annotating relevant
binders with \emph{usage environments} (Section~\ref{sec:usage-environments}).
%
The second key idea is to have two distinct rules for case
expressions, branching on whether the scrutinee is in Weak Head Normal
Form or not, and using ``proof irrelevance'' to track resources that are no
longer available but have yet to be fully consumed
(Section~\ref{sec:lc-case-exps}). Additionally, we introduce tags to split
resources amongst pattern-bound variables and %^as usage environments
encode that all linear components of a pattern must be used in tandem.

We present Linear Core's syntax and type system incrementally, starting with the
judgements and base linear calculi rules (Section~\ref{sec:base-calculi}).
%
Then, usage environments, the rule for $\Delta$-bound variables, and rules for
(recursive) let bindings (Section~\ref{sec:usage-environments}).
%
Finally, we introduce the rules to type case expressions and case alternatives,
along with the key insights to do so, namely branching on WHNF-ness of
scrutinee, proof irrelevant resources, and tagging (Section~\ref{sec:lc-case-exps}).

% We start by introducing the Core-like language, $\dots$ usage environments as a
% way to encode choice between the way a resource is used $\dots$\todo{$\dots$}
%

%\todo[inline]{Explicar algumas das ideias fundamentais, e apresentar as regras
%iterativamente. Podemos começar com as triviais e avançar para os dois pontos
%mais difíceis : Lets e Cases}

\subsection{Language Syntax}

The complete syntax of Linear Core is given in Figure~\ref{fig:full-linear-core-syntax}.
% Figure~\ref{fig:linear-core-types} and Figure~\ref{fig:linear-core-terms}.
%
The types of Linear Core are algebraic datatypes, function types, and
multiplicity schemes to support multiplicity polymorphism: datatypes
($T~\ov{p}$) are parametrised by multiplicities, function types
($\vp\to_\pi\s$) are also annotated with a multiplicity, which can be $1$,
$\omega$ (read \emph{many}), or a multiplicity variable $p$ introduced by a
multiplicity universal scheme ($\forall p.~\vp$).
%

%
Terms are variables $x,y,z$, data constructors $K$, multiplicity
abstractions $\Lambda p.~e$ and applications $e~\pi$, term abstractions
$\lambda \x[\pi].~e$ and applications $e~e'$, where lambda binders are
annotated with a multiplicity $\pi$ and a type $\s$. Then, there are
non-recursive let bindings $\llet{\xD = e}{e'}$, recursive let bindings
$\lletrec{\ov{\xD = e}}{e'}$, where the overline denotes a set of distinct
bindings $x_1{:}_{\D}\s_1\dots x_n{:}_{\D}\s_n$ and associated expressions
$e_1\dots e_n$, and case expressions $\ccase{e}{\zD~\{\ov{\rho \to e'}\}}$,
where $z$ is the case binder and the overline denotes a set of distinct
patterns $\rho_1\dots \rho_n$ and corresponding right hand sides $e'_1\dots
e'_n$. We often omit the case binder $z$ when it is unused. Notably, (recursive) let-bound
binders and case-bound binders are annotated
with a so-called \emph{usage environment} $\Delta$ -- a fundamental construct
for typing semantic linearity in the presence of laziness that we present in
Section~\ref{sec:usage-environments}.
%
Case patterns $\rho$ can be either the \emph{default/wildcard}
pattern $\_$, which matches any expression, or a constructor $K$ and a set of
variables that bind its arguments, where each field of the constructor has an
associated multiplicity denoting which pattern-bound variables must be
consumed linearly or unrestrictedly.
Additionally, the set of patterns in a case expression is assumed to be exhaustive,
i.e. there is always at least one pattern which matches the scrutinized expression.


% Linear Core takes the idea of annotating lets with usage environments from the
% unpublished Linear Mini-Core document by Spiwack et.
% al~\cite{cite:minicore}, which first tentatively tackled Core's
% linearity issues. We discuss this work in more detail in
% Section~\ref{sec:linear-mini-core}.

Datatype declarations $\datatype{T~\overline{p}}{\overline{K:\overline{\sigma
\to_\pi}~T~\overline{p} }}$ have the name of the type being declared $T$
parametrized over multiplicity variables $\ov{p}$, and a set of the data
constructors $K$ with signatures indicating the type and multiplicity of the
constructor arguments. Note that a linear resource is used many times when a
constructor with an unrestricted field is applied to it, since, dually, pattern
matching on the same constructor with an unrestricted field allows it to be
used unrestrictedly.
%Programs are a set of declarations and a top-level
%expression.

\SyntaxFull

%Linear Core is similar to Core without coercions, and with multiplicity
%abstractions instead of type abstractions.
%The key differences are that lets, recursive lets, case binders and
%pattern-bound variables
%the product of combining Linear Haskell's arrow linearity and
%multiplicity polymorphism with Core's key features, except for type equality
%coercions --
%a linear lambda calculus with algebraic datatypes, case
%expressions, recursive let bindings, and multiplicity abstractions. The 

% The (small-step) operational semantics of Linear Core are given in
% Figure~\ref{fig:linear-core-operational-semantics}. We use call-by-name
% evaluation for Linear Core as it captures the non-strict semantics in which
% our type system understands linearity, while being simpler to reason about than
% call-by-need operational semantics.
% % which is traditionally modelled with a
% % mutable heap to store \emph{thunks} and the values they are overwritten with.
% Furthermore, linear function applications, even in a \emph{call-by-need} system, can
% usually be reduced \emph{call-by-name} as the function argument is guaranteed to
% be used exactly once (thus avoiding unnecessarily allocating memory on the heap
% for a redundant \emph{thunk}).
% %
% Specifically, function applications are reduced by the standard
% \emph{call-by-name} $\beta$-reduction, substituting the argument by
% occurrences of the binder in its body, case expressions evaluate their
% scrutinee to WHNF, substituting the result by the case binder and constructor
% arguments for pattern-bound bound variables matching on that same constructor.

% \input{language-v4/OperationalSemantics}

\subsection{Base Typing System\label{sec:base-calculi}}

Linear Core ($\lambda^\pi_\Delta$) is a linear lambda calculus akin to Linear
Haskell's $\lambda^q_\to$ in that both have multiplicity polymorphism,
(recursive) let bindings, case expressions, and algebraic data types.
$\lambda^\pi_\Delta$ diverges from $\lambda^q_\to$ primarily when typing lets,
case expressions, and alternatives (in its purpose to type semantic linearity).
%, and secondarily in only treating multiplicity polymorphism superficially.
%
% \todo{And our treatment of multiplicity polymorphism completely ignores
% algebraic treatment of multiplicities with semiring operations!!! Would it be
% sufficient to add a rule for application of variable multiplicity functions?}
%
%
The core rules of the calculus for abstraction and application are similar to
that of $\lambda^q_\to$ and mostly standard. 
We note that we handle multiplicity polymorphism differently from
Linear Haskell by ignoring the multiplicity semiring and
conservatively treating all multiplicity polymorphic functions as
linear, for the sake of simplicity.
%
The full type system is given in Figure~\ref{fig:linear-core-typing-rules},
with auxiliary judgements given in
Figure~\ref{fig:linear-core-other-judgements}.

\TypingRules
\TypingRulesOther

%We start with the main typing judgement.
%As is common for linear type systems, we use two typing environments, an
%unrestricted $\G$ and a linear $\D$ environment.
The main judgement is written $\G;\D \vdash e : \s$ to denote that expression
$e$ has type $\s$ under the unrestricted environment $\G$ and linear
environment $\D$.
%
%
Variables in $\G$ can be freely discarded (\emph{weakened}) and duplicated
(\emph{contracted}), while resources in $\D$ must be used exactly once. Despite
not having explicit weakening and contraction rules in our system, they are
available as admissible rules for $\G$ (but not for $\D$), since, equivalently
\cite{91621fae-5e53-3497-8291-32b2fab5a743}, resources from $\G$ are duplicated
for sub-derivations and may unrestrictedly exist in the variable rules.
% TODO: Likely rewrite that?
%

Occurrences of unrestricted variables from $\G$ are well-typed as long as the linear
environment is empty, while occurrences of linear variables are only well-typed
when the variable being typed is the only resource available in the
linear context (rules $Var_\omega$ and $Var_1$, respectively).
% \[
% \begin{array}{cc}
% \TypeVarOmega & \TypeLinearVar
% \end{array}
% \]
In both cases, the linear context must contain exactly what is required to
prove the proposition, whereas the unrestricted context may contain arbitrary
variables.
%
Variables in contexts are annotated with their type and multiplicity, so
$\x[\pi]$ is a variable named $x$ of type $\s$ and multiplicity $\pi$.

Linear functions are introduced via the function type ($\s \to_\pi \vp$) with
$\pi = 1$, i.e. a function of type $\s \to_1 \vp$ (or, equivalently, $\s \lolli \vp$)
introduces a linear resource of type $\s$ in the linear environment $\D$ to then type an expression of type $\varphi$.
%
Unrestricted functions are introduced via the function type ($\s \to_\pi \vp$) with $\pi =
\omega$, and the $\lambda$-bound variable is introduced in $\G$ (rules
$\lambda I_1$ and $\Lambda I$). Function application is standard, with
linear function application splitting the linear context in two
disjoint parts, one used to type the argument and the other the
function.
Arguments of unrestricted functions must also be unrestricted, i.e. no
linear variables can be used to type them. 
% \[
% \begin{array}{cc}
% \TypeLamIntroL & \TypeLamIntroW
% \end{array}
% \]
% A linear function application is well-typed if there exists a disjoint split of the
% linear resources into $\D,\D'$ s.t. the function and argument, each under a
% distinct split, are both well-typed and the argument type matches the
% function's expected argument type. Conversely, unrestricted resources are
% duplicated and available whole to both sub-derivations.
% \[
% \TypeLamElimL \quad \TypeLamElimW
% \]
% An unrestricted function, unlike a linear one, consumes its argument
% unrestrictedly (zero or more times). Therefore, in an unrestricted function
% application, allowing any linear resources to occur in the argument expression
% entails consuming those resources unrestrictedly, since the
% variable binding the argument expression could be discarded or used more than
% once in the function body. Thus, argument expressions to unrestricted functions must also
% be unrestricted, i.e. no linear variables can be used to type them.
% %
%
Typing linear and unrestricted function application separately is less
general than typing applications of functions of any multiplicity
$\pi$ by scaling (per the multiplicity semiring) the multiplicities of
the resources used to type the argument by $\pi$, however, our
objective of typing semantic linearity does not benefit much from
doing so and therefore we opt for a simpler design.
% \todo{We might only need multiplicities for the case-of-case definition as it
% exists in ghc?, even then couldn't we do semiring scaling without variables?
% Also, dislike sentence}

Multiplicity abstractions ($\Lambda I$) introduce a multiplicity variable $p$,
and construct expressions of type $\forall p.~\s$, i.e. a type universally
quantified over a multiplicity variable $p$. Again, conservatively, in the body
of the abstraction, function types annotated with a $p$ variable and datatype
fields with multiplicity $p$ are typed as though they are linear functions and
linear fields, because $p$ can be instantiated at both $\omega$ and $1$.
%\[
%%\TypeMultLamIntro \quad \TypeMultLamElim
%\]
A multiplicity application ($\Lambda E$) instantiates a multiplicity-polymorphic type
$\forall p.~\s$ at a particular (argument) multiplicity $\pi$, resulting in an
expression of type $\s$ where occurrences of $p$ are substituted by $\pi$, i.e.
$\s[\pi/p]$.
The rule additionally requires that $\pi$ be \emph{well-formed} in order
for the expression to be well-typed, using the judgement $\G \vdash_{mult}
\pi$, where well-formedness is given by $\pi$ either being $1$, $\omega$, or an
in-scope  multiplicity variable in $\G$.
% \[
% \TypeWellFormedMult
% \]

% These rules conclude the foundations of our linear calculi. In subsequent
% sections we type (recursive) let bindings and case expressions,
% accounting for semantic linearity as per the insights construed in
% Section~\ref{sec:linearity-semantically}, effectively distilling them into the
% key ideas of our work -- encoded as rules.


\subsection{Usage environments\label{sec:usage-environments}}

A \emph{usage environment} $\Delta$ encodes the idea that lazy
bindings do not consume resources upon definition, but rather when the bindings themselves are consumed.
Specifically, we annotate so-called $\Delta$-bound variables with a \emph{usage
environment} to denote that consuming these $\D$-variables equates to consuming the
resources in the annotated usage environment $\D$ (which is essentially a
multiset of linear resources).
%
$\Delta$-bound variables are introduced in the unrestricted environment by
several constructs such as (recursive) let binders, case binders, and case
pattern variables.
%
For example, the let-binder $u$ in the following program is annotated with a
usage environment $\{x{:}_1\s,y{:}_1\s\}$ tracking the resources that are used in its
body. Thus, in the expression $e$, consuming $u$ will equate to consuming the
linear resources $x$ and $y$:
% , as per the insights developed in
% Section~\ref{sec:semantic-linearity-examples},
\[
f = \lambda \xl.~\lambda \y[1].~\llet{u_{\{x:_1\s,y:_1\s\}} = (x,y)}{e}
\]
Furthermore, usage environments guarantee that using a $\Delta$-bound variable
is mutually exclusive with directly using the resources it is annotated with --
using the $\Delta$-bound variable consumes all linear resources listed in its
usage environment, meaning they are no longer available for direct usage.
Dually, using the linear resources directly means they are no longer available
to consume through the usage environment of the $\Delta$-bound variable. The
$\Delta$-bound variable can be left unused since it is unrestricted, regardless
of the variables it is annotated with.

% Finally, we note that usage environments bear a strong resemblance to the linear
% typing environments in the main typing judgement,
% i.e. the environment with the linear resources required to type an expression.
%
% In fact, usage environments and linear typing contexts differ only in that the
% former used to annotate variables, while the latter used to type
% expressions.
%
% Yet, this distinction is slightly blurred after introducing how
% typing environments can be moved to usage environments, or otherwise occurs in
% rules relating the two.

\paragraph{\texorpdfstring{$\D$}{Delta}-bound variables}

A $\Delta$-bound variable $u$ is a variable annotated with a usage environment $\Delta$. Crucially, for any $\Delta$-bound variable $u$:
%
%\begin{enumerate}
%\item
(1) using $u$ is equivalent to using all the linear resources in $\Delta$;
%\item $u$ can only be used once, since the $\D$ resources will not be available afterwards
%\item
(2) using $u$ is mutually exclusive with using the $\Delta$ resources it depends on;
% \item
(3) $u$ can be safely discarded as long as the resources in $\Delta$ are consumed.
%\end{enumerate}
%
Fortunately, since linear resources must be linearly split across
sub-derivations, (2) follows from (1) since consuming the linear
resources in $\Delta$ to type $u$ makes them unavailable in the
context of any other derivation.
% Therefore, expressions using these
% resources a second time, directly, or indirectly through the same (or
% other) usage environment, are ill-typed, as the resources are already
% allocated to the derivation of $u$.
Similarly, (3) also follows from (1), because if the linear resources aren't
consumed in the $\Delta$-var derivation, they must be consumed in an
alternative derivation (or otherwise the expression is ill-typed).
%
These observations all lead to the typing rule for $\Delta$-bound
variables:

\vspace{-0.5cm}
\[
\TypeVarDelta
\]
The rule states that an occurrence of a $\Delta$-bound variable is well-typed if
the linear environment is made up exactly of the resources in the usage environment of
that variable.
%
$\D$-vars are unrestricted and can be discarded and duplicated, despite
multiple occurrences of the same $\Delta$-var in an expression not possibly being well-typed
since that would imply non-linear usage of linear resources.
% multiple occurrences of the same
% $\D$-variable imply non-linear usage of resources that must be used linearly.


\subsection{Lazy let bindings}

In Section~\ref{sec:semantic-linearity-examples}, we discussed how linear
resources used in let-bound expressions are only consumed when the respective
binders are evaluated in the let body.
%, i.e. linear resources required by let-bound expressions are consumed lazily.
%
Moreover, resources captured by a let-bound expression cannot be used
simultaneously with the let-binder in its body, since said
resources would end up being consumed more than once and violate (semantic)
linearity. The binder has to be used in mutual exclusion with the linear
resources captured by the expression it binds -- either the binding or the
resources \emph{must} be used.

% Indeed, usage environments allow us to encode mutual exclusivity between
% alternative ways of consuming linear resources (between $\D$-vars and direct
% resource usage). 
Let-bound variables are the canonical example of a
$\Delta$-bound variable.
% , that is, let-bound variables bind expressions in which
% the resources required to type them are consumed lazily rather than eagerly.
%
Annotating let-bound variables with a usage environment $\D$ delays the
consumption of resources to when the variables themselves are used and
guarantees the desired mutual exclusion property between the binder and the resources:
\[
\TypeLet
\]
The rule for (non-recursive) let bindings splits the linear environment in $\D$
and $\D'$. $\D$ is used to type the body $e$ of the let binding $x$. Perhaps
surprisingly, the resources $\D$ used to type $e$ are still available in the
environment to type the let body $e'$, alongside the unrestricted $x$ binding
annotated with the usage environment $\D$. In essence, the resources of $e$ being
available in $e'$ reflects how typing the body of a lazy binder
doesn't consume resources, and the binding $x$ being an unrestricted
$\D$-variable ensures that using it will consume the resources $\D$ the
expression captures, \emph{if} it is used.
% \todo[inline]{Let bindings are hard, if they are used then we use resources. If
% they don't get used then we use no resources! In practice, resources that show
% up in the body of the let must be used, be it by using the let binder, or by
% using them directly. This makes the let binder and the resources in its body
% mutual exclusive.}

% \todo[inline]{Explain the idea of suspended computation, and how resources will
% be consumed to some extent when we force the computation -- also foreshadowing
% that evaluation to WHNF doesn't necessarily consume all resources}

\subsection{Recursive let bindings}\label{sec:recursivelets}

% Recursive let bindings are very similar to non-recursive ones, the main
% exception being that the recursive bindings may be defined in terms of
% themselves, and we may have more than one binding.
%
Recursive let bindings also bind expressions lazily and so
introduce a $\D$-bound variable for each binding. Resources required to type the
let-bindings are still available in the body of the let, to later be consumed
via $\D$-bound variables, or, directly, if the let-bindings are unused.
%
%Additionally, as seen in Section
%\ref{sec:semantic-linearity-examples:recursive-lets}, recursive uses of a
%binder in its own definition entail consuming all resources otherwise required
%to type the binder's body.

%We assume all mutually recursive groups of bindings are strongly-connected.
%As for groups of recursive let bindings, we recall that, in our
%system, all recursive let groups are strongly-connected -- all bindings in a
%recursive let group are mutually recursive in the sense that they all
%(transitively) depend on one another.
%
% In light of it, (mutually) recursive uses of binders entail consuming all the
% resources required to type all of the binders.
%
%By definition, any binder in such a group may end up recursively using
%any other binder from the group and thus use up any resource occurring.
%
%Accordingly, occurrences of any such binder
%must be typed conservatively, using up the sum of resources needed to type each
%of the binders,
%%
%i.e.,
%Accordingly, all the binders in a strongly-connected group of mutually recursive let
%bindings have to be typed with the same linear resources (which are the least
%upper bound of resources needed to type the bodies of all binders, accounting
%for uses of mutually-recursive binders).
%
% Therefore, we conclude the least upper bound of resources required to type a
% mutually recursive group of let bindings to be the same for any such group that
% is strongly-connected.

The typing rule for recursive groups of bindings leverages both the assumption
that all mutually recursive groups are strongly connected and the corollary
that every binder in such a group must be typed with the same linear context,
as observed in Section~\ref{sec:semantic-linearity-examples:recursive-lets}.
Consequently, all bindings of the recursive group are introduced as
$\D$-bound variables
sharing the same usage environment -- using any one of the bindings in a
recursive group entails consuming all resources required to type that same
group -- so, at most a single binder from the group can be used in the
let body.
%\todo{should we say how this means at most once of the binders from the group can be used?} OK
%, which is also why we can use the same linear resources to type each binder:
\[
\TypeLetRec
\]
This formulation is not syntax-directed 
% (from which an implementation is direct) 
because determining a particular $\D$
to type and annotate all binders is not obvious. We present our system and
metatheory agnostically to the challenge of inferring this linear typing
environment by assuming recursive let expressions are annotated with the
correct typing environment.

In practice, determining this typing environment $\D$ amounts to finding a
least upper bound of the resources needed to type each mutually-recursive
binding that (transitively) uses all binders in the recursive group.
%
Our implementation uses a naive $O(n^2)$ algorithm for inferring usage
environments of recursive bindings.
% , which is not relevant to the theory developed in this section.
%
% The algorithm is a $O(n^2)$ traversal over the so-called \emph{naive usage
% environments} used to type each binding.
%
Moreover, we note that inference of usage environments for recursive binding
groups bears some resemblance to the inference of principle types for recursive
bindings traditionally achieved through the Hindley–Milner inference
algorithm~\cite{DBLP:conf/popl/DamasM82}. % , there might be an opportunity to
% develop a better algorithm leveraging existing inference techniques.
% %
% Despite being a seemingly useful observation, 
We leave the exploration of this connection
as future work.

% We present a naive algorithm for inferring usage environments of recursive bindings in
% Section~\ref{sec:impl:recursive-alg} and leave exploring this potential
% connection as future work.

\subsection{Case Expressions\label{sec:lc-case-exps}}

%Case expressions \emph{drive evaluation} --
% thus they are key to realize a type system that understands linearity in the presence of lazy evaluation.
%
%However, the evaluation of case expressions is considerably nuanced,
%
%In lazy let bindings, computations  can be a case
%expression can effectively consume resources rather than just 
%
A case expression drives evaluation by evaluating its scrutinee to Weak Head
Normal Form (WHNF)~\cite{10.5555/1096899}. Then, the case
alternative whose pattern matches the result of evaluating the
scrutinee is taken\footnote{In our calculus, the alternatives are assumed to be
  exhaustive, i.e. there always exists at least one pattern which
  matches the scrutinee in its WHNF, so we're guaranteed to have an
  expression to progress evaluation.}.
An expression in WHNF can either be %\begin{itemize}
% \item
a $\lambda$-abstraction $(\lambda x.~e)$ 
or a datatype constructor application $(K~\ov{e})$.
%\end{itemize}
In both cases, the sub-expressions $e$ or $\ov{e}$ occurring in the lambda body
or as constructor arguments need not be evaluated for the lambda or constructor
application to be in WHNF. % (if otherwise all sub-expressions
% were fully evaluated the whole expression would also be in \emph{normal form}).
% (that is why it is called \emph{weak} head normal form).
%
Accordingly, these sub-expressions might still depend on linear resources to be
well-typed and such resources will only be consumed when the sub-expressions themselves are evaluated.

As will be made clear in this section, we need to devise a specialized typing
for scrutinees that distinguishes between terms
in WHNF and terms that are not in WHNF.
Following the discussion on expressions in WHNF, we present a
typing judgement $\G;\D \Vdash e : \s \gtrdot \ov{\D_i}$, and a rule for each
of the forms given above:
\[
    \TypeWHNFCons
\qquad
    \TypeWHNFLam
\]
This judgement differs from the main typing judgement in that (1) it only
applies to expressions in weak head normal form, and (2) it ``outputs'' (to the right of $\gtrdot$) a
disjoint set of linear environments ($\ov{\D_i}$), where each environment corresponds to the
linear resources used by a sub-expression of the WHNF expression.
%
To type a constructor application $K~\ov{e_\omega e_i}$, where $e_\omega$
are the unrestricted arguments and $e_i$ the linear arguments of the
constructor, we split the resources $\D$ into a disjoint set of resources
$\ov{\D_i}$ required to type each linear argument individually and return exactly
that split of the resources; the unrestricted $e_\omega$ expressions must be
typed on an empty linear environment. A lambda expression is typed with
the main typing judgement and trivially ``outputs'' the whole $\D$ environment,
as there is always only a single sub-expression in lambda abstractions.

% Precisamos disto?
% %
% \begin{tabbing}
% $\ccase{e}{z~\{\ov{\rho_i \to e_i}\}} \longrightarrow^* \ccase{e'}{z~\{\ov{\rho_i \to e_i}\}}$\`where $e'$ is in WHNF and $e$ is not\\
% $\ccase{K~\ov{e}}{z~\{K~\ov{x} \to e_i\}} \longrightarrow e_i\ov{[e/x]}[K~\ov{e}/z]$\\
% $\ccase{e}{z~\{\_ \to e_i\}} \longrightarrow e_i[e/z]$\`where $e$ is in WHNF\\
% \end{tabbing}
% %
% Recall how the operational semantics encode the evaluation of case
% expressions such that,
% when a scrutinee $K~\ov{e}$ matches a constructor pattern $K~\ov{\x[\pi]}$,
% evaluation proceeds in the case alternative corresponding to the matching
% pattern, with occurrences of $\ov{x}$ being substituted by $\ov{e}$ and
% occurrences of the case binder $z$ substituted by the whole scrutinee
% $K~\ov{e}$. Constructors and lambda expressions may otherwise match match the wildcard
% pattern, resuming evaluation on the alternative body only substituting the case
% binder by the scrutinee. 

We highlight that, when evaluating a case expression, computation only
happens when a scrutinee that is not in WHNF is evaluated to
WHNF. Otherwise, evaluation continues in the alternative by
substituting in the appropriate scrutinee expressions, but without
having performed any additional computation.
% (the scrutinee was already in weak head normal form).
%In short, no computation happens if the scrutinee is already in WHNF.
%
In terms of linearity, resources are consumed only if evaluation happens.
Therefore, resources used to type a scrutinee not in
WHNF will be consumed when the case is evaluated and will no longer be directly available in the case
alternatives. Conversely, when the scrutinee is already in WHNF, linear
resources required to type the scrutinee are still directly available in the
alternatives.
%
%%%%???
%%%%The linear resources used to type an expression in WHNF are exactly those which
%%%%occur to the right of $\gtrdot$ in the WHNF judgement shown above
%%%%(corresponding to the resources required to typecheck the lambda body or the
%%%%constructor arguments).

%Recalling that patterns are either a wildcard that matches anything or data
%constructors parametrised by variables to bind the constructor arguments in the
%case alternative
%
%Let's consider how resources are consumed when the case exp ...
%
%Patterns data constructors with variables to bind the constructor arguments parametrised
%
%\begin{itemize}
%\item The wildcard pattern matches against anything, and is the only pattern that matches against a lambda function
%\item We can match against the data constructor and 
%\end{itemize}
%
%Considering patterns are either data constructors and variables bounding
%A function (lambda expression) can only be matched against the wildcard pattern $\_$, but 
%
%Evaluation continues in the selected branch by
%substituting, first, the pattern variables by the (possibly unevaluated)
%expressions used as arguments to the 

% \todo[inline]{Case expressions are the means by which we do evaluation and
% pattern matching -- when things are scrutinized, we evaluate them (if they
% aren't evaluated -- tag is 0), and then compare the result against multiple
% alternatives}

% \todo[inline]{Item 2.
%     Pattern matching an expression that is evaluated will not consume all
%     the resources that define that computation -- because of laziness, we only
%     evaluate things to WHNF. To fully consume a value, we need to consume all
%     the linear components of that pattern.
% }

\subsubsection{Branching on WHNF-ness}

The dichotomy between evaluation (and resource usage) of a case expression
whose scrutinee is in weak head normal form and one whose scrutinee is not
leads to one of the key insights of $\lambda^\pi_\Delta$: we must \emph{branch}
on weak head normal formed-ness to accurately type case expressions.
%
When the scrutinee is already in WHNF, the resources are
unused upon evaluation and thus available in the alternatives.
%
When it is not, resources will be consumed and cannot be used in the
alternative.
%
To illustrate, consider the following case expressions:
\[
\begin{array}{ccc}
    (1)~\lambda x.~\ccase{K~x}{z~\{\_ \to x\}} &  & (2)~\lambda x.~\ccase{free~x}{z~\{\_ \to x\}}
\end{array}
\]
The first function uses $x$ linearly, but the second does not.
%
Alternatives may also use the case binder or pattern variables, referring to, respectively,
the whole scrutinee and all its used resources; or
constructor arguments and the resources used to type them.
% Using the case binder entails using all the resources required by the scrutinee, and using a pattern
% variable implies using the resources of the corresponding constructor argument.

There are three competing ways
to use the resources from a scrutinee in WHNF in a case alternative: directly, via
the case binder, or by using pattern-bound variables.
%
Recall how $\D$-bound variables encode mutual exclusion between alternative
ways of consuming resources -- it follows that case binders and pattern-bound
variables are yet another instance of $\D$-bound variables.
%
%Resources in a scrutinee that is already in WHNF are only consumed when all
%(linear) fields of the pattern are used, satisfying the definition of
%consuming resources given in Linear Haskell.
%
% We type a case expression whose scrutinee is in weak head normal form with
This suggests the following first rule for cases of scrutinees already in WHNF:
\[
\TypeCaseWHNFIntermediate
\]

First, we assert this rule is only applicable to expressions in weak head
normal form. Second, we appeal to the typing judgement for expressions in WHNF
to determine the split of resources amongst the scrutinee
sub-expressions. Finally, we type all case alternatives with the same context, using the
$\vdash_{alt}$ judgement, introducing
the case binder $z$ in the unrestricted environment as a $\D$-bound
variable whose usage environment is the linear resources $\ov{\D_i}$ used to type the
scrutinee. Those same resources $\ov{\D_i}$ are again made available in the
linear typing environment of the alternative, similarly to how the resources
used to type a $Let$ binder are still available in the continuation.
%
%The $\vdash_{alt}$ judgement is 
%annotated with the disjoint set of linear resources $\ov{\D_i}$ used
%to type the scrutinee sub-expressions,
%and the name of the case binder $z$.
%
%
Although the main idea for typing ``WHNF case expressions'' is conveyed by
this rule, the full rule of our system is slightly more involved, as will be seen after
discussing cases of scrutinees not in WHNF.

The alternative judgement $\G;\D \vdash_{alt} \rho \to e :^z_\D \s \Rightarrow
\vp$ is used to type case alternatives, encompassing three
``modes'' that are distinguished by the kind of arrow that is used:
for alternatives of case expressions whose scrutinee is in WHNF
($\Rightarrow_\mathsf{WHNF}$), not in WHNF ($\Rightarrow_\mathsf{NWHNF}$),
and for alternatives agnostic to the WHNF-ness of the scrutinee
($\Rightarrow$), with $\Rightarrow$ also generalizing the other two.
%
% Following the $Case_\textrm{WHNF}$ rule in which we use the $\Mapsto$ alternative
% judgement, t

First, an alternative whose pattern is a constructor with $n > 0$ linear components
under the $\Rightarrow_{\mathsf{NWHNF}}$ mode is typed as:
\[
\TypeAltNWHNF
\]
The rule states that, for such a match on a scrutinee already in
WHNF, we introduce the linear components of the pattern as $\D$-bound variables
with usage environment matching the linear resources required to type the
corresponding constructor argument in the scrutinee. The resources required to
type each constructor sub-expression come annotated in the judgement (as
${:}_{\ov{\D_i}}$). Unrestricted fields of the constructor are introduced as
unrestricted variables. We note that the typing environment $\D$ always
contains the resources $\ov{\D_i}$ in uses of the alternative judgement.

Second, the rule for alternatives that match on the wildcard pattern,
regardless of the WHNF status of the scrutinee (note the use of $\Rightarrow$, which
is applicable both under $\Rightarrow_{WHNF}$ and $\Rightarrow_{NWHNF}$):
\[
\TypeAltWild
\]
To type a wildcard alternative we simply type the expression with the main
judgement, ignoring all annotations. The case binder will
have already been introduced in the environment with the appropriate usage
environment by the relevant %(WHNF or not)
case expression rule.

Lastly, consider an alternative matching on a data constructor without any
linear components. The linear resources used to type a scrutinee matching such
a pattern are fully consumed during evaluation: the resulting unrestricted
constructor application can only be well-typed under an empty linear
environment.
%
Consequently, the resources to type the scrutinee which are carried over to the
case-alternative environments by the $Case_{WHNF}$ and $Case_{NWHNF}$ rules
(see the latter below), must be reactively destroyed from branches where the
pattern is unrestricted. In failing to do this, we would allow the fully-consumed
resources to be used again in the branch.
% Really, in the WHNF case it is not really necessary to remove the things
% since they must already be empty be definition.
%
%This definition agrees with the intuition we have developed by example in the
%previous section, and with the typing rule we devised for alternatives matching
%constructors without linear components.
%
%Taking into account that case expressions introduce the linear resources of the
%scrutinee in the typing environment of all alternatives, and in the usage
%environment of the case binder, we must reactively update the typing
%environments after matching on such a pattern.
%
The $Alt0$ rule essentially encodes this insight, and is applicable regardless
of the WHNF status of the scrutinee ($\Rightarrow$ mode), as long as
the constructor pattern has no linear fields:
%
\[
\TypeAltZero
\]
The rule deletes the annotated scrutinee environment $\D_s$ from
%two select environments:
the linear typing context (written $\D[\cdot/\D_s]$, a substitution of
the scrutinee typing environment by the empty linear environment $\cdot$)
and from the usage environment of the case binder $z$ (written $\G[\cdot/\D_s]_z$
to similarly delete $\D_s$ from the usage environment of the $\D$-var $z$ in $\G$).
Given that the case-binder $z$ is always annotated with $\D_s$ (essentially,
the linear environment typing the scrutinee), this latter substitution makes
the case-binder unrestricted in branches with unrestricted patterns.
%-- agreeing with our observation in Section \label{sec:semantic-linearity-examples}.

% \begin{itemize}

% \item The linear typing environment, effectively deleting the resources from
% the scrutinee made available by the case expressions (written
% $\D[\cdot/\D_s]$, a substitution of the scrutinee typing environment by the
% empty linear environment $\cdot$).

% \item The usage environment of the case binder $z$, written $\G[\cdot/\D_s]_z$
% to denote replacing the usage environment of the variable $z$ in $\G$, which
% is necessarily $\D_s$ (since we always annotate the judgement with the
% environment of the scrutinee), by the empty environment.

% \end{itemize}
%
This rule observes that any linear resources required to type an expression
that reduces to an unrestricted constructor application are fully consumed
through evaluation and the resulting unrestricted expression can be freely
discarded or duplicated (e.g. via the case binder).
%
%Reactively deleting the resources that typed the scrutinee from the linear
%environment ensures that when we match on an unrestricted pattern there are no
%remaining linear resources to consume. Otherwise, e.g., $\ccase{K_1~x}{\{K_2 \to
%K_2,K_1~y \to K_1~y\}}$ would not be well-typed since the resource $x$ would
%be left \emph{un}-consumed in the first alternative, even though we know by
%matching on $K_1$ that it has already been consumed.
%
%Furthermore, since the case binder in such an alternative refers to the
%unrestricted expression, the case binder too may be used unrestrictedly, which
%we allow by emptying its usage environment.

%It might seem as though deleting the resources from the environment in $\textsc{Alt}_0$
%is necessary to guarantee a resource is not used after it is consumed.
%%
%However, let us consider two situations -- pattern matches in a case
%expression whose scrutinee is in WHNF, and matches on a case expression whose
%scrutinee is \emph{not} in WHNF:
%%
%%\begin{enumerate}
%When the scrutinee is in WHNF, it is either an unrestricted expression
%against which any match will only introduce unrestricted variables, or an
%expression that depends on linear resources. The former trivially allows
%any resource from the scrutinee in the alternatives as well. The latter is
%further divided: 
%%\begin{enumerate}
%%
%%\item
%The pattern is unrestricted while the
%scrutinee is not, so entering this branch is impossible as long as the case
%expression is well-typed; by contradiction, the linear resources from the
%scrutinee could occur unrestrictedly in that branch.
%%
%For uniformity, we type such alternatives as those for scrutinees that
%are not in WHNF;
%%
%The pattern is linear and matches the scrutinee, in which case the
%$AltN_{\textrm{WHNF}}$ is applicable instead of $Alt0$;
%%
%The pattern is linear but does not match the scrutinee and so any
%resource could be used in such alternatives. For uniformity,
%it is also typed as though the scrutinee were not in WHNF.

%If the scrutinee is not in WHNF, the resources occurring in the
%scrutinee will be consumed when evaluation occurs. Therefore, the resources
%used in the scrutinee cannot occur in the alternative body
%(e.g. $x$ cannot occur in $e$ in $\ccase{close~x}{\{K_1 \to e\}}$)
%-- regardless of the pattern.
%%
%% In fact, the resources from a scrutinee that is not in weak head normal form
%% cannot occur in any of the alternatives, even ones matching on constructors
%% with linear components, as the resources may have been consumed when evaluating
%% the expression to weak head normal form.
%%
%We guarantee resources from a scrutinee that is not in WHNF
%cannot occur/directly be used in any case alternative in our rule for typing
%cases not in WHNF, which we introduce below.

%\end{enumerate}

\subsubsection{Proof irrelevant resources}

When the scrutinee is not in WHNF, it is not statically known which resources
will have been consumed after evaluating said scrutinee, or which
are transferred into the branch continuation, e.g. as in $\ccase{f\ x}{z\ \{K\
a \rightarrow e\}}$:
\begin{enumerate}

    \item Cases with non-WHNF scrutinees must be typed such that no resource
    from the scrutinee can be used directly in the branch again, or we
    risk
    consuming the same resource twice. In the example, $x$ must not directly occur
    in $e$ since $f$ \emph{could} have consumed it.

    \item On the other hand, since evaluation to WHNF does not guarantee all
    resources are consumed (unless the result matches an
    unrestricted pattern), we must ensure that any resources that transfer from the
    scrutinee to the alternative are ultimately consumed (in the example, $x$
    is not consumed by evaluating the scrutinee for $f = K$).

    Considering (1), we must resort to a more uniform method of guaranteeing we
    ``finish consuming'' the scrutinee. There are only two ways of
    uniformly referring to the remaining linear resources in the newly-evaluated scrutinee:

        \begin{itemize}
            \item The case binder, which refers to the whole result of evaluating the scrutinee;
            \item The linear components of a constructor pattern, which refer to expressions that may contain linear resources.
        \end{itemize}

%To guarantee all post-evaluation unconsumed scrutinee resources are consumed in
%the alternative, without statically knowing
%Statically we can't know which resources are ``transferred'', but  guarantee
%
\end{enumerate}

%is not sufficient to
%consume all resources used by the scrutinee, since sub-expressions such
%as constructor arguments will be left unevaluated and may still contain
%(``parts of'') the linear resources. To \emph{fully} consume all
%resources occurring in the scrutinee, all linear components of the
%constructor must also be fully evaluated, as witnessed by the
%$\textsc{Alt}_0$ rule above.
%%
%In essence, to type cases scrutinizing expressions not in WHNF, we need to
%forbid the usage of the scrutinee resources while tracking that we necessarily
%``finish consuming'' them, either via the case binder, or by linearly using all
%linear pattern-bound variables introduced in the alternative.

% We tackle this in due time, in the proof irrelevance section.
% \begin{itemize}

% \item The scrutinee resources must \emph{not} be used directly in the case alternatives;
% \item But the result of evaluating the scrutinee to WHNF must still be
% consumed, as all sub-expressions of the scrutinee remain unevaluated and must
% be consumed.
% \item Since the scrutinee resources cannot be consumed directly, they must be
% consumed indirectly through $\D$-variables, namely, either the case binder, or
% the linear pattern-bound variables introduced in the alternative.

% \end{itemize}

% In alternatives of a case where the scrutinee is not in
% WHNF, we must also consume the result of evaluating the scrutinee to WHNF, but the
% scrutinee resources must definitely not be available for consumption. In
% practice, the result of evaluating the scrutinee must be consumed by using
% either the case binder or all the linear components of a constructor pattern,
% except for patterns matching an unrestricted pattern, which are handled with
% the $Alt0$ rule. For WHNF scrutinees, we encode mutual exclusivity between
% consuming resources directly, with the case binder, or through linear pattern
% variables, by introducing the latter two as $\D$-bound variables.  In essence,
% for the counterpart not-WHNF scrutinees, either the case binder or linear
% pattern-bound variables \emph{must} still be used to guarantee the evaluation
% result is consumed (thus their usage environment cannot be empty), but the
% scrutinee resources cannot be used directly.

To encode  linear resources that cannot be
directly used (i.e.,~to which the $\textsc{Var}$ rule is not
applicable) we introduce \emph{proof irrelevant} resources, written as linear resources
within square brackets $[ x{:}\s]$ and lifted to contexts as $[\D]$.
Proof irrelevant resources
are linear resources in every sense, meaning they must be used
exactly once. However, since proof irrelevant resources cannot be
discarded or used directly, they have to be consumed \emph{indirectly} via
$\D$-bound variables, namely, the case binder, or, in mutual exclusion, the linear pattern-bound
variables.

Hence, to type a case expression whose scrutinee is not in WHNF, we
type the scrutinee with linear resources $\D$ and the case
alternatives by introducing the case binder with a usage environment $[\D]$,
having the same proof irrelevant linear context $[\D]$ in the typing
environment, and annotating the judgement with the proof irrelevant resources
for use in the $\Rightarrow_{\textsf{NWHNF}}$ judgement:
\[
\TypeCaseNotWHNF
\]
Note how the rule is similar to the one for scrutinees in WHNF, but
requires the resources in the case binder, typing environment, and
judgement annotation to be made ``irrelevant''.

% In practice, we can't know which resources are consumed by evaluating a given
% expression. The resources become in a limbo state -- they cannot be used
% directly because they might have been consumed, but they mustn't be considered
% as consumed, because they might not have been.  We say these resources enter a
% proof irrelevant state. They must still be tracked as though they weren't
% consumed, but they cannot be used directly to construct the program. How can we
% ensure these proof irrelevant resource variables are fully consumed? With usage
% environments -- for the case binder and for the pattern variables, and
% otherwise propagate

% \todo[inline]{The case binder and pattern variables will consume the scrutinee
% resources, be those irrelevant or relevant resources}

Finally, we recall the tentative $Case_\textrm{WHNF}$ rule presented before and
highlight its flaw: the $\G;\D \vdash_{alt} \rho \to e :^z_{\D_s} \s \Rightarrow_{\textsf{WHNF}}
\vp$ judgement is only well-defined for patterns $\rho$ matching the WHNF form
of the scrutinee, as the distribution of resources per constructor components
only makes sense for the constructor pattern matching the scrutinee.
% Essentially, if the scrutinee is in WHNF the matching alternative is easily
% determined, and must be treated with the specialized $\Mapsto$ judgement, which
% only applies to the matching constructor.
% %
Alternatives not matching the scrutinee could use resources arbitrarily as they
will never be executed. We uniformly treat non-matching alternatives
as if the scrutinee were not in WHNF. Having introduced proof irrelevant
resources, we can now present the full $Case_\textrm{WHNF}$ rule:
\[
\TypeCaseWHNF
\]
We note that it might seem unusual to specialize a rule for expressions in
WHNF, as programs scrutinizing an expression in WHNF are rarely
written by humans.
Yet, our system is designed to be suitable for optimising compilers
in which intermediate programs commonly scrutinize expressions in WHNF.
%
% Crucially, type preservation for the case-reduction substituting the
% case binder and pattern variables in the alternative is not possible
% to prove without branching on WHNF-ness, since otherwise the
% $\D$-substitution is not well-defined.  \todo[inline]{What is the
%   $\Delta$-substitution? Clarify}

\subsubsection{Splitting and tagging fragments}

%% NOTA -- Sempre a repetir a mesma coisa
% Intuitively, in case alternatives whose scrutinee is not in WHNF,
% % (and for scrutinees in WHNF which don't match the case alternative)
% the proof-irrelevant resources introduced by the case expression must be fully
% consumed, either via the case binder $z$, or by using all linear pattern-bound
% variables (for uniformity, we also treat alternatives that do not match a
% scrutinee in WHNF this way).

As opposed to scrutinees in WHNF, where the resources used to type a scrutinee
can be cleanly divided amongst the various sub-expressions of a constructor
application and, henceforth, each pattern variable, there is no direct mapping
between the resources typing a scrutinee not in WHNF and the usage
environments of pattern variables in any alternative.

%
% That is, there is no direct mapping between the usage environments of the
% linear pattern-bound variables and the resources used in the scrutinee.
% \todo{WAIT, there never was!
% Only when the K matches the scrutinee. Maybe we need a separate judgement for
% typing other constructors, which would be standalone and show up in this
% section too?}
%
We introduce \emph{tagged resources} as a means to enforce that all pattern-bound
variables for a scrutinee not in WHNF are either \emph{jointly} used to consume
all resources occurring in the environment, or not at all (instead, the case
binder may be used). Given linear resources $[\D_s]$ used to type a scrutinee,
and a pattern $K~\ov{x_\omega},\ov{y_i}$ with $i$ linear components, we assign
a usage environment $\D_i$ to each linear pattern variable where $\D_i$ is
obtained from the scrutinee environment \emph{tagged} with the constructor name
and linear-variable index $\lctag{\irr{\D_s}\!}{K_i}$. Then, $y_i{:}_{\D_i}\s$ is
introduced in $\G$, just like other $\D$-variables.
\[
  \begin{array}{cc}
    \TypeAltNNotWHNF & \TypeVarSplit
    \end{array}
\]
%
% The tag consists of a constructor name $K$ and an index $i$ identifying the
% position of the pattern variable among all bound variables in that pattern.
%
Having uniquely tagged the resources in the usage environment of each pattern
variable, we need only to express that (1) the pattern-bound $\D$-variables can
be used (i.e., the tagged resources need be available in the linear
environment in order for the $\textsc{Var}_\D$ rule to be applicable) and (2)
if a $K$-pattern-bound $\D$-variable is consumed, all remaining $K$-$\D$-variables,
standing for the remaining linear components of the same pattern, must also be
consumed.

To satisfy these two constraints, we introduce a $\textit{Split}$ rule that
allows a linear resource $x{:}_1\s$ to be split into $n$ resources at a given
constructor $K$, where $n$ is the number of linear components of the
constructor, and each resource resulting from the split is \emph{tagged} with
$K$ and the positional index of a linear component (i.e. $x{:}_1\s$ can be
split into $\ov{\lctag{x{:}_1\s}{K_i}}^n$).
%
By assigning to each pattern variable a \emph{fragment} of the scrutinee
resources (with a tag), we require the scrutinee resources to be
$\textsc{Split}$ in order to use pattern variables at all.  Moreover, the
remaining tagged resources cannot be used directly, yet need to still be consumed
exactly once. Thus, the choice to consume the tagged resources via the usage
environments of the other pattern variables is forced, ensuring that no
variable for a constructor's linear component can go unused (the tagged environments are disjoint).

For instance, in the term $\lambda x.~\ccase{f~x}{z~\{K~a~b\to
  (a,b)\}}$, where $x$ is a linear variable, the case alternative is
typed with $\irr{x}$,
the case binder $z$ is introduced as $\z[\irr{x}]$, and the pattern variables
are introduced as $\var[a][\lctag{\irr{x}}{K_1}]$ and
$\var[b][\lctag{\irr{x}}{K_2}]$, assuming both components of $K$ are linear.
%
The occurrences of $a$ and $b$ are well-typed because we can first
$\textsc{Split}$ $[x{:}_1\s]$ into $\lctag{[x{:}_1\s]}{K_1}, \lctag{[x{:}_1\s]}{K_2}$,
%
% since for any of the scrutinee
% resources to be used by a linear pattern-bound variable usage, the
% resources must be $Split$ for the fragments corresponding to that
% $\D$-var to be consumed, and, consequently, the remaining fragments
% have to be consumed through the other linear pattern-bound variables.
%
noting that $Split$ can be applied both to relevant and proof irrelevant linear
resources in $\D$.

% Using tags for fragments instead of fractions (e.g. $\D_s*i/n$) is necessary
% to guarantee we cannot use the same variable multiple times to consume
% multiple fractions of the resource. It also has the added benefit of allowing
% mixing of pattern variables bound at different alternatives (e.g.~$\lambda
% x~y.~\ccase{(x,y)}{(a,b)\to\ccase{(a,b)}{(z,w)\to(a,w)}}$).

%%%%% \section{Linear Core Examples}
%%%%% 
%%%%% \todo[inline]{If I have no time...}
%%%%% 
%%%%% Linear Mini-Core~\cite{cite:minicore} lists examples of Core programs where
%%%%% semantic linearity must be understood in order for them to be well-typed. In
%%%%% this section, we show those examples in Linear Core ($\lambda^\pi_\Delta$),
%%%%% briefly explaining why they are indeed well-typed.
%%%%% 
%%%%% \paragraph{Equations}
%%%%% 
%%%%% The Linear Haskell function is compiled in Linear Core as\\
%%%%% %
%%%%% \begin{minipage}{0.47\textwidth}
%%%%% \begin{code}
%%%%% data C = Red | Green | Blue
%%%%% f :: C -o C -o C
%%%%% f Red q = q
%%%%% f p Green = p
%%%%% f Blue q = q
%%%%% \end{code}
%%%%% \end{minipage}
%%%%% \begin{minipage}{0.47\textwidth}
%%%%% \[
%%%%% \begin{array}{ll}
%%%%% \lambda p{:}_1C~q{:}_1C.~\ccase{p}{p2{:}_{\{p\}}C \\
%%%%% \{Red \to q \\
%%%%% ; \_ \to \ccase{q}{q2{:}_{\{q\}}C\\
%%%%%   \{Green \to p2\\
%%%%%   ; \_ \to \ccase{p2}{p3{:}_{\{p\}}C \\
%%%%%   \{Blue \to q2\}} \}} \}}
%%%%% \end{array}
%%%%% \]
%%%%% \end{minipage}
%%%%% 
%%%%% \paragraph{Unrestricted Fields}
%%%%% 
%%%%% The following is well-typed:
%%%%% Let $\datatype{K}{K : A \lolli B \to C}$, and $f$:
%%%%% \[
%%%%% \lambda \xl.~\ccase{x}{\var[z][x]~\{ K~a~b \to (z, b) \}}
%%%%% \]
%%%%% 
%%%%% \paragraph{Wildcard}
%%%%% 
%%%%% The following is ill-typed:
%%%%% \begin{code}
%%%%% f = \x -> case x of z { _ -> True }
%%%%% \end{code}
%%%%% 
%%%%% \paragraph{Duplication}
%%%%% 
%%%%% The following is ill-typed:
%%%%% \begin{code}
%%%%% data Foo = Foo A
%%%%% f = \x -> case x of z { Foo a -> (z, a) }
%%%%% \end{code}


% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Metatheory
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metatheory of Linear Core\label{sec:main:metatheory}}

We develop the metatheory of Linear Core by first 
presenting the operational semantics of $\lambda^\pi_\D$,
consisting of a lazy natural semantics in the
style of Launchbury~\cite{10.1145/158511.158618}.
This semantics conveys the expected behavior of an implementation of
lazy evaluation and is agnostic to any linearity information.
Such a semantics is ill-suited for reasoning about
linearity and so we develop an \emph{instrumented} linearity-aware semantics that is
enriched with sufficient information to allow us to establish type
safety, thus showing that linearity is preserved. We show that the natural
and instrumented semantics are bisimilar for well-typed terms and so
derive type safety in the natural semantics
(Section~\ref{sec:typesafe}). Finally, we show that multiple optimising
transformations such as those performed by GHC on Linear Core are
type preserving
(Section~\ref{sec:optimisations-preserve-types-meta}), and thus
linearity preserving.

\subsection{Operational Semantics}

The Launchbury-style natural semantics, presented in Figure~\ref{fig:opsem}, captures
standard lazy evaluation while ignoring linearity information.
% The second
% semantics is significantly instrumented with type information and is thus
% \emph{linearity aware}, resulting in a stuck state when a linear
% variable is used more than once. The former is a more direct model of
% an implementation of lazy evaluation, however it is not so convenient
% to reason about formally. The latter semantics is augmented with the additional
% information necessary to strengthen the induction hypothesis to make our
% type safety proofs go through.
% %
% We show that for well-typed terms, the two semantics coincide. 
%
%Both semantics are
The natural semantics is equipped with an evaluation environment that
maps variables to expressions and is
mutated in order to express shared evaluation. Terms are explicit about
their sharing (in the sense of shared reductions in lazy evaluation),
and so we perform a translation step that makes all sharing explicit
through let-binders (see Appendix~\ref{app:opsem}).
We write $\llet{\ov{x_i{:}_{\Delta_i}\sigma = e_i}}{e'}$ for the iterated
let-binding of variables $\ov{x_i}$. 

\begin{figure}

  {\small
    \[
  \begin{array}{c}
    \infer[]
    {\,}
    {\Theta : \Lambda p.e \Downarrow \Theta : \Lambda p.e}
    \qquad
    \infer[]
    {\Theta : e\Downarrow \Theta' : \Lambda p.e' \quad \Theta' :
    e'[\pi/p]\Downarrow \Theta'' : v}
    {\Theta : e~\pi\Downarrow \Theta'' : v }\\[1.5em]
    \infer[]
    {\,}
    {\Theta : \lambda x:_\pi \sigma . e \Downarrow \Theta : \lambda x:_\pi \sigma . e }
    \qquad
    \infer[]
    {\Theta : e \Downarrow \Theta' : \lambda y:_\pi \sigma . e' \quad
    \Theta' : e'[x/y] \Downarrow \Theta'' : v }
    {\Theta : e~x \Downarrow \Theta'' : v}\\[1.5em]
    \infer[]
    {(\Theta,  x:_\omega \sigma = e) : e \Downarrow \Theta' : v}
    {(\Theta , x:_\omega \sigma = e) : x \Downarrow (\Theta',x:_\omega
    \sigma = v) : v}
    \qquad
    \infer[]
    {(\Theta,x:_\omega \sigma = e) : e' \Downarrow \Theta' : v}
    {\Theta : \llet{x{:}_{\Delta}\sigma = e}{e'}\Downarrow \Theta' : v
    }\\[1.5em]
    \infer[]
    {\,}
    {\Theta : K~\ov{x_i} \Downarrow \Theta : K~\ov{x_i}}
    \qquad
    \infer[]
    {\Theta : e \Downarrow \Theta' : K~\ov{x_i} \quad
    \Theta' : e'\ov{[x_i/y_i]}[K~\ov{x_i}/z] \Downarrow \Theta'' : v }
    {\Theta :
    \ccase{e}{z{:}_{\Delta'}\sigma~\{{\dots,K~\ov{y_i} \to e', {\dots}}\}}
    \Downarrow \Theta'' : v}\\[1.5em]
    \infer[]
    {\Theta : e \Downarrow \Theta' : K~\ov{x_i} \quad
    \Theta' : e'[K~\ov{x_i}/z] \Downarrow \Theta'' : v }
    {\Theta :
    \ccase{e}{z{:}_{\Delta'}\sigma~\{\dots , \_\to
    e'}\} \Downarrow \Theta'' : v}
    \qquad
    \infer[]
    {% (\Gamma, \overline{x_i:_\omega \sigma_i = e_i}) : e_1 \Downarrow \Theta_1
    % : v_1 \dots  (\Gamma, \overline{x_i:_\omega \sigma_i = e_i}) : e_n
    % \Downarrow \Theta_n : v_n \quad
    (\Theta, \overline{x_i:_\omega \sigma_i = e_i}) : e' \Downarrow \Theta'
    : v
    }
    {\Theta : \lletrec{\overline{x_i{:}_{\Delta}\sigma_i = e_i}}{e'}
    \Downarrow \Theta' : v}
    \end{array}
\]}
    \caption{Natural Semantics of $\lambda^\pi_\D$\label{fig:opsem}}
  \end{figure}

  The natural semantics is defined via the relation
$\Theta : e \Downarrow \Theta' : v$ where $e$ is an expression, $v$ a
value, and $\Theta$ and $\Theta'$ are evaluation environments with bindings of
the form $x:_\omega\sigma = e$ which assigns the expression $e$ to the variable
$x$ of the given type $\s$. The rules are standard, augmenting the runtime
environment with let-bound expressions which are evaluated (only once) if the
corresponding let-bound variable is forced.


% The second
% semantics is significantly instrumented with type information and is thus
% \emph{linearity aware}, resulting in a stuck state when a linear
% variable is used more than once. The former is a more direct model of
% an implementation of lazy evaluation, however it is not so convenient
% to reason about formally. The latter semantics is augmented with the additional
% information necessary to strengthen the induction hypothesis to make our
% type safety proofs go through.
% %
% We show that for well-typed terms, the two semantics coincide. 

While the natural semantics is a mostly direct model of an implementation
of lazy evaluation, it is inconvenient for formal reasoning about
well-typed linear terms.
%
We follow an approach
similar to that of \cite{cite:linearhaskell}, defining
an \emph{instrumented} operational semantics in which linear variables are
erased from 
the runtime environment once they are forced, ensuring that any term violating linearity
will result in a stuck state. The semantics is also type-aware and
carries with it sufficient data to reconstruct typing derivations for
the purposes of showing type safety.

The instrumented semantics is presented in
Figure~\ref{fig:linopsem}, defining the judgment $\Gamma ; \Delta \vdash (\Theta \mid e) \Downarrow (\Theta'
\mid v) : \sigma , \Sigma$ where $\Gamma$ and $\Delta$ are typing
contexts for expressions in $\Sigma$
($\Gamma$ tracks unrestricted and $\Delta$-bound variables, $\Delta$ tracks linear
assumptions);
$\Theta$ and $\Theta'$ are evaluation environments, consisting of bindings of the form
$x :_\pi \sigma = e$ or $x :_\Delta \sigma = e$; $e$ is the expression being evaluated and $v$
its resulting value, both of type $\sigma$; $\Sigma$ is a list of assignments of the form
$e : \tau$ which are expressions in which
bindings in $\Theta$ may also be used. This additional data is needed to
inductively show that the overall evaluation state is well-typed (and
linearity preserving). The rules mostly mirror those of the natural
semantics, with the exception of the linear variable rule which erases
the binding from the execution environment. Both semantics define
evaluation relations of the form $a \Downarrow b$, where $a$ and $b$
are evaluation states. We also rely on a notion
of partial derivations and partial evaluation (see
Appendix~\ref{app:opsem}), written $a\Downarrow^* b$, which allows us
to state and reason about a progress property.

\begin{figure}
\[
  \begin{array}{c}
    \infer[]
    {\,}
    {\Gamma;\Delta \vdash (\Theta \mid \Lambda p.e) \Downarrow (\Theta \mid
    \Lambda p.e) : \forall p . \sigma , \Sigma }
    \\[1.5em]
    \infer[]
    {\Gamma ; \Delta \vdash (\Theta \mid  e) \Downarrow (\Theta' \mid
    \Lambda p.e') : \forall p . \sigma , \Sigma \quad \Gamma ;\Delta \vdash
      (\Theta' \mid e'[\pi/p]) \Downarrow (\Theta'' \mid v) : \sigma[\pi/p], \Sigma}
    {\Gamma ; \Delta \vdash (\Theta \mid e~\pi) \Downarrow (\Theta''
      \mid v) : \sigma[\pi/p] , \Sigma  }\\[1.5em]
    \infer[]
    {\,}
    {\Gamma ;\Delta \vdash (\Theta \mid \lambda x:_\pi \sigma . e)
    \Downarrow (\Theta \mid \lambda x:_\pi\sigma .e) : \sigma
    \rightarrow_\pi \tau,\Sigma }\\[1.5em]
    \infer[]
    {\Gamma;\Delta \vdash  (\Theta \mid e) \Downarrow (\Theta' \mid
    \lambda y:_1 \sigma . e') : \sigma \rightarrow_1 \tau , x:\sigma, \Sigma
    \quad
    \Gamma ; \Delta \vdash (\Theta' , y:_{1} \sigma = x \mid e') \Downarrow (\Theta''
    \mid v) : \tau , \Sigma  }
    {\Gamma ; \Delta\vdash (\Theta \mid  e~x ) \Downarrow (\Theta''
    \mid v) : \tau , \Sigma }\\[1.5em]
           \infer[]
    {\Gamma;\Delta \vdash  (\Theta \mid e) \Downarrow (\Theta' \mid
    \lambda y:_\omega \sigma . e') : \sigma \rightarrow_\omega \tau , x:\sigma, \Sigma
    \quad
            \Gamma ; \Delta \vdash (\Theta' \mid e'[x/y]) \Downarrow (\Theta''
    \mid v) : \tau , \Sigma  }
    {\Gamma ; \Delta\vdash (\Theta \mid  e~x ) \Downarrow (\Theta''
    \mid v) : \tau , \Sigma }\\[1.5em]
     
       \infer[]
    {\Gamma ; \Delta  \vdash (\Theta  , x:_{\Delta'} \sigma = e\mid e)
    \Downarrow (\Theta' \mid v) : \sigma , \Sigma \and \D'' = \D' \setminus (\Theta \setminus \Theta')}
    {\Gamma ; \Delta \vdash (\Theta , x:_{\Delta'} \sigma = e \mid x)
      \Downarrow (\Theta' , x:_{\Delta''} \sigma = v \mid v) : \sigma,
    \Sigma }
    \\[1.5em]
           \infer[]
    {\Gamma ;\Delta  \vdash (\Theta \mid e)
    \Downarrow (\Theta' \mid v) : \sigma,\Sigma}
    {\Gamma ; \Delta \vdash (\Theta , x:_1 \sigma = e \mid x)
    \Downarrow (\Theta' \mid v) : \sigma,\Sigma}
    \\[1.5em]
    
    \infer[]
    {\Gamma ;\Delta \vdash (\Theta,x:_{\Delta'} \sigma = e \mid e')
    \Downarrow (\Theta' \mid v) : \tau,\Sigma}
    {\Gamma ; \Delta \vdash (\Theta \mid \llet{x{:}_{\Delta'}\sigma =
    e}{e'})\Downarrow (\Theta' \mid v) : \tau , \Sigma
    }\\[1.5em]
    
    \infer[]
    {\,}
    {\Gamma ; \Delta \vdash (\Theta \mid K~\ov{x_i}) \Downarrow
    (\Theta \mid K~\ov{x_i}) : T , \Sigma}
    \\[1.5em]
    
    \infer[]
    { K : \ov{ \sigma_i
    \rightarrow_\omega \sigma_j \lolli} T
    \\
    \Gamma, \ov{y_i :_\omega \sigma_i} ;\Delta , \ov{y_j :_1 \sigma_j} \vdash (\Theta \mid e) \Downarrow (\Theta' \mid
      K~\ov{x_i}) : T , e' : \tau ,\Sigma \\
    \Gamma ;\Delta \vdash (\Theta' \mid e'\ov{[x_i/y_{i,j}]}[K~\ov{x_i}/z]
    ) \Downarrow (\Theta'' \mid v) :\tau , \Sigma }
    {\Gamma ;\Delta \vdash (\Theta \mid
    \ccase{e}{z{:}_{\Delta'}T~\{{\dots,K~\ov{y_{i,j}} \to e', {\dots} }\}})
    \Downarrow (\Theta'' \mid  v) : \tau , \Sigma}\\[1.5em]

    
    \infer[]
    {K : \ov{ \sigma_i
    \rightarrow_\omega \sigma_j \lolli} T\\
    \Gamma ; \Delta, z{:}_1\s \vdash (\Theta \mid e) \Downarrow (\Theta' \mid
    K~\ov{x_i}) : T , e', \Sigma \quad
    \Gamma ;\Delta \vdash (\Theta' \mid  e'[K~\ov{x_i}/z])
    \Downarrow (\Theta'' \mid v) : \tau,\Sigma }
    {\Gamma ; \Delta \vdash (\Theta \mid 
    \ccase{e}{z{:}_{\Delta'}T~\{\dots , \_\to
    e'}\}) \Downarrow (\Theta'' \mid v) : \tau}
    \\[1.5em]
    \infer[]
    {% (\Gamma, \overline{x_i:_\omega \sigma_i = e_i}) : e_1 \Downarrow \Theta_1
    % : v_1 \dots  (\Gamma, \overline{x_i:_\omega \sigma_i = e_i}) : e_n
    % \Downarrow \Theta_n : v_n \quad
    \Gamma ; \Delta \vdash (\Theta, \overline{x_i:_{\Delta'} \sigma_i =
    e_i} \mid e' )\Downarrow (\Theta'
    \mid v) : \tau
    }
    {\Gamma ;\Delta \vdash (\Theta \mid \lletrec{\overline{x_i{:}_{\Delta'}\sigma_i = e_i}}{e'})
    \Downarrow (\Theta' \mid v) : \tau}

   \end{array}
 \]
 \caption{Instrumented Operational Semantics~\label{fig:linopsem}}
  
\end{figure}

\subsection{Type Safety}\label{sec:typesafe}

Our results rely on a series of lemmas relating linear, unrestricted and
$\Delta$-bound variables, as well as a lemma characterizing irrelevant
resources.
%
% Additionally, we state our assumptions that outline an isomorphism between
% using a linear variable $\xl$ and a $\D$-variable $\xD$ that consumes existing
% resources $\D$, for any $\D$.


\renewcommand{\DeltaLinearRelationLemma}{
\begin{restatable}[$\Delta$-bound to Linear]{lemma}{deltaone}\label{lem:deltaone}
% Any $\Delta$-variable with a fully-irrelevant usage environment can be made a linear variable as long as its irrelevant environment is dropped from the linear environment (and the unrestricted env. is updated accordingly).\\
If $\G,\x[\irr{\D}]; \irr{\D},\D' \vdash e : \vp$ 
then $\G[x/\irr{\D}]; \D',\xl \vdash e :\vp$.
\end{restatable}
}

\renewcommand{\LinearDeltaRelationLemma}{
  \begin{restatable}[Linear to $\Delta$-bound]{lemma}{onedelta}\label{lem:onedelta}
If $\G; \D',\xl \vdash e :\vp$
then $\G[\D/x],\xD; \D,\D' \vdash e : \vp$ ($\Delta$ fresh).
\end{restatable}
}

\renewcommand{\DeltaUnrestrictedRelationLemma}{
\begin{restatable}[Unrestricted and $\Delta$-bound]{lemma}{undelta}\label{lem:undelta}
%An unrestricted variable is equivalent to a $\D$-var with an empty usage environment.\\
$\G,\xo; \D \vdash e : \vp$ iff $\G,\x[\cdot]; \D \vdash e : \vp$
\end{restatable}
}

\paragraph{$\Delta$-bound variables} % Our development relies on a characterization of $\D$-bound
% variables
A well-typed program with a linear variable ($\xl$) is equivalently
well-typed if the linear variable were instead $\D$-bound ($\xD$) with
usage environment $\D$, with $\D$ available in the linear context (and the unrestricted context updated accordingly).

\LinearDeltaRelationLemma


\noindent Dually, any $\Delta$-bound variable with an irrelevant usage
environment can be made into a linear variable as long as its
(irrelevant) environment is dropped from the linear context.

% Dually, a well-typed program with resources $\D$ and $\D$-bound
% variable ($\xD$) is equivalently well-typed, as long as $\D$ is consumed
% through the use of $x$, if $x$ is moved to the linear context, resources $\D$
% are removed from the linear context, and occurrences of $\D$ whole in usage
% environments are substituted by $x$ (occurrences of fragments of $\D$ in usage
% environments are unimportant since $\D$ was consumed whole by $x$, not by any
% of the fragment-using $\D$-vars).

\DeltaLinearRelationLemma

% Intuitively, a linear variable 

\noindent Finally, unrestricted and $\D$-bound
variables with an empty usage environment are equivalent.

\DeltaUnrestrictedRelationLemma

\paragraph{Irrelevance}
%
Proof irrelevant resources can only be consumed
indirectly, essentially encoding that the (non-WHNF) case scrutinee
resources must be consumed through the case binder or the linear
pattern-bound variables.
%
As a case expression is evaluated, the scrutinee will eventually
reduce to WHNF,
which must then be typed with rule $Case_{\textrm{WHNF}}$.
%
Crucially, the two case rules must be in harmony in the system, in the sense that
case expressions typed using the $Case_{\textrm{Not WHNF}}$ rule must also be
well-typed by the $Case_{\textrm{WHNF}}$ once the scrutinee is evaluated to WHNF.

% The type preservation theorem states that a well-typed expression
% remains well-typed in the presence of evaluation. Specifically, when the case
% expression whose scrutinee is evaluated to WHNF is handled in the
% preservation proof.

% The \emph{Irrelevance} lemma is required to prove preservation for that
% evaluation case. We need to prove that the alternatives of a case expression
% typed with proof irrelevant resources are still well-typed when the proof
% irrelevant resource is substituted by the scrutinee resources as it is evaluated to WHNF.
% In this sense, the \emph{Irrelevance} lemma witnesses the soundness of typing a
% case alternative with proof irrelevant resources in a certain context with respect to
% typing the same expression with arbitrary resources (we note, however, typing
% an alternative with proof irrelevant resources is not complete wrt using
% arbitrary resources -- a counter example needs only to use a resource
% directly).

\WHNFConvSoundness

The \emph{Irrelevance} lemma witnesses the soundness of typing a
case alternative with proof irrelevant resources with respect to
typing the same expression with arbitrary resources. However, typing
a case alternative with proof irrelevant resources is not complete wrt using
arbitrary resources -- a counter example needs only to use a resource
directly.

% \noindent Intuitively, the lemma holds since proof irrelevant resources can
% only be used through the case binder or pattern-bound variables. If we
% consistently replace the proof irrelevant resources both in the typing
% environment and in the usage environments containing them, the expression
% remains well-typed. We note that the proof irrelevant resources are always
% unique when introduced in such a case alternative (we always take the scrutinee
% environment to make irrelevant, and allow nested ``irrelevantness''), so the
% case binder has the only occurrence of those resources in the $\G$ environment.
% % (being somewhat akin to congruence).
% %
% The proof is given in Section~\ref{sec:proof:irrelevance}.

%\subsection{Type safety\label{sec:type-safety-meta}}
% The $\lambda^\pi_\D$ type system is sound: well-typed programs in Linear Core do not
% get \emph{stuck} and their evaluation preserves linearity.
We prove type safety of the Linear Core system via the standard type
preservation and progress results. As is customary, we make use of multiple
substitution lemmas, one for each kind of variable: unrestricted variables
$\xo$, linear variables $\xl$, and $\D$-bound variables $\xD$. The
development is reported in Appendices~\ref{app:proofs}
and~\ref{app:opsem}, where type safety is established directly for the
instrumented semantics and ported to the natural semantics via a
bisimulation argument.

  \begin{theorem}[Type Preservation]
    For any well-typed evaluation state $a$, if $a \Downarrow
    b$ or $a \Downarrow^* b$ then $b$ is well-typed.
\end{theorem}
\begin{theorem}[Progress]
Let $a$ be a well-typed evaluation state. For any partial evaluation $a \Downarrow^* b$ 
the evaluation can be extended.
\end{theorem}

% We start with the auxiliary results, as we will make use of them in a select part of the preservation proof.

% \TypePreservationTheorem
% %
% \ProgressTheorem
% \noindent Type preservation states that a well-typed expression $e$ that
% evaluates to $e'$ remains well-typed under the same context:
%
% Type preservation
% % ($\S$~\ref{sec:proof:type-preservation})
% follows by structural induction on the reductions $e \longrightarrow
% e'$ from the operational semantics. Most cases are straightforward, appealing to one or more
% substitution lemmas (see Appendix~\ref{sec:proof:type-preservation}). The most
% interesting case is that of case expressions whose scrutinee can be further
% evaluated -- we branch on whether the scrutinee becomes in WHNF and appeal to Lemma~\ref{lem:irrev} if so.
%
% This case guarantees that the separation of rules for treating scrutinees is
% consistent, in the sense that a well-typed case expression with a scrutinee not
% in WHNF remains well-typed after the scrutinee is evaluated to WHNF.
%
%
%
%\noindent
% Progress states that the evaluation of a well-typed term does not block:
% Similarly, progress is proved by induction on typing ($\S$~\ref{sec:proof:progress}).

% \subsubsection{Substitution Lemmas}

% The preservation and progress theorems depend on multiple substitution lemmas,
% one for each kind of variable, as is standard.
% % The proofs are given in Section~\ref{sec:proof:substitution-lemmas}.
% % The ... themselves diverge from their common formulation, because
% % $\D$-variables refer to linearly bound variables, so substitution must take into account


% The linear substitution lemma states that a well-typed expression $e$ with a
% linear variable $x$ of type $\s$ remains well-typed if
% occurrences of $x$ in the $e$ are replaced by an expression $e'$ of the same
% type $\s$, and occurrences of $x$ in the linear context and in usage
% environments of $\D$-bound variables are replaced by the linear context $\D'$
% used to type $e'$:

% \LinearSubstitutionLemma

% \noindent Where $\G[\D'/x]$ substitutes all occurrences of $x$ in the usage
% environments of $\D$-variables in $\G$ by the linear variables in $\D'$.
% % ($x$ couldn't appear anywhere besides usage environments of $\D$-bound variables, since $x$ is linear).

% The substitution of the resource in the usage environments is illustrated
% by the following example. Consider the term $\llet{y = use~x}{y}$ where $use$ and $x$ are free variables:
% if we replace occurrences of $x$ by $e'$ (where $\G;\D \vdash e : \s$), then the
% ``real'' usage environment of $y$ goes from $\{x\}$ to $\D$. If we don't update
% the usage environment of $y$ accordingly, we'll ultimately be typing
% $y{:}_{\{x\}}\vp$ with $\D$ instead of $x$, which is not valid.

% The linear substitution lemma extends to case alternatives as well.
% The lemma for substitution of linear variables in case alternatives is similar
% to the linear substitution lemma, applied to the case alternative judgement.
% % Is slightly more involved, in the sense that there are more environments in which the
% % substitution $[\D/x]$ must be applied (for the same reason):
% %
% \LinearSubstitutionAltsLemma
% %
% \noindent We further require that the environment annotated in the case
% alternative judgement, $\D_s$, is a subset of the environment used to type the
% whole alternative $\D_s \subseteq \D$. In all occurrences of the alternative
% judgement (in $Case_{\textrm{WHNF}}$ and $Case_{\textrm{Not WHNF}}$), the
% environment annotating the alternative judgement is \emph{always} a subset of
% the alternative environment.

% The substitution lemma for unrestricted variables follows the usual
% formulation, with the added restriction (common to linear type systems) that
% the expression $e'$ that is going to substitute the unrestricted variable $x$
% is typed on an empty linear environment:
% %
% \UnrestrictedSubstitutionLemma
% %
% \noindent Similarly, we also prove the substitution of unrestricted variables preserves types on an alternative case expression:
% %
% \UnrestrictedSubstitutionAltsLemma

% Finally, we introduce the lemma stating that substitution of $\D$-bound
% variables by expressions of the same type preserves the type of the original
% expression.
% %
% What distinguishes this lemma from traditional substitution lemmas is that the
% usage environment $\D$ of the variable $x$ being substituted by expression $e'$
% must match exactly the typing environment $\D$ of $e'$ and the
% environment of the original expression doesn't change with the substitution:
% %
% \DeltaSubstitutionLemma
% %
% \noindent Intuitively, if $x$ is well-typed with $\D$ in $e$, substituting $x$
% by an expression $e'$ which is typed in the same environment $\D$ allows the
% distribution of resources $\D,\D'$ used to type $e$ across sub-derivations to remain
% unchanged. To prove the theorems, we don't need a ``stronger'' substitution of
% $\D$-vars lemma (allowing arbitrary resources $\D''$ to type $e'$, as in other
% substitution lemmas), as we only ever substitute $\D$-variables by expressions
% whose typing environment matches the variables usage environment. However, it
% is not obvious whether such a lemma is possible to prove for $\D$-variables
% (e.g. let $\G;\D \vdash e :\s$ and $\G; \D' \vdash \llet{x = e'}{x}$, if we
% substitute $e$ for $x$ the resources $\D'$ are no longer consumed).

% The $\D$-substitution lemma on case alternatives reflects again that the typing
% environment of the expression substitution the variable must match its usage
% environment. We recall that $\D_s \subseteq \D,\D'$ states that the annotated
% environment is always contained in the typing environment, which is true of all
% occurrences of this judgement. An alternative formulation of this lemma could
% instead explicitly list $\D_s$ as part of the typing environment for the same
% effect:

% \DeltaSubstitutionAltsLemma

% The proofs for substitution lemmas of linear, unrestricted, and
% $\D$-variables are available in Section~\ref{sec:proof:substitution-lemmas}.

%TODO! Substitution of proof-irrelevant linear variables preserves typing. The
%term always remains the same because $x$ cannot occur in any term, however, all
%variables that refer to $x$ in their usage environment must now refer the usage env. of the substitee (e.g. $[x] => [\D]$).
%This seems trivial to see correct, since all occurrences are in environments, so we get some equivalence similar to the one we need for the proof of Alt0.
%
%TODO: Multiplicity substitution preserves typing lemma
%
%TODO: Canonical forms lemma
%
%TODO: Corollary of $\Delta$-var subst. for $\ov{\Delta}$
%
%TODO: Constructor app typing:
%If $\Gamma, \Delta \vdash K~\ov{e}$ and $K{:}\ov{\sigma\to\pi}~T~\ov{p} \in \Gamma$ and $\hasnolinearvars{\Gamma}$
%then $\ov{\Gamma, \Delta_i \vdash e_i : \sigma_i}$

\subsection{Optimisations preserve linearity\label{sec:optimisations-preserve-types-meta}}
%\todo[inline]{Check Commuting case-let in Fig.~\ref{fig:opttrans}!}
A main goal of the Linear Core type system is 
to serve as a typed intermediate representation for optimising
compilers of lazy languages with linearity. In light of this,
we show that multiple optimising transformations are type
preserving in Linear Core. %(i.e.,~preserve linearity semantically).

% The optimising transformations proved sound wrt Linear Core in this section
% have been previously explained and motivated in
% Section~\ref{sec:core-to-core-transformations}.
% %
%\{\overline{\rho\to e'}\}
\begin{figure}[t]

  {\small
  \[
    \begin{array}{ll}
   (\llet{\xD = e}{e'} )  \Longrightarrow \llet{\xD =       e}{e'[e/x]} &                    \mbox{Inlining}\\
       (\lambda \x[\pi][\s].~e)~e'  \Longrightarrow e[e'/x]  &                \mbox{$\beta$-reduction}\\
      (\ccase{(K~\ov{e})}{\z[\D][\s]~\{\overline{\rho_j\to e_j}, K~\ov{x} \to e_i, \overline{\rho_k\to e_k}\}} )\Longrightarrow  e_i\ov{[e/x]}[K~\ov{e}/z] &
                                  \mbox{Case of known constr.}\\
      (\ccase{(\ccase{e_c}{\z[\D]~\{\ov{\rho_{c_i}\to e_{c_i}}\}})}{\var[w][\irr{\D,\D'}][\s']~\{\ov{\rho_i\to e_i}\}})\\
            \Longrightarrow 
            %{{{
      \ccase{e_c}{\z[\D]~\{\ov{\rho_{c_i} \to \ccase{e_{c_i}}{w~\{\ov{\rho_i\to e_i}\}}}\}}
      & \mbox{Case-of-case}\\
      (\lambda \y[\pi].~\llet{\xD = e}{e'})
      \Longrightarrow
      \llet{\xD=e}{\lambda\y[\pi].~e'} & \mbox{Commuting let-$\lambda$}\\
      ((\llet{v = e}{b})~a) \Longrightarrow \llet{v = e}{b~a} &\mbox{Commuting let-app.}\\
      (\ccase{(\llet{v = e}{b})}{\{\overline{\rho\to e'}\}}) \Longrightarrow
      %{{{
      \llet{v =  e}{\ccase{b}{\{\overline{\rho\to e'}\}}}
                               &
                                 \mbox{Commuting let-case}\\
      (\ccase{e}{\{\overline{\rho_j\to e_j}, \rho \to E[e_1],
      \overline{\rho_k\to e_k}\}} ) \qquad (\mbox{$x$ fresh}) \\
      %{{{
     \Longrightarrow \llet{x = e_1}{\ccase{e}{\{\overline{\rho_j\to e_j}, \rho \to E[x], \overline{\rho_k\to e_k}\}}} 
                                                                        & \mbox{Commuting case-let}\\
      (\llet{x = (\llet{v = e}{b})}{c}) \Longrightarrow \llet{v = e}{\llet{x = b}{c}}
                                                                      & \mbox{Commuting let-let}\\
      f \Longrightarrow \lambda x.(f~x) & \mbox{$\eta$-expansion}\\
      \lambda x.(f~x) \Longrightarrow f & \mbox{$\eta$-reduction}\\
      (\ccase{x}{z~\{\ov{\rho_i\to e_i}\}}) \Longrightarrow \ccase{x}{z~\{\ov{\rho_i\to  e_i[z/x]}\}}
                                                                      & \mbox{Binder swap}\\
      % (\ccase{x}{z~\{\ov{\rho_i\to e_i}\}} )\Longrightarrow \ccase{x}{z~\{\ov{\rho_i\to e_i[x/z]}\}}
      %                                                                 & \mbox{Reverse binder swap}
    \end{array}
  \]}
  \caption{Optimising transformations validated by Linear
    Core\label{fig:opttrans} (for commuting case-let we
      require $e_1$ not to capture the case binder, variables bound by the
      pattern $\rho$ and the context $E[{-}]$ -- see Appendix~\ref{app:optimisations} for
    details).} 
\end{figure}





We describe Core-to-Core transformations as $e_1 \Longrightarrow e_2$,
where $e_1$ is an arbitrary \emph{well-typed} expression
matching a certain shape (or of a certain type), which is
transformed into expression $e_2$. Validating a transformation
entails showing that $e_2$ is well-typed. We often annotate the arrow
with the name of the transformation when describing chains of such
transformations.

The list of transformations we have
validated is given in Figure~\ref{fig:opttrans}.
%
The behaviour of most transformations can be inferred from its name:
Inlining substitutes a let-bound expression in the let body; $\beta$-reduction
and case of known constructor effectively perform evaluation of the given expression;
case-of-case commutes cases in scrutinee position inside the outer case alternatives;
%let floating and  for let-bound expressions to be floated out of $\lambda$-abstractions;
the five commuting conversions allow let-bound expressions to be commuted with other
Core constructs; $\eta$-expansion and reduction apply the $\eta$-laws to terms of function type;
finally, binder swap substitutes occurrences of a scrutinee variable for the
case binder. While many of the transformations above are not obviously optimising,
they are chained in the compiler pipeline to expose optimisation opportunities.


% Transformations are described by an arbitrary well-typed expression with a certain shape, on
% the left hand side (lhs) of the arrow $\Longrightarrow$, resulting in an expression on
% the right hand side (rhs) that we prove to be well-typed.
% %
% % For our proofs, we assume the lhs to be a well-typed expression and prove the
% % rhs is well-typed as well.
% %
% For each transformation, we describe the intuition behind the transformation
% preserving linearity in our system.

% \todo[inline]{Aqui uma lista itemizada das transformações todas. As
%   provas todas para apendice.}


%%% COMENTADO AQUI
% \subsubsection{Inlining}

% % To the best of our knowledge, there is no linear type system for which inlining
% % preserves linearity\footnote{https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0111-linear-types.rst\#id90}

% \input{language-v4/proofs/optimizations/Inlining}

% \subsubsection{\texorpdfstring{$\beta$}{Beta}-reduction}

% \input{language-v4/proofs/optimizations/BetaReduction}

% \subsubsection{Case of known constructor}

% \input{language-v4/proofs/optimizations/CaseOfKnownConstructor}

% \subsubsection{Let floating}

% \input{language-v4/proofs/optimizations/LetFloating}

% \subsubsection{\texorpdfstring{$\eta$}{Eta}-conversions}

% \input{language-v4/proofs/optimizations/EtaConvs}

% \subsubsection{Binder Swap}

% The binder swap transformation applies to case expressions whose scrutinee is a
% single variable $x$, and it substitutes occurrences of $x$ in the case
% alternatives for the case binder $z$. If $x$ is a linear resource, $x$ cannot
% occur in the case alternatives (as we conservatively consider variables are not
% in WHNF), so the substitution preserves types vacuously. Otherwise, $x$ can be
% freely substituted by $z$, since $z$ is also an unrestricted resource (it's
% usage environment is empty because $x$ is unrestricted).

% \input{language-v4/proofs/optimizations/BinderSwap}

\paragraph{Reverse Binder Swap\label{sec:reverse-binder-swap-considered-harmful}}

%Finally, we discuss the special case of scrutinizing a
%single variable $x$, e.g.:
%$
%\lambda x.~\ccase{x}{\_ \to x}
%$. 
%It might seem as though this function is linear:
%%begin{itemize}
%% \item
%if the argument instantiating $x$ is in WHNF, then scrutinizing it is a no-op, and returning $x$
%just returns the resource intact;
%% \item
%if the argument instantiating $x$ is not in WHNF, then scrutinizing it evaluates it to WHNF, and returning
%$x$ returns the result of evaluating $x$ that still had to be consumed exactly
%once.
%%\end{itemize}
%However, in practice, this program's linearity can only be determined by
%further analysis on the non-strict evaluation strategy. If linear
%function applications are $\beta$-reduced \emph{call-by-name}
%(often desirable, as linear functions are known to use their argument exactly
%once)
%% and thus call-by-name reduction will definitely not duplicate computation
%while the example function is considered linear, then such an application might
%duplicate linear resources during evaluation. For instance:
%\[
%\begin{array}{l}
%(\lambda x.~\ccase{x}{\_ \to x})~(free~x)
%\Longrightarrow_{CBN}
%\ccase{free~x}{\_ \to free~x}
%\end{array}
%\]
%On the other hand, if linear function applications are reduced
%\emph{call-by-need}, the above example would instead be semantically linear
%because the result of freeing $x$ would be bound to some $y$ first.
%%
%The system we present in the next section does accept this function
%scrutinizing a variable as linear, as our operational semantics are
%call-by-need.
%This interaction between evaluation and linearity is considered specifically in the
%reverse binder swap transformation discussed in
%Section~\ref{sec:optimisations-preserve-types-meta}.\todo{Figure out precisely reverse binder swap proof and reevaluate}
%

Reverse binder swap is dual to the binder swap transformation, substituting
occurrences of the case binder $z$ by the scrutinee in the special case when
the scrutinee is a variable $x$.
%
% his is dual to what the binder swap transformation
% does in hope of eliminating multiple uses of $x$ (allowing for inlining). 
By using the scrutinee $x$ instead of the case binder, we might be able to
float out expressions from the alternative using the case binder:
\[
    \ccase{x}{z~\{\rho \rightarrow e\}} \Rightarrow \ccase{x}{z~\{\rho \rightarrow e[x/z]\}}
\]

%For example, we might float an expensive computation involving $z$ out of the
%case alternative, where $z$ is now out of scope:
%
%{\small\[
%\begin{array}{l}
%(\lambda x.~\lletrec{go~y = \ccase{x}{z~\{(a,b) \to \ E[expensive~z] \} }}{\dots})
%\Longrightarrow_\textrm{Reverse binder swap}\\
%(\lambda x.~\lletrec{go~y = \ccase{x}{z~\{(a,b) \to E[expensive~x] \} }}{\dots})
%\Longrightarrow_\textrm{Commuting case-let}\\
%\lambda x.~\llet{t = \mathit{expensive}~x}{(\lletrec{go~y = \ccase{x}{z~\{(a,b) \to E[t] \} }}{\dots})}\\
%\end{array}
%\]}
%
%\noindent If $go$ is compiled into a loop, we only compute
%$\mathit{expensive}~x$ once instead of in every loop iteration.
%
Even though GHC applies the reverse binder swap transformation in the
Core-to-Core passes, this optimisation violates linearity in Linear Core
because the transformed program is rejected -- the scrutinee $x$, a single
variable, is not considered to be in WHNF by our system, thus occurrences of
$x$ in any alternative are ill-typed in it. This is a conservative choice in $\lambda^\pi_\Delta$ for
typing the subtle case where the scrutinee is a single variable.

Consider $\ccase{x}{\_ \to x}$. Perhaps surprisingly, this expression can be
considered semantically linear under call-by-need but violates
linearity under call-by-name:
%
%An expression in which a variable $x$ occurs both in the case scrutinee and in
%the alternatives (e.g.,~$\ccase{x}{\_ \to x}$) could be considered linear if
%considered in isolation:
% \[
% \G; \xl \vdash \ccase{x}{\_ \to x} : \s
% \]
% The reasoning is done by branching on whether $x$ refers to an expression in
% WHNF or an unevaluated thunk.
% \begin{itemize}
% \item
Under call-by-need, if $x$ refers to an unevaluated expression, scrutinizing it forces the expression
bound by $x$ to WHNF. In a subsequent use of
$x$ in an alternative, $x$ refers to the already evaluated scrutinee in WHNF.
Since $x$ is just another name (like the case binder) for the scrutinee in
WHNF, its use is also valid in the alternatives.
%
Dually, if $x$ refers to an expression already in WHNF, no evaluation takes
place and $x$ is still just another name for the scrutinee in WHNF.

However, under call-by-name, evaluation of $x$ is not shared:
%However, allowing this expression to be linear makes $\lambda^\pi_\Delta$ unsound!
%Consider the function application $(\lambda x.~\ccase{x}{\_ \to x})~(use~y)$
%where $y$ is a free linear variable, and assume $\lambda x.~\ccase{x}{\_ \to x}$
%to be a linear function. According to $\lambda^\pi_\Delta$'s call-by-name
%$\beta$-reduction, we have:
\[
\begin{array}{l}
(\lambda x.~\ccase{x}{\_ \to x})~(use~y)
\Longrightarrow_\textrm{CBName}
\ccase{use~y}{\_ \to use~y}
\end{array}
\]
After the reduction, $y$ is a linear variable consumed both in the scrutinee
and in the case alternative -- $y$ has been duplicated!
%
If the application is instead reduced call-by-need, $y$ is not duplicated:
\[
\begin{array}{l}
(\lambda x.~\ccase{x}{\_ \to x})~(use~y)
\Longrightarrow_\textrm{CBNeed}
\llet{x = use~y}{\ccase{x}{\_ \to x}}
\end{array}
\]
%then the computation using $y$ would be let-bound, and $y$ would be used as a
%scrutinee variable, which preserves semantic linearity.

In an optimising compiler such as GHC, there is no definitive evaluation
strategy. It is mostly up to heuristics to determine what to inline
\emph{à la} call-by-name and what to create let-bindings for \emph{à
la} call-by-need.
%
In this flexible evaluation setting, we highlight the reverse binder swap is
only a linearity-preserving transformation as long as a linear variable with
more than one occurrence is never substituted for an expression with free
linear variables.
%
%This is unfortunately at odds with
%Moreover, allowing the reverse binder swap also challenges the 
%
%It additionally challenges the non-heuristic property that linear variables can
%be unconditionally inlined.......

%the aggressive inlining passes blur evaluation
%there is no definitive evaluation
%strategy in the sense functional compilers use both when agressively inline
%expressions \emph{à la} call-by-name.
%call-by-need for
%every function application -- our result shows that failing to do so
%when calling a function such as the one above is \emph{unsound}.
%
%In an optimising compiler, a binding may be deemed unnecessary if the function
%argument is inferred to be used exactly once. Linearity can play a
%(non-heuristic) role in this inference, for a linear function uses its
%argument exactly once by definition.
%
% Since the compiler may leverage this information (we
% briefly discuss \emph{linearity-influenced optimisations} in
% Section~\ref{sec:discussion}).
%
%However, it is incompatible to both type expressions like $(\lambda
%x.~\ccase{x}{\_ \to x})$ as linear functions and consider
%call-by-name $\beta$-reduction of linear functions unconditionally
%safe (without risk of duplicating resources nor work).
%
%Furthermore, considering such an use of $x$ to be linear also makes inlining of
%linear let bindings no longer unconditionally safe.

% $\beta$-reduction reduces an application of a linear function using
% call-by-name -- If we know the argument is used exactly once, a binding to
% share the result of computing the argument is unnecessary, so we instead
% substitute the argument expression for the linearly-bound variable in the
% $\lambda$-body directly.
%%
%% Essentially, Linear Core would be unsound, and even duplicate resources, if the
%% above kind of expressions, where linear variable scrutinees occur in the
%% alternatives body, were well-typed, because of its interaction with the
%% call-by-name reduction of linear functions.
%In this sense, the reverse binder
%swap is an optimisation that creates ill-typed expressions from well-typed
%ones, so it is deemed an \emph{invalid} optimisation that does not preserve types in
%our system.

%% Reverse binder swap is not a problem in the GHC simplifier because of the
%% weaker notion of linearity understood by occurrence analysis. Occurrence
%% analysis is a static analysis pass which can be used to determine whether a
%% lambda application can be $\beta$-reduced call-by-name, and $\ccase{x}{\_ \to
%% x}$ is \emph{not} seen as using $x$ linearly by the analysis. Thus,
%% $\beta$-reduction is done with call-by-need on such an expression.
%
% In practice, the optimisation preserves linearity when applied as part of the
% GHC pipeline due to the occurrence analyser being naive with regard to semantic
% linearity.

% Concluding, in being able to understand more programs as linear, our type
% system allows more expressions to be considered linear for $\beta$-reduction
% without a let-allocation, however, it makes reverse binder swap an invalid
% transformation since its output, when considered linear, might violate
% linearity when further optimised.

% (Link to ticket)
% 
% \begin{tabbing}
% (1) All optimisations preserve (semantic) linearity\\
% (2) If a function is (semantically) linear, then we can evaluate it using call-by-name and preserve linearity\\
% (3) Reverse binder swap is an optimisation\\
% (4) If reverse binder swap is applied to a case scrutinizing a linear resource in the body (`e`) of a linear function `f`, then the function is still linear by (1)\\
% (5) If we evaluate `f`, we do it call-by-name because of (2)\\
% (6) Call-by-name substitution of the linear argument in the body of a function has been reverse binder swapped doesn’t preserve linearity\\
% (7) Contradiction: By 3 and 1, `f` is linear after reverse-binder-swap. By 2, we can substitute arguments to `f` call-by-name and preserve linearity, which contradicts with 6 that says call-by-name substitution after reverse binder swap violates linearity\\
% \end{tabbing}

% Conclusion:
% Either we need to forfeit that we can always substitute call-by-name linear
% function applications, or we forfeit that reverse binder swap preserves
% linearity (instead, it preserves a weaker notion of linearity understood by the
% syntatic-occurrence-analyzer)

% \todo[inline]{Reverse-binder-swap is only well-defined in certain scenarios
% where the optimizations don't apply call-by-name beta-reduction after the
% reverse-binder-swap optimization -- otherwise we would duplicate resources.
% In this case, it is not a matter of syntatic vs semantic linearity
% }

% \todo[inline]{
% Mention, from ``Call-by-name, call-by-value, call-by-need and the linear lambda calculus'':
% The call-by-name calculus is not entirely suitable for reasoning about
% functional programs in lazy languages, because the beta rule may copy the
% argument of a function any number of times. The call-by-need calculus uses a
% diferent notion of reduction, observationally equivalent to the call-by-name
% calculus. But call-by-need, like call-by-value, guarantees that the argument
% to a function is not copied before it is reduced to a value.
% }

% It's also interesting to note that reverse-binder-swap preserves linearity under pure call-by-need but not under call-by-name, because
% (In the sense that if EVEN linear functions reduce call-by-need rather than call-by-name, then it would preserve optimisations)

% Reduce call-by-name linear function application
% \begin{code}
% f y = (\x. case x of _ -> x:1) (h y)
% ===>
% f y = (case x of _ -> x)[h y/x]
% ===>
% f y = (case h y of _ -> h y) -- consume y twice.
% \end{code}
% 
% Vs. call-by-need
% \begin{code}
%  (\y = (\x. case x of _ -> x:1) (h y)) e
% ===>
%     let y = e in
%        let x = h y in
%         case x of _ -> x
% ===>
%        let x = h e_v in
%         case x of _ -> x
% ===>
%         case x_v of _ -> x_v
% \end{code}

% \subsubsection{Case of Case}

% The case of case transformation applies to case expressions whose scrutinee is
% another case expression, and returns the innermost case expression transformed by repeating
% the outermost case expression in each alternative of the innermost case,
% scrutinizing the original alternative body.

% Intuitively, since the scrutinee of the outermost case is not in WHNF, no
% resources from it can directly occur in the outermost alternatives. By moving
% the outermost alternatives inwards with a different scrutinee, the alternatives
% remain well-typed because they are typed using either the case binder or the
% pattern bound variables, which, by the \emph{Irrelevance} lemma, makes it
% well-typed for any scrutinee consuming arbitrary resources. The proof is given in Section~\ref{sec:proof:caseofcase}.

% \CaseOfCaseTheorem

% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Linear Core as a GHC Plugin
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Linear Core as a GHC Plugin\label{sec:discuss:implementation}}

We have implemented the Linear Core type system as a plugin for the Glasgow
Haskell Compiler.
GHC plugins allow developers to inspect and modify programs being compiled by
GHC, at different stages of compilation~\cite{10.1145/3331545.3342599}.
%
In particular, for any given Haskell module, Core plugins run for (and receive
as input) every intermediate program produced in the compilation process, i.e.
from desugaring and after each optimising transformation.
%
Our implementation further substantiates our claim that Linear Core is
suitable for the intermediate language of an optimising compiler.
%\todo[inline]{Tem de ser anonimizado, provavelmente alterando a bib
  %entry para omitir autores e o proprio link}
The GHC Linear Core plugin~\cite{cite:linear-core-plugin} implements a
typechecker for Linear Core: given a Core program, our plugin typechecks the
linearity of all expressions bound in that program, failing if a linear
resource is not used \emph{exactly once} according to semantic linearity of the
$(\lambda^\pi_\Delta)$ system.
%
% Furthermore, the implementation accepts all example programs from Chapter~\ref{sec:linearity-semantically}
% deemed well-typed by Linear Core, which are marked with a
% \colorbox{notyet}{\notyetcolorname} background.

% Additionally, we discuss the implementation of the Linear Core type system
% directly in the Glasgow Haskell Compiler.

% This section discusses the implementation of Linear Core as a GHC Plugin, with
% a dash of painful history in the attempt of implementing Linear Core directly
% into GHC.

The implementation of Linear Core as a typechecker does not follow
directly from the description of the type system because Linear Core
is not \emph{syntax-directed}. Specifically, the most challenging
features are splitting linear resources amongst sub-derivations and
consuming fragments of resources through pattern-bound variables.
Instead of non-deterministically splitting linear resources amongst
sub-derivations, we thread input/output linear resources through each
derivation~\cite{DBLP:journals/tcs/CervesatoHP00}.
%
For a scrutinee not in WHNF, pattern variables in a case alternative are
introduced as $\D$-variables with usage environment $\lctag{\irr{\D}}{K_i}$,
where $\D$ are the scrutinee resources and $K_i$ the tag of that pattern
variable. To use these pattern variables, the scrutinee resources must be first
$Split$ into fragments. Instead of guessing which resources need to be split,
the implementation consumes tagged fragments of a resource \emph{as needed},
i.e., only when consuming a resource whose usage environment has a resource
tagged $K_j$ do we $Split$ that resource on $K$ and consume the $K_j$ fragment.
%
Finally, our implementation must infer the usage environments of binders in
a recursive let group before using them to typecheck the let body. We use a
naive $O(n^2)$ algorithm (where $n$ is the number of let bindings) to determine
these usage environments. %Further research regarding
%this inference challenge is discussed in Section~\ref{sec:future-work}.
%
%
%
% We use the following techniques to tackle the \emph{non-syntax-directedness} of
% Linear Core:
%
% \begin{itemize}

% % \item Instead of non-deterministically splitting linear resources amongst
% % sub-derivations, we thread input/output linear resources through each
% % derivation using the resource management for linear logic described
% % by~\cite{DBLP:journals/tcs/CervesatoHP00}.
% % \todo{Escrever uma regra?}

% % In a case expression whose scrutinee is not in WHNF,
% \item Pattern variables bound in a case alternative, for a scrutinee not in WHNF,
% are introduced as $\D$-variables with usage environment $\lctag{\irr{\D}}{K_i}$,
% where $\D$ are the scrutinee resources and $K_i$ the tag of that pattern
% variable. To use the resources through the pattern-bound $\D$-vars, they must
% be first $Split$ into fragments.

% We consume tagged fragments of a resource \emph{as needed}, i.e., when a resource,
% whose usage environment has a fragmented resource with tag $K_j$, is used, we $Split$
% the matching resource according to the constructor $K$ and consume the fragment
% $K_j$, rather than eagerly determining which resources need to be fragmented to
% do so.
% %
% We note that it is safe to destructively fragment the resource, i.e. removing
% the whole resource and only leaving the split fragments, because resources are
% only $Split$ when a fragment is needed and, consequently, if a fragment is
% consumed, using the ``whole'' resource as well violates linearity.

% \end{itemize}
%

% The usage environments of a recursive group of binders (that is not necessarily
% strongly-connected) is computed in two separate passes.
% %
% First, we calculate a \emph{naive environment} by recording the linear
% resources semantically used in the binder bodies, while counting \emph{uses}
% (not syntactic occurrences) of the mutually recursive let variables.
% %
% Second, the binder names and corresponding \emph{naive environment} (mapping
% each linear resource to $1$ and the recursive variables to the $n$ number of
% times they are \emph{used}) in Cartesian pairs are given as input to
% % Algorithm~\ref{computeRecUsages},
% an algorithm which computes the actual usage environment
% of each binder.
%
% TODO: I should probably use the re-computed usageEnvs instead of the naiveUsageEnvs.
% I'm pretty sure it might fail in some inputs if I keep using the naiveUsageEnvs.
% \begin{algorithm}
% $usageEnvs \gets naiveUsageEnvs.map(fst)$\;
% \For{$(bind, U) \in naiveUsageEnvs$}{
%     \For{$V \in usageEnvs$}{
%         $V \gets sup(V[bind]*U\setminus\{bind\}, V\setminus\{bind\})$
%     }
% }
% \caption{computeRecUsages\label{computeRecUsages}}
% \end{algorithm}
%
% Intuitively, the algorithm, for each recursive binder, iterates over the
% (initially naive) usage environments and substitutes occurrences of the
% recursive binders by their corresponding usage environment,
% scaled up by the amount of times that recursive binder is used in the
% environment being updated. The result is the least upper bound of linear
% resources used by each strongly-connected group of mutually recursive bindings
% (for each binder of such a group), since all occurrences of the recursive
% binders in the usage environments will be substituted away by the corresponding
% recursive usage environments.
%
% The high-level description is:
% \begin{itemize}
%     \item Given a list of binders and their naive environment ($(f, F), (g, G),
%     (h, H)$) in which each use of $f, g, h$ is mapped to a count $n$ in $F, G, H$
%
%     \item For each pair of a letrec-bound variable and corresponding usage
%     environment, update all bindings and their usage as described in the
%     algorithm
%
%     \item After iterating through all bound rec vars, all usage environments
%         will be free of recursive bind usages, and hence describe the ``final'' usage environment
% \end{itemize}
%
% The complexity of computing a usage environment for $n$ recursive let binders
% is quadratic in $n$,
% % i.e. the algorithm has $O(n^2)$ complexity,
% but this is not an issue since it is uncommon to have more than a handful of
% binders in the same recursive let block.

% TOdo: INCLUDE THIS??
% The plugin successfully validates linearity throughout the
% (optimising) compilation of linearity-heavy libraries, namely
% \texttt{linear-base} and \texttt{linear-smc}, except in expressions whose
% linearity depends on so-called \emph{multiplicity coercions}, which are an
% avenue of future work (Section~\ref{sec:future-work}) exploring the intersection
% of Linear Core with type equality coercions.

The results of running the Linear Core GHC plugin on large 
libraries focused around linear types are reported in
Figure~\ref{fig:core-plugin-res}.
%
%
We compiled the Haskell standard library for programming with linear types,
\texttt{linear-base} (4000 lines, comprising over 100 modules), the
\texttt{linear-smc}~\cite{10.1145/3471874.3472980} (1500 lines) library, and
\texttt{priority-sesh}~\cite{10.1145/3471874.3472979} (1400 lines), a
session-types library, using our plugin.
%
We count the number of programs accepted by our implementation, where
each top-level binding in a module counts as a program, and every such
binding is typechecked once per optimisation pass (i.e., we typecheck
all intermediate programs produced by GHC). The total amount of programs
rejected by the typechecker are counted dually, also across every optimisation
pass, without halting compilation when a program is rejected. We note that our
implementation is not performance conscious, and types every intermediate
program from scratch, instead of preserving information throughout the
pipeline.

%``Total Rejected'' column, but we distil these rejections into ``Unique
%Rejections'' by removing duplicate rejections (those of the same
%program and for the same linearity-violating reason, but occurring at
%different stages). We further categorize the unique rejections into
%``Linear modulo Call-by-name'', ``Linear Rejected'', ``Not Linear
%Rejected'', and ``Unknown Rejected''.  We note that our implementation
%is not performance conscious. For instance, \texttt{linear-base} takes
%35 seconds to compile with our plugin, instead of 20 seconds.
%%
%% Using the plugin, \texttt{linear-base} takes 35 seconds to compile, instead of
%% 20 seconds. We note, however, that the implementation is not performance
%% conscious, and types every intermediate program from scratch, instead of
%% maintaining linearity information throughout the pipeline.

%Programs ``linear modulo call-by-name'' are a class of programs
%which scrutinize a variable, but then use the variable in the case
%alternatives of the case scrutinizing it. As discussed in
%Section~\ref{sec:reverse-binder-swap-considered-harmful}, these programs can be
%understood as linear as long as applications of linear functions binding these
%variables are \emph{not} reduced \emph{call-by-name}.
%In Core, these programs are not seen as
%linear, and thus GHC does not not reduce them using a call-by-name evaluation strategy.
%% We have a flag in our implementation to accept some of these programs...
%%
%``Linear Rejected'' programs include different kinds of programs which are
%rejected by the Linear Core system, but are still semantically linear. An
%example is a program to which a rewrite rule was applied, resulting in an
%application of unrestricted function to a linear resource.
%% in the first argument
%% to \incode{build}:
%% \begin{lstlisting}
%% take :: Int -> Replicator a *' $\lolli$ '* [a]
%% take = \ (ds :: Int) (r :: Replicator b) ->
%%      case ds of
%%        1 -> build (\(c :: b -> a -> a) (n :: a) -> c (extract r) n)
%%        ...
%% \end{lstlisting}
%% We know the linear resource is still used linearly because \incode{build} will
%% always instance the unrestricted function to $(:)$ (read \emph{Cons}), which is
%% linear. Additionally, these include programs scrutinizing a value of a type of
%% which all constructors have no linear components, but only matching on the
%% default alternative, programs where common-sub-expression elimination
%% substituted more than one occurrence of \incode{Ur x} by \incode{y}, in the body of
%% scrutinizing \incode{y} (a linear variable), and other programs affected by rewrite rules.
%%
%``Not Linear Rejected'' indicate programs that we do not understand as linear,
%semantically, and are simultaneously rejected by Linear Core and its
%implementation. % These programs were not necessarily identified as bad
%% by the linter.\footnote{rever}
%% An example, where the last component of \incode{HashMap}, \incode{wwz},
%% is linear, but is not being consumed in the case alternative matching on it:
%% \begin{lstlisting}
%% jssvi :: Ur Bool *' $\lolli$ '* Set Int *' $\lolli$ '* Ur (TestT IO ())
%% jssvi (a :: Ur Bool) (b :: Set Int)
%%   = case a of
%%      Ur ss -> case b of { HashMap wwx wwy wwz -> jump wjssAd ss }
%% \end{lstlisting}
%%
%Finally, ``Unknown Rejected'' programs are those whose validity we did not
%check. These include both programs accepted by Linear Core, but not by its
%implementation, and programs that are simply rejected by Linear Core, but which
%were not categorized.

{\small
  \input{prototype/core-plugin-results-2}
  }
%
The results indicate that our mostly direct implementation of Linear Core is
successful in accepting the vast majority of the thousands of intermediate
programs produced by GHC when compiling libraries that make extensive use of
linear types.
%
However, Linear Core does not accept every single program produced by the
optimisation pipeline of GHC. Our manual analysis of rejected programs revealed
excellent results. Programs considered ill-typed by the Linear Core
implementation include:
%
\begin{itemize}
    \item Programs we expected GHC to produce, but know are not seen as linear by $\lambda^\pi_\Delta$.
        Namely, programs resulting from the reverse binder swap which
        scrutinize a variable and then use it again in the case alternatives.
        As discussed in Section~\ref{sec:reverse-binder-swap-considered-harmful}, these
        programs could be understood as linear as long as all applications of
        linear functions are reduced \emph{call-by-need}, but our system
        conservatively rejects it in light of the flexible evaluation strategy
        used by optimizing compilers.

    \item Programs rejected due to the lack of ``linearity coercions'' in
        $\lambda^\pi_\Delta$. Extending Linear Core with \emph{multiplicity coercions} 
        could make these programs be understood as linear
        (discussed in Section~\ref{sec:future-work}).

    \item Programs which actually violate linearity, in that the term
        violates the linear type it is annotated with. These are the programs
        we ultimately want to spot and reject by having a linearly typed Core
        validate intermediate programs. We found both a program which outright
        discarded a linear resource and that rewrite rules implementing stream
        fusion~\cite{10.1145/165180.165214,10.1145/1291151.1291199}
        (among other rules) could produce linearly-invalid programs (in one such case,
        the type of \lstinline{build} was not general enough to accommodate linearity).
\end{itemize}
%
Overall, the programs rejected by the Linear Core plugin,
%, in \texttt{linear-base},
besides validating that our implementation is faithful to the
$\lambda^\pi_\Delta$ system insofar as programs that should not be accepted
are deemed ill-typed, provide further insight into the remaining
details required to fully typecheck linearity in a mature optimising compiler.


% Talk about using our plugin on linear-base and other code bases... If I can get
% a few more case studies it would be pretty good. But then it's imperative to
% also use -dlinear-lint and make sure my plugin rejects a few of the examples

%%% \subsection{Consuming tagged resources as needed}
%%% 
%%% As discussed in Section~\ref{}, pattern-bound linear variables are
%%% put in the context with a \emph{tagged} usage environment with the resources of
%%% the scrutinee. In a \emph{tagged} usage environment environment, all resources
%%% are tagged with a constructor and an index into the many fields of the
%%% constructor.
%%% 
%%% In practice, a resource might have more than one tag. For example, in the following
%%% program, after the first pattern match, |a| and |b| have, respectively, usage
%%% environments $\{\lctag{x}{K_1}\}$ and $\{\lctag{x}{K_2}\}$:
%%% \begin{code}
%%% f x = case x of
%%%        K a b -> case a of
%%%         Pair n p -> (n,p)
%%% \end{code}
%%% However, in the following alternative, |n| has usage environment
%%% $\{\lctag{\lctag{x}{K_1}}{Pair_1}\}$ and |p| has
%%% $\{\lctag{\lctag{x}{K_1}}{Pair_2}\}$. To typecheck
%%% |(n,p)|, one has to $Split$ |x| first on |K| and then on |Pair|, in order for
%%% the usage environments to match.
%%% 
%%% In our implementation, we split resources on demand (and don't directly allow
%%% splitting linear resources), i.e. when we use a tagged resource we split the
%%% linear resource in the linear environment (if available), but never split otherwise.
%%% %
%%% Namely, starting on the innermost tag (the closest to the variable name), we
%%% substitute the linear resource for its split fragments, and then we iteratively
%%% further split those fragments if there are additional tags.
%%% %
%%% We note that it is safe to destructively split the resource (i.e. removing the
%%% original and only leaving the split fragments) because we only split resources
%%% when we need to consume a fragment, and as soon as one fragment is consumed
%%% then using the original ``whole'' variable would violate linearity.
%%% 
%%% In the example, if |n| is used, we have to use its usage environment, which in
%%% turn entails using $\lctag{\lctag{x}{K_1}}{Pair_1}$, which has two tags. In this order, we:
%%% \begin{itemize}
%%% \item Split $x$ into $\lctag{x}{K_1}$ and $\lctag{x}{K_2}$
%%% \item Split $\lctag{x}{K_1}$ and $\lctag{x}{K_2}$ into
%%%   \begin{itemize}
%%%   \item $\lctag{\lctag{x}{K_1}}{Pair_1}$ and $\lctag{\lctag{x}{K_1}}{Pair_2}$
%%%   \item Leave $\lctag{x}{K_2}$ untouched, as we only split on demand, and we aren't using a fragment of $\lctag{x}{K_2}$.
%%%   \end{itemize}
%%% \item Consume $\lctag{\lctag{x}{K_1}}{Pair_1}$, the usage environment of $n$, by removing it from the typing environment.
%%% \end{itemize}

%%%\subsection{Merging Linear Core into GHC\label{sec:merging-linear-core}}
%%%
%%%Describe the ticket for linear Core, the pending MRs, and the difficulty in
%%%even annotating the bind site across optimisations regardless of multiplicities.

% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related and Future Work\label{sec:discussion}}

% In this chapter, we compare our contributions and Linear Core to related
% existing works in the literature,
% % (including linearity in a lazy, evaluation models in terms of linearity, and
% % the Core system).
% %
% consider further research
% % deemed out of the scope of this work and of the Linear Core type system
% (notably, so-called \emph{multiplicity coercions} to handle the
% interaction between linearity and \emph{coercions}, a key feature of Core which we
% left out our system), and conclude.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Related Work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%paragraph{Related Work}

% In this section we discuss related work, namely, Linear
% Haskell~\cite{cite:linearhaskell}, Linear Mini-Core~\cite{cite:minicore}, and
% linearity-influenced optimising
% transformations~\cite{cite:let-floating,peytonjones1997a,cite:linearhaskell}.

% TODO: A brief introduction to the related work section?

% \subsection{Formalization of Core}\todo{terrible paragraph name, and terrible paragraph}
% 
% As such, there exists no formal definition of Core that
% accounts for linearity. In this context, we intend to introduce a linearly typed
% System $F_C$ with multiplicity annotations and typing rules to serve
% as a basis for a linear Core. Critically, this Core linear language
% must account for call-by-need evaluation semantics and be valid in
% light of Core-to-Core optimising transformations.

% \parawith{System FC}

%System $F_C$~\cite{cite:systemfc} (Section~\ref{sec:core}) does not
%account for linearity in its original design, and, to the best of our
%knowledge, no extension to System $F_C$ with linearity and non-strict
%semantics exists.
%

% \begin{itemize}
% \item SystemFC tal como está não tem linearidade de todo
% \item Formalmente nao temos published definição de linearidade no Core
% \item Regras para sistema tipo FC com linearidade
% \item mas uma extensão tipo linear lambda calculus nao consegui exprimir as transformações do core
% \end{itemize}

% Haskell Core's foundational language was imbued with linear types, but it does
% not account for linearity with the whole of the type system
% 
% Multiplicity annotations in SystemFC?
% 
% Rules?

\paragraph{Linear Haskell\label{sec:related-work-linear-haskell}.}
%
% \todo[inline]{Say something about Linear Haskell's lazy operational semantics,
% but the type system not being concerned with linearity in the presence of
% laziness}
%
% Haskell, contrary to most programming languages with linear types, has existed
% for 31 years of its life \emph{without} linear types. As such, the introduction
% of linear types to Haskell comes with added challenges that do not exist in
% languages that were designed with linear types from the start:
% %
% \begin{itemize}
%     \item Backwards compatibility. The addition of linear types shouldn't break
%         all existing Haskell code.
%     \item Code re-usability. The linearly-typed part of Haskell's ecosystem and
%         its non-linearly-typed counterpart should fit in together and it must be
%         possible to define functions readily usable by both sides
%         simultaneously.
%     \item Future-proofing. Haskell, despite being an
%         industrial-strength language, is also a petri-dish for experimentation
%         and innovation in the field of programming languages. Therefore, Linear
%         Haskell takes care to accommodate possible future features, in
%         particular, its design is forwards compatible with affine and dependent
%         types.
% \end{itemize}
% %
Linear Haskell~\cite{cite:linearhaskell} augments the Haskell surface language
with linear types, but it is not concerned with extending GHC's intermediate
language(s), which presents its own challenges. 
%
However, the implementation of Linear Haskell in GHC does modify and extend Core
with linearity/multiplicity annotations. Core's type system is unable to type
semantic linearity of programs in the sense elaborated in our work,
which results in Core rejecting most linear programs resulting from optimising
transformations that leverage the non-strict semantics of Core.
%
Our work overcomes the limitations of Core's linear type system derived from
Linear Haskell by understanding linearity semantically in the presence of
laziness, and by showing that multiple Core-to-Core
optimisations employed by GHC are linearity preserving, using a
linearity-aware semantics that is essentially identical to that of~\cite{cite:linearhaskell}.
Linear Core can also be seen as a system that validates the programs written in
Linear Haskell and are compiled by GHC, by guaranteeing (through typing) that
linear resources are still used exactly once throughout the optimising
transformations.



\paragraph{Linear Mini-Core\label{sec:linear-mini-core}}

Linear Mini-Core~\cite{cite:minicore} is a specification of linear types in
Core as they were being implemented in GHC, and doubles as the (unpublished)
precursor to our work. Linear Mini-Core first observes the incapacity of
Core's type system to accept linear programs after transformations, and 
introduces usage environments for let-bound variables with the same goal of
Linear Core of specifying a linear type system for Core that accepts the
optimising transformations.

We draw from Linear Mini-Core the rule for non-recursive let expressions and
how let-bound variables are annotated with a usage environment. However, our
work further explores the interaction of laziness with linearity in depth, and
diverges significantly in rules for typing other constructs, notably, case expressions and
case alternatives. Furthermore, unlike Mini-Core, we prove Linear Core is type
safe, guarantees linear resource usage, and that multiple optimising
transformations, when applied to Linear Core programs, preserve linearity.

% \subsection{OutsideIn(X)\label{related-work-gadts}}
% 
% Defines constraint-based type system parametrized over X which does not account
% for local type refinements regarding linearity.
% 
% Se for modificar o typechecker com as multiplicity coercions vou ter de falar
% disto.

% \subsection{Rust}
% 
% Rust has a core based on linear types. Describe Rust's architecture?
% How do they handle linearity plus optimisations
% They probabluy don't typecheck linearity in Core

\paragraph{Linearity-influenced optimisations}

Core-to-Core transformations appear in many works across the research
literature~\cite{cite:let-floating,peytonjones1997a,santos1995compilation,peytonjones2002secrets,baker-finch2004constructed,maurer2017compiling,Breitner2016_1000054251,sergey_vytiniotis_jones_breitner_2017},
all designed in the context of a typed language (Core) which does not have
linear types. However, some works~\cite{cite:let-floating,peytonjones1997a,cite:linearhaskell} have observed that
certain optimisations (in particular, let-floating and inlining) greatly
benefit from linearity analysis and, in order to improve those transformation,
special purpose linear-type-inspired systems were created and implemented.
%
Preserving linear types in Core throughout the compilation pipeline allows the
optimiser to leverage non-heuristic linearity information where, previously, it
would resort solely to ad-hoc or incomplete custom-built linearity inference
passes (naturally, these passes are still necessary to optimise programs not
using explicit linearity or multiplicity annotations). Linearity may
potentially be used to the benefit of other optimising transformations that
currently do not take it into account.

% \begin{itemize}
% \item Transfs. core to core aparecem em vários artigos, e são desenhadas no contexto de uma linguagem tipificada mas que não é linearly typed.
% \item nestes dois artigos é observado que se houvesse a capacidade de explorar linearidade podiamos fazer as coisas de forma diferente
% \item Todas estas optimizaçoes de decadas foram desenhadas sem linear types e há sitios onde linear types podiam ajudar mas não existiam na altura
% \item POdemos usar linear types multiplicitpiadads para lazy language core q definimos para nao ter de fazer sistemas lineares de proposito para optimizações
% \item Ser ad-hoc incompleto ou nao feito de todo
% \end{itemize}

% \parawith{A transformation based optimiser for Haskell}
% They discuss a cardinality analysis based on a linear type system but create (an
% ad-hoc?) one suited. Comparison in the measure of creating optimizations based
% on linearity.
% 
% \parawith{Let-Floating: Moving Bindings to Give Faster Programs\label{sec:rw:let-floating}}
% In the paper~\cite{cite:let-floating}...
% They say they are doing work on a linear type system to identify places where
% the lambda is linearly used and therefore floating-in is beneficial and
% floating-out not as productive.

% \subsection{Call-by-value, call-by-name and call-by-value...}
% 
% The work~\cite{cite:call-by-name-value-and-need-linear-lambda-calculus}...

% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Future Work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Future Work\label{sec:future-work}}

We highlight some avenues of future work. Briefly,
these include \emph{multiplicity coercions}, optimisations leveraging
linearity, resource inference for usage environments, and ultimately using
Linear Core in a mature optimising compiler with lazy evaluation and linear
types -- the Glasgow Haskell Compiler. Lastly, we discuss the
% we hypothesize Linear($X$), a linear system parametrized on the evaluation strategy, and the
generalization of Linear Core to the surface Haskell language.

\paragraph{Multiplicity Coercions.}
Linear Core does not have type equality coercions, a flagship feature of GHC
Core's type system.
%
Coercions %briefly explained in Section~\ref{sec:core},
allow the Core intermediate language to encode a panoply of Haskell source
type-level features such as GADTs, type families, or newtypes.
%
In Linear Haskell, multiplicities are introduced as annotations to function
arrows which specify the linearity of the function. In practice,
multiplicities are simply types of kind \incode{Multiplicity}, where \incode{One} and \incode{Many}
are the type constructors of the kind \incode{Multiplicity}; multiplicity polymorphism
follows from type polymorphism, where multiplicity variables are
just type variables. Encoding multiplicities as types allows Haskell programs
to leverage features available for types to naturally extend to multiplicities
as well.
For instance, it is possible via the use of GADTs to define a
function whose linearity of its second argument depends on the value
of its first argument, internally realized through so-called
\emph{multiplicity coercions}. Currently, Core cannot make use of such
coercions to determine whether the usages of linear resources match
their intended multiplicity. Studying the interaction between coercions and multiplicities is a main avenue
of future work for Linear Core.
%
% Consequently, we might define, e.g., using a GADT \incode{SBool} and a type family
% |If|, the function \incode{dep} which is linear in the second argument if the first
% argument is \incode{STrue} and unrestricted otherwise:
% %
% \begin{limitation}
% \begin{lstlisting}
% data SBool :: Bool -> Type where
%   STrue :: SBool True
%   SFalse :: SBool False

% type family If b t f where
%   If True t _ = t
%   If False _ f = f

% dep :: SBool b -> Int %(If b One Many) -> Int
% dep STrue x = x
% dep SFalse _ = 0
% \end{lstlisting}
% \end{limitation}
% %
% This example is linear and should be accepted. However, the example is rejected
% by the GHC's Core type checker.
% Critically, Core doesn't currently understand
% so-called \emph{multiplicity coercions}. Even though after matching on |STrue|
% we have access to a coercion from the function multiplicity $m$ to $1$ ($m \sim
% 1$), we cannot use this coercion to determine whether the usages of the linear
% resources match the multiplicity.
% %
% Studying the interaction between coercions and multiplicities is a main avenue
% of future work for Linear Core.

% In GHC, multiplicity coercions are tracked by issue $19517$\footnote{https://gitlab.haskell.org/ghc/ghc/-/issues/19517}.

% \todo[inline]{Relate to levity polymorphism and runtime rep coercions (Sam)}

\paragraph{Optimisations leveraging linearity.}
We only briefly mentioned how linearity can inform optimisations to produce
more performant programs. We leave exploring optimisations unblocked by
preserving linearity in the intermediate language with Linear Core as future
work. Linearity influenced optimising transformations have been also discussed
by Linear Haskell~\cite{cite:linearhaskell} and
in~\cite{cite:let-floating,peytonjones1997a}. An obvious candidate is
\emph{inlining}, which is applied based on heuristics from information provided
by the \emph{cardinality analysis} pass that counts occurrences of bound
variables.  Linearity can be used to non-heuristically inform
the inliner~\cite{cite:linearhaskell}.
% Additionally, we argue that in Linear Core accepting more programs as linear
% there are more chances to use linearity, in contrast to a linear type system
% which does not account for lazy evaluation and thus rejects more programs.

% \paragraph{Usage environment resource inference.}
% In Section~\ref{sec:linearity-semantically}, we discussed how there is not an obvious way to determine the set of linear
% resources used by a group of (mutually) recursive bindings, .
% though the resources used by each binder are the solution to a set determined
% by the recursive bindings group.  In Section~\ref{sec:main:linear-core}, we
% further likened the challenge of determining usage environments for a recursive
% group of bindings to a unification problem as that solved by the Hindley-Milner
% type inference algorithm~\cite{DBLP:conf/popl/DamasM82} based on generating and solving
% constraints. Even though these are useful observations, our implementation of
% Linear Core uses a naive algorithm to determine the usage environments, thereby
% leaving as future work the design of a principled algorithm to determine the
% usage environments of recursive group of bindings.

\paragraph{Linear Core in the Glasgow Haskell Compiler.}
Linear Core is suitable as the intermediate language of an optimising compiler
for a linear and lazy language such as Haskell Core, in that optimising
transformations in Linear Core preserve types \emph{and} linearity, since Linear
Core understands semantic linearity in the presence of laziness, unlike
Core's current type system under which optimisations currently violate
linearity.
%
Integrating Linear Core in the Glasgow Haskell Compiler is one of the ultimate
goals of our work. Core's current type system ignores linearity due to
its limitation in understanding semantic linearity, and our work fills this gap
and would allow Core to be linearly typed all throughout.
%
A linearly typed Core that preserves linearity throughout the optimisation
pipeline of GHC both validates the correctness of the compiler, which is
already achieved to a great extent by preserving (non-linear) types, and
informs optimisations, allowing the compiler to generate more performant programs.
%
Implementing Linear Core in GHC is a challenging endeavour, since we must
account for all other Core features (e.g. strict constructor fields), propagate
new or modified data throughout the entire pipeline, and accept more
optimisations. Despite our initiative in this direction\footnote{[Link removed
due to
anonymization]} %\footnote{https://gitlab.haskell.org/ghc/ghc/-/issues/23218} ,
we leave this as future work.

\paragraph{Generalizing Linear Core to Haskell.}
Linear types, despite their compile-time correctness guarantees regarding
resource management, impose a burden on programmers in being a restrictive
typing discipline (witnessed, e.g., by Linear
Constraints~\cite{cite:linearconstraints}). Linear Core eases the restrictions
of linear typing by being more flexible in understanding linearity for lazy
languages. In this sense, it is an avenue of future
work to apply the ideas from this work to the surface Haskell language.

% \section*{Acknowledgements}

% We thank Arnaud Spiwack for valuable and insightful discussions.\todo{Do these have to be anonymized?}

% \begin{itemize}
% 
% \item Linear(X), a linear type system defined by the underlying definition of
% evaluation (which in turn implies how consuming a resource is defined)
% 
% \item Implementation in Core
% 
% \item Generalization to source level language, being more permissive in the
% handling of resources imposes less burden on the programmer
% 
% \item It's harder to typecheck linearity like this in the source level because
% of the interaction with other source features, but seems feasible and an
% improvement to the usability of linear types. It allows more lazy functional
% programming idioms with linear types (also because laziness and strictness is less well defined as in Core, bc opts)
% 
% \item Beautiful inference algorithm for recursive usage environments -- insight
% that looks like inference for recursive function principle types, but haven't
% figured it out -- connection to type inference / hindley milner
% 
% \item We kind of ignore the multiplicity semiring. We should discuss
% how we don't do ring operations ... but that's kind of wrong.
% 
% % \item We know the case binder to ALWAYS be in WHNF, perhaps there could
% % be some annotation on the case binder s.t. we know nothing happens when we
% % scrutinize it as a single variable
% 
% \item Mechanizing the system and metatheory
% 
% \end{itemize}


% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Conclusion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% We give up on this section and instead describe "syntax-directedness" in the implementation chapter
%
%
% \section{Syntax Directed System}
% 
% \todo[inline]{In the other system we assume that the recursive lets are strongly connected, i.e. the expressions always}
% 
% \input{language-v4/SyntaxDirectedSystem}
% 
% \subsection{Inferring usage environments}
% 
% \todo[inline]{The difference between this and the previous section is a bit blurry}
% 
% \todo[inline]{There's one more concern: usage environments aren't readily
% available, especially in recursive lets. We must perform inference of usage
% environments before we can typecheck using them. This is how:}
% 
% \todo[inline]{Rather, we define a syntax directed type system that infers usage environments while checking...}
% 

% \section{Conclusion}

% Optimising compilers with a typed and lazy intermediate language with linear
% types (of which GHC is the prime example) leverage laziness to heavily
% transform and rewrite programs into simpler forms.
% %
% However, these optimising transformations push the interaction between
% linearity and laziness to the limits where linearity can no longer be seen
% syntactically, despite being maintained semantically, in the sense that linear
% resources are still used exactly once when the optimised program is run.

% In this work we explored linearity in the presence of laziness by example
% through the interactions of linear types with lazy (recursive) let bindings and
% case expressions that evaluate their scrutinee to Weak Head Normal Form. Most
% example programs were linear semantically, but not syntactically.
% %
% We developed a linear type system, Linear Core, for an intermediate language
% akin to GHC Core, with laziness and linearity. In contrast to GHC Core's type
% system, or any other linear type system (to the best of our knowledge), our
% type system understands semantic linearity, and can thus correctly type a wider
% range of linear programs, as those explored in the semantic linearity examples.
% %
% Crucially, we proved soundness of the type system, and proved multiple
% optimising transformations preserve linearity, despite most violating linearity
% in other linear type systems. Additionally, we implemented Linear Core as a GHC
% plugin to further explore its suitability in the intermediate language of an
% optimising compiler.

% Concluding, Linear Core is a suitable type system for linear, lazy,
% intermediate languages of optimising compilers such as GHC, as it understands
% linearity in the presence of laziness s.t. optimisations preserve types and
% linearity, and further unblocks optimisations influenced by linearity, e.g.
% inlining and call-by-name $\beta$-reduction for applications of (semantically)
% linear functions.

% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% {{{ Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix

\section{Natural and Instrumented Operational Semantics}\label{app:opsem}

We define a lazy big-step operational semantics for $\lambda_\Delta^\pi$ in the
style of Launchbury~\cite{10.1145/158511.158618} natural semantics. The semantics is
equipped with an environment which assigns expressions to variables and is
mutated in order to express lazy evaluation. Terms are explicit about
their sharing (in the sense of shared reductions in lazy evaluation),
and so we perform a translation that makes all sharing explicit
through let-binders. This translation is presented in Figure~\ref{fig:explicitsharing}.
We write $\llet{\ov{x_i{:}_{\Delta_i}\sigma = e_i}}{e'}$ for the iterated
let-binding of variables $\ov{x_i}$.
\begin{figure}
\[
  \begin{array}{lclr}
    x^* & \triangleq & x\\

    (\Lambda p.~e)^* & \triangleq & \Lambda p.~(e)^*\\
    (\lambda x:_\pi\sigma .e)^* & \triangleq & \lambda x:_\pi\sigma . (e)^*\\
    (e~\pi)^* & \triangleq & (e)^*~\pi\\
    (e~x)^* & \triangleq & (e)^*~x\\
    (e~e')^* & \triangleq & \llet{x{:}_{\Delta}\sigma =
                            (e')^*}{(e)^*~x}     \\ &&\qquad \mbox{with
                            $\Gamma;\Delta' \vdash e :
                            \sigma\rightarrow_\pi \varphi$} \\ &&\qquad \mbox{and
                                       $\Gamma;\Delta \vdash e' : \sigma$}\\
      K~\ov{e_i} & \triangleq & \llet{\ov{x_i:_{\Delta_i} \sigma_i =
                                   (e_i)^*}}{K~\ov{x_i}} \\ &&
                                       \qquad\mbox{with
                                       $\ov{\Gamma;\Delta_i\vdash
                                       e_i :
                                       \sigma_i}$}\\                                              
(\ccase{e}{z{:}_{\Delta}\sigma~\{\overline{\rho\to e'}\}})^* &
                                                               \triangleq
                                &
                                  \ccase{(e)^*}{z{:}_{\Delta}\sigma~\{\overline{\rho\to (e')^*}\}}\\
    (\llet{x{:}_{\Delta}\sigma = e}{e'}      )^* & \triangleq & \llet{x{:}_{\Delta}\sigma  = (e)^*}{(e')^*}    \\
    (\lletrec{\overline{x{:}_{\Delta}\sigma = e}}{e'}  )^* & \triangleq &\lletrec{\overline{x{:}_{\Delta}\sigma = (e)^*}}{(e')^*}  
      \end{array}
    \]
    \caption{Explicit Sharing Translation\label{fig:explicitsharing}}
  \end{figure}

  
The natural semantics (Figure~\ref{fig:natsemapp}) is defined via the relation
$\Theta : e \Downarrow \Theta' : v$ where $e$ is an expression, $v$ a
value, $\Theta$ and $\Theta'$ are environments with bindings of the
form $x:_\omega\sigma = e$ which assigns the expression $e$ to the
variable $x$ of the given type.

\begin{figure}
\[
  \begin{array}{c}
    \infer[]
    {\,}
    {\Theta : \Lambda p.e \Downarrow \Theta : \Lambda p.e}
    \qquad
    \infer[]
    {\Theta  : e\Downarrow \Theta' : \Lambda p.e' \quad \Theta' :
    e'[\pi/p]\Downarrow \Theta'' : v}
    {\Theta : e~\pi\Downarrow \Theta'' : v }\\[1.5em]
    \infer[]
    {\,}
    {\Theta : \lambda x:_\pi \sigma . e \Downarrow \Theta : \lambda x:_\pi \sigma . e }
    \qquad
    \infer[]
    {\Theta : e \Downarrow \Theta' : \lambda y:_\pi \sigma . e' \quad
    \Theta' : e'[x/y] \Downarrow \Theta'' : v }
    {\Theta : e~x \Downarrow \Theta'' : v}\\[1.5em]
    \infer[]
    {(\Theta , x:_\omega \sigma = e): e \Downarrow \Theta' : v}
    {(\Theta , x:_\omega \sigma = e) : x \Downarrow (\Theta',x:_\omega
    \sigma = v) : v}
    \qquad
    \infer[]
    {(\Theta,x:_\omega \sigma = e) : e' \Downarrow \Theta' : v}
    {\Theta : \llet{x{:}_{\Delta}\sigma = e}{e'}\Downarrow \Theta' : v
    }\\[1.5em]
    \infer[]
    {\,}
    {\Theta : K~\ov{x_i} \Downarrow \Theta : K~\ov{x_i}}
    \qquad
    \infer[]
    {\Theta : e \Downarrow \Theta' : K~\ov{x_i} \quad
    \Theta' : e'\ov{[x_i/y_i]}[K~\ov{x_i}/z] \Downarrow \Theta'' : v }
    {\Theta :
    \ccase{e}{z{:}_{\Delta'}\sigma~\{{\dots,K~\ov{y_i} \to e', {\dots}}\}}
    \Downarrow \Theta'' : v}\\[1.5em]
    \infer[]
    {\Theta : e \Downarrow \Theta' : K~\ov{x_i} \quad
    \Theta' : e'[K~\ov{x_i}/z] \Downarrow \Theta'' : v }
    {\Theta :
    \ccase{e}{z{:}_{\Delta'}\sigma~\{\dots , \_\to
    e'}\} \Downarrow \Theta'' : v}
    \qquad
    \infer[]
    {% (\Gamma, \overline{x_i:_\omega \sigma_i = e_i}) : e_1 \Downarrow \Theta_1
    % : v_1 \dots  (\Gamma, \overline{x_i:_\omega \sigma_i = e_i}) : e_n
    % \Downarrow \Theta_n : v_n \quad
    (\Theta, \overline{x_i:_\omega \sigma_i = e_i}) : e' \Downarrow \Theta'
    : v
    }
    {\Theta : \lletrec{\overline{x_i{:}_{\Delta}\sigma_i = e_i}}{e'}
    \Downarrow \Theta' : v}
    \end{array}
  \]
  \caption{Natural Semantics for $\lambda_\Delta^\pi$\label{fig:natsemapp}}
\end{figure}

Our instrumented, linearity-aware semantics (akin to that
of~\cite{cite:linearhaskell})
is defined in Figure~\ref{fig:instrsemapp}.
In this semantics, linear variables are erased from
the runtime environment, ensuring that any term violating linearity
produces a stuck state. The semantics is defined by
the judgment $\Gamma ; \Delta \vdash (\Theta \mid e) \Downarrow (\Theta'
\mid v) : \sigma , \Sigma$ where $\Gamma$ and $\Delta$ are typing judgments
($\Gamma$ tracks unrestricted variables, $\Delta$ tracks linear
assumptions) for variables occurring in $\Sigma$;
$\Theta$ and $\Theta'$ are runtime environments, consisting of bindings of the form
$x :_\pi \sigma = e$ or $x :_\Delta \sigma = e$ ; $e$ is the expression being evaluated and $v$
its resulting value, both of type $\sigma$; $\Sigma$ is a list of assignments of the form
$e : \tau$, which are expressions in which variables in $\Theta$ are
used.


\begin{figure}
\[
  \begin{array}{c}
    \infer[]
    {\,}
    {\Gamma;\Delta \vdash (\Theta \mid \Lambda p.e) \Downarrow (\Theta \mid
    \Lambda p.e) : \forall p . \sigma , \Sigma }
    \\[1.5em]
    \infer[]
    {\Gamma ; \Delta \vdash (\Theta \mid  e) \Downarrow (\Theta' \mid
    \Lambda p.e') : \forall p . \sigma , \Sigma \quad \Gamma ;\Delta \vdash
      (\Theta' \mid e'[\pi/p]) \Downarrow (\Theta'' \mid v) : \sigma[\pi/p], \Sigma}
    {\Gamma ; \Delta \vdash (\Theta \mid e~\pi) \Downarrow (\Theta''
      \mid v) : \sigma[\pi/p] , \Sigma  }\\[1.5em]
    \infer[]
    {\,}
    {\Gamma ;\Delta \vdash (\Theta \mid \lambda x:_\pi \sigma . e)
    \Downarrow (\Theta \mid \lambda x:_\pi\sigma .e) : \sigma
    \rightarrow_\pi \tau,\Sigma }\\[1.5em]
    \infer[]
    {\Gamma;\Delta \vdash  (\Theta \mid e) \Downarrow (\Theta' \mid
    \lambda y:_1 \sigma . e') : \sigma \rightarrow_1 \tau , x:\sigma, \Sigma
    \quad
    \Gamma ; \Delta \vdash (\Theta' , y:_{1} \sigma = x \mid e') \Downarrow (\Theta''
    \mid v) : \tau , \Sigma  }
    {\Gamma ; \Delta\vdash (\Theta \mid  e~x ) \Downarrow (\Theta''
    \mid v) : \tau , \Sigma }\\[1.5em]
        \infer[]
    {\Gamma;\Delta \vdash  (\Theta \mid e) \Downarrow (\Theta' \mid
    \lambda y:_\omega \sigma . e') : \sigma \rightarrow_\omega \tau , x:\sigma, \Sigma
    \quad
            \Gamma ; \Delta \vdash (\Theta' \mid e'[x/y]) \Downarrow (\Theta''
    \mid v) : \tau , \Sigma  }
    {\Gamma ; \Delta\vdash (\Theta \mid  e~x ) \Downarrow (\Theta''
    \mid v) : \tau , \Sigma }\\[1.5em]
       \infer[]
    {\Gamma ; \Delta  \vdash (\Theta, x:_{\Delta'} \sigma = e \mid e)
    \Downarrow (\Theta' \mid v) : \sigma , \Sigma \\
      \D'' = \D' \setminus (\Theta \setminus \Theta')
      }
    {\Gamma ; \Delta \vdash (\Theta , x:_{\Delta'} \sigma = e \mid x)
      \Downarrow (\Theta' , x:_{\Delta''} \sigma = v \mid v) : \sigma, \Sigma}
    \\[1.5em]
           \infer[]
    {\Gamma ;\Delta  \vdash (\Theta \mid e)
    \Downarrow (\Theta' \mid v) : \sigma,\Sigma}
    {\Gamma ; \Delta \vdash (\Theta , x:_1 \sigma = e \mid x)
    \Downarrow (\Theta' \mid v) : \sigma,\Sigma}
    \\[1.5em]
    
    \infer[]
    {\Gamma ;\Delta \vdash (\Theta,x:_{\Delta'} \sigma = e \mid e')
    \Downarrow (\Theta' \mid v) : \tau,\Sigma}
    {\Gamma ; \Delta \vdash (\Theta \mid \llet{x{:}_{\Delta'}\sigma =
    e}{e'})\Downarrow (\Theta' \mid v) : \tau , \Sigma
    }\\[1.5em]
    
    \infer[]
    {\,}
    {\Gamma ; \Delta \vdash (\Theta \mid K~\ov{x_i}) \Downarrow
    (\Theta \mid K~\ov{x_i}) : T , \Sigma}
    \\[1.5em]
    
    \infer[]
    { K : \ov{ \sigma_i
    \rightarrow_\omega \sigma_j \lolli} T
    \\
    \Gamma, \ov{y_i :_\omega \sigma_i} ;\Delta , \ov{y_j :_1 \sigma_j} \vdash (\Theta \mid e) \Downarrow (\Theta' \mid
      K~\ov{x_i}) : T , e' : \tau ,\Sigma \\
    \Gamma ;\Delta \vdash (\Theta' \mid e'\ov{[x_i/y_{i,j}]}[K~\ov{x_i}/z]
    ) \Downarrow (\Theta'' \mid v) :\tau , \Sigma }
    {\Gamma ;\Delta \vdash (\Theta \mid
    \ccase{e}{z{:}_{\Delta'}T~\{{\dots,K~\ov{y_{i,j}} \to e', {\dots} }\}})
    \Downarrow (\Theta'' \mid  v) : \tau , \Sigma}\\[1.5em]

    
    \infer[]
    {K : \ov{ \sigma_i
    \rightarrow_\omega \sigma_j \lolli} T\\
    \Gamma ; \Delta, z{:}_1\s \vdash (\Theta \mid e) \Downarrow (\Theta' \mid
    K~\ov{x_i}) : T , e', \Sigma \quad
    \Gamma ;\Delta \vdash (\Theta' \mid  e'[K~\ov{x_i}/z])
    \Downarrow (\Theta'' \mid v) : \tau,\Sigma }
    {\Gamma ; \Delta \vdash (\Theta \mid 
    \ccase{e}{z{:}_{\Delta'}T~\{\dots , \_\to
    e'}\}) \Downarrow (\Theta'' \mid v) : \tau}
    \\[1.5em]

     \infer[]
     {% (\Gamma, \overline{x_i:_\omega \sigma_i = e_i}) : e_1 \Downarrow \Theta_1
     % : v_1 \dots  (\Gamma, \overline{x_i:_\omega \sigma_i = e_i}) : e_n
     % \Downarrow \Theta_n : v_n \quad
     (\Gamma ; \Delta \vdash (\Theta, \overline{x_i:_{\Delta'} \sigma_i =
     e_i} \mid e' )\Downarrow (\Theta'
     \mid v) : \tau
     }
     {\Gamma ;\Delta \vdash (\Theta \mid \lletrec{\overline{x_i{:}_{\Delta'}\sigma_i = e_i}}{e'})
     \Downarrow (\Theta' \mid v) : \tau}

   \end{array}
 \]
 \caption{Instrumented Semantics for $\lambda_\Delta^\pi$\label{fig:instrsemapp}}
 \end{figure}

 Following~\cite{Gunter1993APA,cite:linearhaskell}, we also consider
 partial derivations of our semantics in order to be able to state a
 progress result. Given our set of rules defining judgments of the
 form $a \Downarrow b$ with ordered premises, we define a total
 derivation of $a \Downarrow b$ as a tree in the standard way. A
 partial derivation $a \Downarrow?$ is either a root labelled with $a
 \Downarrow?$ or an application of a rule matching $a$ on the left of
 the evaluation arrow, where exactly one of the premises $a'
 \Downarrow?$ has a partial  derivation, all the premises to the left
 of $a' \Downarrow?$ have a total derivation, and the premises to the
 right of $a'\Downarrow?$ are not known yet.
 %

 By construction, in a partial derivation, there is only one premise
 $b\Downarrow?$ with no sub-derivation. We call $b$ the head of such a
 partial derivation.
We write $a \Downarrow^* b$ for the relation which holds when $b$ is
the head of some partial derivation with root $a \Downarrow?$.  We
write $a \Downarrow^* b$  the partial evaluation relation.
 
Below, we write $\Theta {\uparrow^1}$ for the linear bindings in evaluation environment $\Theta$ and $\Theta {\uparrow^\omega}$ for all other bindings.



 
 \begin{definition}[Environment Expansion]
   We rely on an expansion of a runtime environment $\Theta$ for the evaluation of a term $e$ into a (typed) term, written $[\Theta \mid e]$, defined inductively as follows:
   \[
     \begin{array}{lcl}
       \left[ \cdot \mid e \right] & \triangleq & e\\
       \left[ \Theta , x:_1\sigma = e' \mid e \right] & \triangleq  & [\Theta \mid (\lambda x_1:\sigma . e)~e']\\
       \left[\Theta , x:_\Delta \sigma = e' \mid e \right] & \triangleq & [\Theta \mid \llet{x:_\Delta \sigma = e'}{e}]
    \end{array}
   \]
 \end{definition}


We note that for the treatment of recursive let groups, environment
expansion needs to happen for the entire group of let-bound
variables. This is easily achieved by extending the runtime
environment with information about recursive let groupings, which we
omit for the sake of presentation.
 
 \begin{definition}[Well-typed State]
   We write $\G;\D \vdash \Theta \mid e : \tau,\Sigma$ to denote the following typing judgment:

   \[
\G ; \D \vdash [ \Theta \mid (e,\mathit{terms}(\Sigma))] : \tau \otimes \bigotimes(\Sigma)
   \]
   where $\mathit{terms}(e_1 : \sigma_1 , \dots , e_n : \sigma_n)$ stands for the tuple $(e_1 ,( \dots , (e_n , ())))$ and
   $\bigotimes(e_1 : \sigma_1 , \dots , e_n : \sigma_n)$ for $\sigma_1 \otimes ( \dots (\sigma_n \otimes ()))$.
 \end{definition}

 \begin{lemma}
   Iff $\G ; \D \vdash [ \Theta \mid e] : \sigma$
     then $\G , \Theta\uparrow^{\omega} ; \D , \Theta\uparrow^1 \vdash  (e, \Theta\downarrow^1_e) : \sigma \otimes \bigotimes(\Theta\downarrow^1_\sigma)$
   \end{lemma}



\subsection{Bisimulation}


We relate our two operational semantics through a bisimulation,
allowing us to transfer type safety of the instrumented semantics to
the lazy big-step semantics. The relation essentially allows the
execution environment to treat some unrestricted bindings
of the natural semantics as linear.

\begin{definition}[Bisimulation]
We define the relation $\gamma(\Theta : e)(\G ; \D \vdash \Theta' \mid
e' : \tau,\Sigma)$ between a well-typed state and an ordinary state of
the lazy big-step semantics if $e = e'$ and $\Theta'{\uparrow^\omega}
\leq \Theta$.
\end{definition}

\begin{lemma}~\label{lem:naturaltoinstr}
  \begin{itemize}
    \item For all $\gamma(\Theta : e)(\G ; \D \vdash \Theta' \mid
e : \tau,\Sigma)$ such that $\Theta : e \Downarrow \Theta'' : v$
there exists a well-typed state $\G ; \D \vdash (\Theta''' \mid v) :
\tau,\Sigma$ such that $\G ; \D \vdash (\Theta' \mid e) \Downarrow
(\Theta''' \mid v) : \tau,\Sigma$ and $\gamma(\Theta'' : v)(\G ; \D
\vdash \Theta''' \mid v : \tau,\Sigma)$
\item For all $\gamma(\Theta : e)(\G ; \D \vdash \Theta' \mid
e : \tau,\Sigma)$ such that $\Theta : e \Downarrow^* \Theta'' : v$
there exists a well-typed state $\G ; \D \vdash (\Theta''' \mid v) :
\tau,\Sigma$ such that $\G ; \D \vdash (\Theta' \mid e) \Downarrow^*
(\Theta''' \mid v) : \tau,\Sigma$ and $\gamma(\Theta'' : v)(\G ; \D
\vdash \Theta''' \mid v : \tau,\Sigma)$
\end{itemize}
\end{lemma}
\begin{proof}
By induction on the given operational semantics rules.
  \end{proof}

\begin{lemma}~\label{lem:instrtonatural}
  \begin{itemize}
\item  For all $\gamma(\Theta : e)(\G ; \D \vdash \Theta' \mid
e : \tau,\Sigma)$ such that $\G ; \D \vdash (\Theta' \mid e) \Downarrow
(\Theta'' \mid v) : \tau,\Sigma$, there exists a state $\Theta''' : v$
such that $\Theta : e \Downarrow \Theta''' : v$ and
$\gamma(\Theta''' : v)(\G ; \D \vdash (\Theta'' \mid v) :
\tau,\Sigma)$
\item For all $\gamma(\Theta : e)(\G ; \D \vdash \Theta' \mid
e : \tau,\Sigma)$ such that $\G ; \D \vdash (\Theta' \mid e) \Downarrow^*
(\Theta'' \mid v) : \tau,\Sigma$, there exists a state $\Theta''' : v$
such that $\Theta : e \Downarrow^* \Theta''' : v$ and
$\gamma(\Theta''' : v)(\G ; \D \vdash (\Theta'' \mid v) :
\tau,\Sigma)$
   \end{itemize}
 \end{lemma}
\begin{proof}
By induction on the given operational semantics rules.
  \end{proof}


  



\section{Type Safety Proofs}\label{app:proofs}

In the following we write $\Mapsto$ to stand for
$\Rightarrow_\mathsf{WHNF}$ and $\Rrightarrow$ for $\Rightarrow_\mathsf{NWHNF}$.

\subsection{Auxiliary Lemmas}
The following lemmas presuppose the variable names across the typing
contexts are distinct.

  \begin{lemma}[Linear to $\Delta$-bound]~\label{lem:onedelta-app}

    \begin{enumerate}
    
      \item If $\G; \D',\xl \vdash e :\vp$
        then $\G[\D/x],\xD; \D,\D' \vdash e : \vp$ (with $\Delta$ fresh).
      \item If $\G ; \D' , \xl \vdash_{alt} \rho \rightarrow e
        :^z_{\Delta_s} \sigma \Rightarrow \rho$ then
        $\G[\D/x],\xD;\D,\D' \vdash_{alt} \rho \rightarrow e
        :^z_{\Delta_s} \sigma \Rightarrow \rho$ (with $\Delta$ fresh).
   
      \end{enumerate}
\end{lemma}
\begin{proof}
Straightforward induction on the structure of the given derivation,
reconstructing the original derivation and applying rule
$\mathit{Var}_\Delta$ where rule $\mathit{Var}_1$ was applied on
$x$ in the original derivation.
\end{proof}
\onedelta*

\begin{proof}
By Lemma~\ref{lem:onedelta-app}(1).
\end{proof}



\begin{lemma}[$\Delta$-bound to Linear]~\label{lem:deltaone-app}

  \begin{enumerate}
 \item If $\G,\x[\irr{\D}]; \irr{\D},\D' \vdash e : \vp$
   then $\G[x/\irr{\D}]; \D',\xl \vdash e :\vp$.
 \item If $\G ,\x[\irr{\D}]; \irr{\D}, \D' \vdash_{alt} \rho \rightarrow e
   :^z_{\Delta_s} \sigma \Rightarrow \rho$ then
   $\G[x/\irr{\D}];\D',\xl \vdash_{alt} \rho \rightarrow e
   :^z_{\Delta_s} \sigma \Rightarrow \rho$.
  \end{enumerate}
\end{lemma}
\begin{proof}
Straightforward induction on the structure of the given derivation,
reconstructing the original derivation and applying rule
$\mathit{Var}_1$ where rule $\mathit{Var}_\D$ was applied on
$x$ in the original derivation.
\end{proof}



\deltaone*
\begin{proof}
By Lemma~\ref{lem:deltaone-app}(1).
\end{proof}

\begin{lemma}[Unrestricted and $\Delta$-bound]~\label{lem:undelta-app}
  \begin{enumerate}
    \item $\G,\xo; \D \vdash e : \vp$ iff $\G,\x[\cdot]; \D \vdash e :
      \vp$
    \item $\G,\xo;\D \vdash_{alt} \rho \rightarrow e
      :^z_{\Delta_s} \sigma \Rightarrow \rho$ iff
      $\G,\x[\cdot];\D \vdash_{alt} \rho \rightarrow e
   :^z_{\Delta_s} \sigma \Rightarrow \rho$
  \end{enumerate}
\end{lemma}
\begin{proof}
Straightforward induction on the structure of the given derivation,
noting that rules $\mathit{Var}_\Delta$ and $\mathit{Var}_\omega$
coincide when $\Delta$ is empty.
\end{proof}

\undelta*

\begin{proof}
By Lemma~\ref{lem:undelta-app}.
\end{proof}


\subsection{Irrelevance\label{sec:proof:irrelevance}}

\input{language-v4/proofs/WHNFConvSoundness}

\subsection{Substitution Lemmas\label{sec:proof:substitution-lemmas}}

\input{language-v4/proofs/LinearSubstitutionLemma}

\input{language-v4/proofs/UnrestrictedSubstitutionLemma}

\input{language-v4/proofs/DeltaSubstitutionLemma}



\subsection{Type Preservation\label{sec:proof:type-preservation}}

% \input{language-v4/proofs/TypePreservationTheorem}
\begin{theorem}[Type Preservation]\label{thm:typepres}
  Let $\G ; \D \vdash (\Theta \mid e) \Downarrow (\Theta' \mid v) :
  \tau , \Sigma$ or $\G ; \D \vdash (\Theta \mid e) \Downarrow^* (\Theta' \mid v) :
  \tau , \Sigma$.
  If $\G ; \D \vdash \Theta \mid e : \tau , \Sigma$ then $\G ; \D \vdash \Theta' \mid v : \tau , \Sigma$
  
\end{theorem}

We also derive type preservation for the lazy natural semantics.

  \begin{theorem}[Type Preservation]
For any well-typed $[\Theta \mid e]$, if $\Theta : e \Downarrow
\Theta' : e'$ or $\Theta : e \Downarrow^* \Theta' : e'$ then we have
that $[\Theta \mid e']$ is well-typed.
\end{theorem}
\begin{proof}
By Lemma~\ref{lem:naturaltoinstr} and Theorem~\ref{thm:typepres}.
\end{proof}

\subsection{Progress\label{sec:proof:progress}}

%\input{language-v4/proofs/ProgressTheorem}

\begin{theorem}[Progress]\label{thm:prog}
Let $\G ; \D \vdash \Theta \mid e : \tau,\Sigma$. Any partial derivation $\G; \D \vdash (\Theta \mid e)
\Downarrow?,\Sigma$ can be extended. 
\end{theorem}

\begin{proof}
 Essentially all cases are standard. The only potential issue is the
 (linear) variable rule.
It suffices to show that whenever a variable is evaluated it is
present in the evaluation environment. This situation is impossible
since the state
$\G ; \D \vdash \Theta \mid x : \tau , \Sigma$ where $x$ is absent
from $\Theta$ is not well-typed and so cannot be the head of a partial
derivation. 
\end{proof}

\begin{theorem}[Progress]
For any partial derivation of $\Theta : e \Downarrow?$, for $[\Theta |
e]$ well-typed, the derivation can be extended.
\end{theorem}
\begin{proof}
Follows from Lemma~\ref{lem:instrtonatural} and Theorem~\ref{thm:prog}.
 \end{proof}


\section{Optimisations preserve linearity}\label{app:optimisations}

\subsection{Inlining}
\input{language-v4/proofs/optimizations/Inlining}

\subsection{\texorpdfstring{$\beta$}{Beta}-reduction}

\input{language-v4/proofs/optimizations/BetaReduction}

\subsection{Case of known constructor}

\input{language-v4/proofs/optimizations/CaseOfKnownConstructor}

\subsection{Case of Case\label{sec:proof:caseofcase}}

The case of case transformation applies to case expressions whose scrutinee is
another case expression, and returns the innermost case expression transformed by repeating
the outermost case expression in each alternative of the innermost case,
scrutinizing the original alternative body.

Intuitively, since the scrutinee of the outermost case is not in WHNF, no
resources from it can directly occur in the outermost alternatives. By moving
the outermost alternatives inwards with a different scrutinee, the alternatives
remain well-typed because they are typed using either the case binder or the
pattern bound variables, which, by the \emph{Irrelevance} lemma, makes it
well-typed for any scrutinee consuming arbitrary resources.

\input{language-v4/proofs/optimizations/CaseOfCase}

\subsection{Commuting let}

\input{language-v4/proofs/optimizations/LetFloating}

\subsection{\texorpdfstring{$\eta$}{Eta}-conversions}

\input{language-v4/proofs/optimizations/EtaConvs}

\subsection{Binder Swap}

The binder swap transformation applies to case expressions whose scrutinee is a
single variable $x$, and it substitutes occurrences of $x$ in the case
alternatives for the case binder $z$. If $x$ is a linear resource, $x$ cannot
occur in the case alternatives (as we conservatively consider variables are not
in WHNF), so the substitution preserves types vacuously. Otherwise, $x$ can be
freely substituted by $z$, since $z$ is also an unrestricted resource (it's
usage environment is empty because $x$ is unrestricted).

\input{language-v4/proofs/optimizations/BinderSwap}




% G ; D |- (Theta | e x) \Downarrow (Theta'' | v) : tau, Sigma

% QUEREMOS PROVAR:
% Se
% G ; D |- (Theta | e x) : tau , Sigma
% entao
% G ; D |- (Theta'' | v) : tau, Sigma    

% por i.h.
% Se G;D |- (Theta | e) : sigma -> tau, x:tau , Sigma
% entao
% G ; D |- (Theta' | \y:sigma.e') : sigma->tau, x:tau,Sigma

% por i.h.
% Se G ; D |- (Theta' , y:sigma = x | e') : tau, Sigma
% entao
% G;D |- (Theta'' | v) : tau , Sigma


% Gamma ; Delta |- [Theta | (e x , terms(Sigma))] : (tau , types(Sigma))
% Gamma ; Delta |- [Theta | (e , terms(x:tau,Sigma))] : (tau->sigma , types(x:tau,Sigma))


% Daqui Gamma ; Delta |- [Theta' | (\y:_1 sigma.e' , terms(x:tau,Sigma))] : (sigma->tau, types(x:tau,Sigma))
% tirar Gamma ; Delta |- [Theta',y:sigma = x | (e' , terms(Sigma))] : (sigma->tau, types(Sigma))


% [Theta' , x_1 : tau = y | e] = (\x_1:tau . [Theta' | e] ) y
% [ Theta' , x_Delta:tau = e' | e] = let x_Delta = e' in [Theta' | e]
% [ . | (e,e')] = (e,e')

% Gamma ; Delta |- [Theta | (e , terms(Sigma))] : (tau , types(Sigma))

 % Gamma ; Delta |- Theta | e  : tau, Sigma

% }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

% TODO: - In the letrec case: congratulations on finding an inference algorithm
% (though I will want to see the proof some day, I don't see why it works yet).
% You should clarify that, during linting, you will have a usage environment
% annotation and won't need to run the inference algorithm. This algorithm is
% only needed when you first create a letrec.

% vim: fen fdm=marker
